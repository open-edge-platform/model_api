Search.setIndex({"alltitles": {"API Reference": [[9, "api-reference"]], "Accessing Performance Metrics": [[8, "accessing-performance-metrics"]], "Action Classification": [[10, null]], "ActionClassificationModel": [[7, "actionclassificationmodel"]], "Adapters": [[0, null]], "Advanced Usage": [[8, "advanced-usage"]], "Analyzing Bottlenecks": [[8, "analyzing-bottlenecks"]], "Anomaly": [[11, null]], "AnomalyDetection": [[7, "anomalydetection"]], "Async Pipeline": [[26, null]], "Basic Usage": [[8, "basic-usage"]], "Batch Processing Performance": [[8, "batch-processing-performance"]], "Bert and its subclasses": [[7, "bert-and-its-subclasses"]], "BertQuestionAnswering": [[7, "bertquestionanswering"]], "Best Practices": [[8, "best-practices"]], "CTPN": [[7, "ctpn"]], "Classification": [[12, null]], "ClassificationModel": [[7, "classificationmodel"]], "Description": [[12, "description"], [13, "description"], [16, "description"], [17, "description"]], "Detailed Metrics Access": [[8, "detailed-metrics-access"]], "Detection": [[28, null]], "Detection Model": [[13, null]], "DetectionModel and its subclasses": [[7, "detectionmodel-and-its-subclasses"]], "Example": [[13, "example"], [16, "example"], [17, "example"]], "Example: Complete Performance Analysis": [[8, "example-complete-performance-analysis"]], "FaceBoxes": [[7, "faceboxes"]], "Frame Rate and Throughput": [[8, "frame-rate-and-throughput"]], "Guides": [[6, null]], "HpeAssociativeEmbedding": [[7, "hpeassociativeembedding"]], "Image Model": [[14, null]], "ImageModel and its subclasses": [[7, "imagemodel-and-its-subclasses"]], "Individual Timing Statistics": [[8, "individual-timing-statistics"]], "Inference Adapter": [[1, null]], "Inputs": [[12, "inputs"], [13, "inputs"], [16, "inputs"], [17, "inputs"], [20, "inputs"]], "Instance Segmentation": [[16, null], [30, null]], "Keypoint Detection": [[17, null]], "List of values": [[7, "list-of-values"]], "Logging Performance Metrics": [[8, "logging-performance-metrics"]], "MaskRCNNModel": [[7, "maskrcnnmodel"]], "Model": [[18, null]], "Model API Documentation": [[9, null]], "Model Specifications": [[12, "model-specifications"], [20, "model-specifications"]], "Model configuration": [[7, null]], "Models": [[15, null], [17, "models"]], "NanoDet": [[7, "nanodet"]], "Onnx Adapter": [[2, null]], "OpenPose": [[7, "openpose"]], "OpenVINO Model Specifications": [[13, "openvino-model-specifications"], [16, "openvino-model-specifications"], [17, "openvino-model-specifications"]], "Openvino Adapter": [[3, null]], "Outputs": [[12, "outputs"], [13, "outputs"], [16, "outputs"], [17, "outputs"], [20, "outputs"]], "Overview": [[8, "overview"]], "Ovms Adapter": [[4, null]], "Parameters": [[17, "parameters"]], "Performance Metrics": [[8, null]], "Performance Monitoring During Inference": [[8, "performance-monitoring-during-inference"]], "Performance Optimization Tips": [[8, "performance-optimization-tips"]], "Pipelines": [[27, null]], "Sam Models": [[19, null]], "Segmentation": [[20, null]], "SegmentationModel and its subclasses": [[7, "segmentationmodel-and-its-subclasses"]], "Semantic Segmentation": [[31, null]], "Ssd": [[21, null]], "Tiler": [[32, null]], "Tilers": [[29, null]], "Types": [[22, null]], "UltraLightweightFaceDetection": [[7, "ultralightweightfacedetection"]], "Utils": [[5, null], [23, null]], "Visual Prompting": [[24, null]], "Warm-up Considerations": [[8, "warm-up-considerations"]], "YOLO and its subclasses": [[7, "yolo-and-its-subclasses"]], "YOLOX": [[7, "yolox"]], "YOLOv5, YOLOv8": [[7, "yolov5-yolov8"]], "Yolo": [[25, null]], "YoloV4": [[7, "yolov4"]]}, "docnames": ["adapters/index", "adapters/inference_adapter", "adapters/onnx_adapter", "adapters/openvino_adapter", "adapters/ovms_adapter", "adapters/utils", "guides/index", "guides/model-configuration", "guides/performance_metrics", "index", "models/action_classification", "models/anomaly", "models/classification", "models/detection_model", "models/image_model", "models/index", "models/instance_segmentation", "models/keypoint_detection", "models/model", "models/sam_models", "models/segmentation", "models/ssd", "models/types", "models/utils", "models/visual_prompting", "models/yolo", "pipelines/async_pipeline", "pipelines/index", "tilers/detection", "tilers/index", "tilers/instance_segmentation", "tilers/semantic_segmentation", "tilers/tiler"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["adapters/index.md", "adapters/inference_adapter.md", "adapters/onnx_adapter.md", "adapters/openvino_adapter.md", "adapters/ovms_adapter.md", "adapters/utils.md", "guides/index.md", "guides/model-configuration.md", "guides/performance_metrics.md", "index.md", "models/action_classification.md", "models/anomaly.md", "models/classification.md", "models/detection_model.md", "models/image_model.md", "models/index.md", "models/instance_segmentation.md", "models/keypoint_detection.md", "models/model.md", "models/sam_models.md", "models/segmentation.md", "models/ssd.md", "models/types.md", "models/utils.md", "models/visual_prompting.md", "models/yolo.md", "pipelines/async_pipeline.md", "pipelines/index.md", "tilers/detection.md", "tilers/index.md", "tilers/instance_segmentation.md", "tilers/semantic_segmentation.md", "tilers/tiler.md"], "indexentries": {"__call__() (model_api.adapters.utils.inputtransform method)": [[5, "model_api.adapters.utils.InputTransform.__call__", false]], "__call__() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.__call__", false]], "__call__() (model_api.models.ssd.boxeslabelsparser method)": [[21, "model_api.models.ssd.BoxesLabelsParser.__call__", false]], "__call__() (model_api.models.ssd.multipleoutputparser method)": [[21, "model_api.models.ssd.MultipleOutputParser.__call__", false]], "__call__() (model_api.models.ssd.singleoutputparser method)": [[21, "model_api.models.ssd.SingleOutputParser.__call__", false]], "__call__() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[24, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.__call__", false]], "__call__() (model_api.models.visual_prompting.samvisualprompter method)": [[24, "model_api.models.visual_prompting.SAMVisualPrompter.__call__", false]], "__call__() (model_api.tilers.instance_segmentation.instancesegmentationtiler method)": [[30, "model_api.tilers.instance_segmentation.InstanceSegmentationTiler.__call__", false]], "__call__() (model_api.tilers.semantic_segmentation.semanticsegmentationtiler method)": [[31, "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler.__call__", false]], "__call__() (model_api.tilers.tiler.tiler method)": [[32, "model_api.tilers.tiler.Tiler.__call__", false]], "actionclassificationmodel (class in model_api.models.action_classification)": [[10, "model_api.models.action_classification.ActionClassificationModel", false]], "add_edge() (model_api.models.classification.simplelabelsgraph method)": [[12, "model_api.models.classification.SimpleLabelsGraph.add_edge", false]], "add_rotated_rects() (in module model_api.models.utils)": [[23, "model_api.models.utils.add_rotated_rects", false]], "addorfindsoftmaxandtopkoutputs() (in module model_api.models.classification)": [[12, "model_api.models.classification.addOrFindSoftmaxAndTopkOutputs", false]], "anomalydetection (class in model_api.models.anomaly)": [[11, "model_api.models.anomaly.AnomalyDetection", false]], "apply_coords() (model_api.models.sam_models.samdecoder method)": [[19, "model_api.models.sam_models.SAMDecoder.apply_coords", false]], "async_pipeline (model_api.tilers.tiler.tiler attribute)": [[32, "model_api.tilers.tiler.Tiler.async_pipeline", false]], "asyncpipeline (class in model_api.pipelines.async_pipeline)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline", false]], "available_wrappers() (model_api.models.model.model class method)": [[18, "model_api.models.model.Model.available_wrappers", false]], "await_all() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.await_all", false]], "await_all() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.await_all", false]], "await_all() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.await_all", false]], "await_all() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.await_all", false]], "await_all() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.await_all", false]], "await_all() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline.await_all", false]], "await_any() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.await_any", false]], "await_any() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.await_any", false]], "await_any() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.await_any", false]], "await_any() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.await_any", false]], "await_any() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.await_any", false]], "await_any() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline.await_any", false]], "basevalue (class in model_api.models.types)": [[22, "model_api.models.types.BaseValue", false]], "booleanvalue (class in model_api.models.types)": [[22, "model_api.models.types.BooleanValue", false]], "boxeslabelsparser (class in model_api.models.ssd)": [[21, "model_api.models.ssd.BoxesLabelsParser", false]], "build_error() (model_api.models.types.basevalue method)": [[22, "model_api.models.types.BaseValue.build_error", false]], "callback() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline.callback", false]], "change_layout() (in module model_api.adapters.onnx_adapter)": [[2, "model_api.adapters.onnx_adapter.change_layout", false]], "classificationmodel (class in model_api.models.classification)": [[12, "model_api.models.classification.ClassificationModel", false]], "clear_topological_cache() (model_api.models.classification.simplelabelsgraph method)": [[12, "model_api.models.classification.SimpleLabelsGraph.clear_topological_cache", false]], "clip_detections() (in module model_api.models.utils)": [[23, "model_api.models.utils.clip_detections", false]], "clip_size (model_api.models.action_classification.actionclassificationmodel property)": [[10, "model_api.models.action_classification.ActionClassificationModel.clip_size", false]], "compute_resolution() (model_api.models.utils.outputtransform method)": [[23, "model_api.models.utils.OutputTransform.compute_resolution", false]], "configurablevalueerror": [[22, "model_api.models.types.ConfigurableValueError", false]], "copy_raw_result() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.copy_raw_result", false]], "create_core() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.create_core", false]], "create_hard_prediction_from_soft_prediction() (in module model_api.models.segmentation)": [[20, "model_api.models.segmentation.create_hard_prediction_from_soft_prediction", false]], "create_model() (model_api.models.model.model class method)": [[18, "model_api.models.model.Model.create_model", false]], "crop_resize() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.crop_resize", false]], "crop_resize_graph() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.crop_resize_graph", false]], "crop_resize_ocv() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.crop_resize_ocv", false]], "data (model_api.models.visual_prompting.prompt attribute)": [[24, "model_api.models.visual_prompting.Prompt.data", false]], "detect_model_type() (model_api.models.model.model class method)": [[18, "model_api.models.model.Model.detect_model_type", false]], "detectionbox (class in model_api.models.yolo)": [[25, "model_api.models.yolo.DetectionBox", false]], "detectionmodel (class in model_api.models.detection_model)": [[13, "model_api.models.detection_model.DetectionModel", false]], "detectiontiler (class in model_api.tilers.detection)": [[28, "model_api.tilers.detection.DetectionTiler", false]], "dictvalue (class in model_api.models.types)": [[22, "model_api.models.types.DictValue", false]], "embed_preprocessing() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.embed_preprocessing", false]], "execution_mode (model_api.tilers.tiler.tiler attribute)": [[32, "model_api.tilers.tiler.Tiler.execution_mode", false]], "execution_modes (model_api.tilers.tiler.tiler attribute)": [[32, "model_api.tilers.tiler.Tiler.EXECUTION_MODES", false]], "feature_vectors (model_api.models.visual_prompting.visualpromptingfeatures attribute)": [[24, "model_api.models.visual_prompting.VisualPromptingFeatures.feature_vectors", false]], "find_layer_bboxes_output() (model_api.models.ssd.boxeslabelsparser static method)": [[21, "model_api.models.ssd.BoxesLabelsParser.find_layer_bboxes_output", false]], "find_layer_by_name() (in module model_api.models.ssd)": [[21, "model_api.models.ssd.find_layer_by_name", false]], "from_openvino() (model_api.adapters.utils.layout static method)": [[5, "model_api.adapters.utils.Layout.from_openvino", false]], "from_shape() (model_api.adapters.utils.layout static method)": [[5, "model_api.adapters.utils.Layout.from_shape", false]], "from_str() (model_api.models.types.booleanvalue method)": [[22, "model_api.models.types.BooleanValue.from_str", false]], "from_str() (model_api.models.types.dictvalue method)": [[22, "model_api.models.types.DictValue.from_str", false]], "from_str() (model_api.models.types.listvalue method)": [[22, "model_api.models.types.ListValue.from_str", false]], "from_str() (model_api.models.types.numericalvalue method)": [[22, "model_api.models.types.NumericalValue.from_str", false]], "from_str() (model_api.models.types.stringvalue method)": [[22, "model_api.models.types.StringValue.from_str", false]], "from_user_layouts() (model_api.adapters.utils.layout static method)": [[5, "model_api.adapters.utils.Layout.from_user_layouts", false]], "get_all_probs() (model_api.models.classification.classificationmodel method)": [[12, "model_api.models.classification.ClassificationModel.get_all_probs", false]], "get_ancestors() (model_api.models.classification.simplelabelsgraph method)": [[12, "model_api.models.classification.SimpleLabelsGraph.get_ancestors", false]], "get_children() (model_api.models.classification.simplelabelsgraph method)": [[12, "model_api.models.classification.SimpleLabelsGraph.get_children", false]], "get_contours() (in module model_api.models.utils)": [[23, "model_api.models.utils.get_contours", false]], "get_contours() (model_api.models.segmentation.segmentationmodel method)": [[20, "model_api.models.segmentation.SegmentationModel.get_contours", false]], "get_hierarchical_predictions() (model_api.models.classification.classificationmodel method)": [[12, "model_api.models.classification.ClassificationModel.get_hierarchical_predictions", false]], "get_input_layers() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.get_input_layers", false]], "get_input_shape() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.get_input_shape", false]], "get_label_name() (model_api.models.image_model.imagemodel method)": [[14, "model_api.models.image_model.ImageModel.get_label_name", false]], "get_labels_in_topological_order() (model_api.models.classification.simplelabelsgraph method)": [[12, "model_api.models.classification.SimpleLabelsGraph.get_labels_in_topological_order", false]], "get_layout_for_input() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_layout_for_input", false]], "get_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_model", false]], "get_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_model", false]], "get_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_model", false]], "get_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.get_model", false]], "get_model() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.get_model", false]], "get_model() (model_api.tilers.tiler.tiler method)": [[32, "model_api.tilers.tiler.Tiler.get_model", false]], "get_model_class() (model_api.models.model.model class method)": [[18, "model_api.models.model.Model.get_model_class", false]], "get_multiclass_predictions() (model_api.models.classification.classificationmodel method)": [[12, "model_api.models.classification.ClassificationModel.get_multiclass_predictions", false]], "get_multilabel_predictions() (model_api.models.classification.classificationmodel method)": [[12, "model_api.models.classification.ClassificationModel.get_multilabel_predictions", false]], "get_output_layers() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.get_output_layers", false]], "get_parent() (model_api.models.classification.simplelabelsgraph method)": [[12, "model_api.models.classification.SimpleLabelsGraph.get_parent", false]], "get_performance_metrics() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.get_performance_metrics", false]], "get_raw_result() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.get_raw_result", false]], "get_raw_result() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline.get_raw_result", false]], "get_result() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline.get_result", false]], "get_rt_info() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.get_rt_info", false]], "get_rt_info_from_dict() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.get_rt_info_from_dict", false]], "get_saliency_maps() (model_api.models.classification.classificationmodel method)": [[12, "model_api.models.classification.ClassificationModel.get_saliency_maps", false]], "get_shape_from_onnx() (in module model_api.adapters.onnx_adapter)": [[2, "model_api.adapters.onnx_adapter.get_shape_from_onnx", false]], "get_subclasses() (model_api.models.model.model class method)": [[18, "model_api.models.model.Model.get_subclasses", false]], "get_user_config() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.get_user_config", false]], "get_value() (model_api.models.types.basevalue method)": [[22, "model_api.models.types.BaseValue.get_value", false]], "greedylabelsresolver (class in model_api.models.classification)": [[12, "model_api.models.classification.GreedyLabelsResolver", false]], "h (model_api.models.yolo.detectionbox attribute)": [[25, "model_api.models.yolo.DetectionBox.h", false]], "has_reference_features() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[24, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.has_reference_features", false]], "image_blob_name (model_api.models.action_classification.actionclassificationmodel attribute)": [[10, "model_api.models.action_classification.ActionClassificationModel.image_blob_name", false]], "image_blob_name (model_api.models.image_model.imagemodel attribute)": [[14, "model_api.models.image_model.ImageModel.image_blob_name", false]], "image_blob_names (model_api.models.action_classification.actionclassificationmodel attribute)": [[10, "model_api.models.action_classification.ActionClassificationModel.image_blob_names", false]], "image_blob_names (model_api.models.image_model.imagemodel attribute)": [[14, "model_api.models.image_model.ImageModel.image_blob_names", false]], "image_info_blob_names (model_api.models.image_model.imagemodel attribute)": [[14, "model_api.models.image_model.ImageModel.image_info_blob_names", false]], "imagemodel (class in model_api.models.image_model)": [[14, "model_api.models.image_model.ImageModel", false]], "infer() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[24, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.infer", false]], "infer() (model_api.models.visual_prompting.samvisualprompter method)": [[24, "model_api.models.visual_prompting.SAMVisualPrompter.infer", false]], "infer_async() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.infer_async", false]], "infer_async() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.infer_async", false]], "infer_async() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.infer_async", false]], "infer_async() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.infer_async", false]], "infer_async() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.infer_async", false]], "infer_async_raw() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.infer_async_raw", false]], "infer_batch() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.infer_batch", false]], "infer_sync() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.infer_sync", false]], "infer_sync() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.infer_sync", false]], "inference_adapter (model_api.models.model.model attribute)": [[18, "model_api.models.model.Model.inference_adapter", false]], "inferenceadapter (class in model_api.adapters.inference_adapter)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter", false]], "input_transform (model_api.models.action_classification.actionclassificationmodel attribute)": [[10, "model_api.models.action_classification.ActionClassificationModel.input_transform", false]], "input_transform (model_api.models.image_model.imagemodel attribute)": [[14, "model_api.models.image_model.ImageModel.input_transform", false]], "inputs (model_api.models.model.model attribute)": [[18, "model_api.models.model.Model.inputs", false]], "inputtransform (class in model_api.adapters.utils)": [[5, "model_api.adapters.utils.InputTransform", false]], "instancesegmentationtiler (class in model_api.tilers.instance_segmentation)": [[30, "model_api.tilers.instance_segmentation.InstanceSegmentationTiler", false]], "is_ovms_model() (model_api.adapters.ovms_adapter.ovmsadapter static method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.is_ovms_model", false]], "is_ready() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.is_ready", false]], "is_ready() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.is_ready", false]], "is_ready() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.is_ready", false]], "is_ready() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.is_ready", false]], "is_ready() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.is_ready", false]], "is_ready() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline.is_ready", false]], "keypointdetectionmodel (class in model_api.models.keypoint_detection)": [[17, "model_api.models.keypoint_detection.KeypointDetectionModel", false]], "label (model_api.models.visual_prompting.prompt attribute)": [[24, "model_api.models.visual_prompting.Prompt.label", false]], "layout (class in model_api.adapters.utils)": [[5, "model_api.adapters.utils.Layout", false]], "layout (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.layout", false]], "learn() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[24, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.learn", false]], "listvalue (class in model_api.models.types)": [[22, "model_api.models.types.ListValue", false]], "load() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.load", false]], "load_labels() (in module model_api.models.utils)": [[23, "model_api.models.utils.load_labels", false]], "load_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.load_model", false]], "load_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.load_model", false]], "load_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.load_model", false]], "load_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.load_model", false]], "load_parameters_from_onnx() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.load_parameters_from_onnx", false]], "log_layers_info() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.log_layers_info", false]], "log_runtime_settings() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.log_runtime_settings", false]], "logger (model_api.models.model.model attribute)": [[18, "model_api.models.model.Model.logger", false]], "maskrcnnmodel (class in model_api.models.instance_segmentation)": [[16, "model_api.models.instance_segmentation.MaskRCNNModel", false]], "meta (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.meta", false]], "metadata (class in model_api.adapters.inference_adapter)": [[1, "model_api.adapters.inference_adapter.Metadata", false]], "model (class in model_api.models.model)": [[18, "model_api.models.model.Model", false]], "model (model_api.tilers.tiler.tiler attribute)": [[32, "model_api.tilers.tiler.Tiler.model", false]], "model_api.adapters.inference_adapter": [[1, "module-model_api.adapters.inference_adapter", false]], "model_api.adapters.onnx_adapter": [[2, "module-model_api.adapters.onnx_adapter", false]], "model_api.adapters.openvino_adapter": [[3, "module-model_api.adapters.openvino_adapter", false]], "model_api.adapters.ovms_adapter": [[4, "module-model_api.adapters.ovms_adapter", false]], "model_api.adapters.utils": [[5, "module-model_api.adapters.utils", false]], "model_api.models.action_classification": [[10, "module-model_api.models.action_classification", false]], "model_api.models.anomaly": [[11, "module-model_api.models.anomaly", false]], "model_api.models.classification": [[12, "module-model_api.models.classification", false]], "model_api.models.detection_model": [[13, "module-model_api.models.detection_model", false]], "model_api.models.image_model": [[14, "module-model_api.models.image_model", false]], "model_api.models.instance_segmentation": [[16, "module-model_api.models.instance_segmentation", false]], "model_api.models.keypoint_detection": [[17, "module-model_api.models.keypoint_detection", false]], "model_api.models.model": [[18, "module-model_api.models.model", false]], "model_api.models.sam_models": [[19, "module-model_api.models.sam_models", false]], "model_api.models.segmentation": [[20, "module-model_api.models.segmentation", false]], "model_api.models.ssd": [[21, "module-model_api.models.ssd", false]], "model_api.models.types": [[22, "module-model_api.models.types", false]], "model_api.models.utils": [[23, "module-model_api.models.utils", false]], "model_api.models.visual_prompting": [[24, "module-model_api.models.visual_prompting", false]], "model_api.models.yolo": [[25, "module-model_api.models.yolo", false]], "model_api.pipelines.async_pipeline": [[26, "module-model_api.pipelines.async_pipeline", false]], "model_api.tilers.detection": [[28, "module-model_api.tilers.detection", false]], "model_api.tilers.instance_segmentation": [[30, "module-model_api.tilers.instance_segmentation", false]], "model_api.tilers.semantic_segmentation": [[31, "module-model_api.tilers.semantic_segmentation", false]], "model_api.tilers.tiler": [[32, "module-model_api.tilers.tiler", false]], "model_loaded (model_api.models.model.model attribute)": [[18, "model_api.models.model.Model.model_loaded", false]], "model_loaded (model_api.tilers.tiler.tiler attribute)": [[32, "model_api.tilers.tiler.Tiler.model_loaded", false]], "module": [[1, "module-model_api.adapters.inference_adapter", false], [2, "module-model_api.adapters.onnx_adapter", false], [3, "module-model_api.adapters.openvino_adapter", false], [4, "module-model_api.adapters.ovms_adapter", false], [5, "module-model_api.adapters.utils", false], [10, "module-model_api.models.action_classification", false], [11, "module-model_api.models.anomaly", false], [12, "module-model_api.models.classification", false], [13, "module-model_api.models.detection_model", false], [14, "module-model_api.models.image_model", false], [16, "module-model_api.models.instance_segmentation", false], [17, "module-model_api.models.keypoint_detection", false], [18, "module-model_api.models.model", false], [19, "module-model_api.models.sam_models", false], [20, "module-model_api.models.segmentation", false], [21, "module-model_api.models.ssd", false], [22, "module-model_api.models.types", false], [23, "module-model_api.models.utils", false], [24, "module-model_api.models.visual_prompting", false], [25, "module-model_api.models.yolo", false], [26, "module-model_api.pipelines.async_pipeline", false], [28, "module-model_api.tilers.detection", false], [30, "module-model_api.tilers.instance_segmentation", false], [31, "module-model_api.tilers.semantic_segmentation", false], [32, "module-model_api.tilers.tiler", false]], "multiclass_nms() (in module model_api.models.utils)": [[23, "model_api.models.utils.multiclass_nms", false]], "multipleoutputparser (class in model_api.models.ssd)": [[21, "model_api.models.ssd.MultipleOutputParser", false]], "names (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.names", false]], "nchw_layout (model_api.models.image_model.imagemodel attribute)": [[14, "model_api.models.image_model.ImageModel.nchw_layout", false]], "nms() (in module model_api.models.utils)": [[23, "model_api.models.utils.nms", false]], "numericalvalue (class in model_api.models.types)": [[22, "model_api.models.types.NumericalValue", false]], "onnxruntimeadapter (class in model_api.adapters.onnx_adapter)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter", false]], "openvinoadapter (class in model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter", false]], "operations_by_type() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.operations_by_type", false]], "outputs (model_api.models.model.model attribute)": [[18, "model_api.models.model.Model.outputs", false]], "outputtransform (class in model_api.models.utils)": [[23, "model_api.models.utils.OutputTransform", false]], "ovmsadapter (class in model_api.adapters.ovms_adapter)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter", false]], "parameters() (model_api.models.action_classification.actionclassificationmodel class method)": [[10, "model_api.models.action_classification.ActionClassificationModel.parameters", false]], "parameters() (model_api.models.anomaly.anomalydetection class method)": [[11, "model_api.models.anomaly.AnomalyDetection.parameters", false]], "parameters() (model_api.models.classification.classificationmodel class method)": [[12, "model_api.models.classification.ClassificationModel.parameters", false]], "parameters() (model_api.models.detection_model.detectionmodel class method)": [[13, "model_api.models.detection_model.DetectionModel.parameters", false]], "parameters() (model_api.models.image_model.imagemodel class method)": [[14, "model_api.models.image_model.ImageModel.parameters", false]], "parameters() (model_api.models.instance_segmentation.maskrcnnmodel class method)": [[16, "model_api.models.instance_segmentation.MaskRCNNModel.parameters", false]], "parameters() (model_api.models.keypoint_detection.keypointdetectionmodel class method)": [[17, "model_api.models.keypoint_detection.KeypointDetectionModel.parameters", false]], "parameters() (model_api.models.model.model class method)": [[18, "model_api.models.model.Model.parameters", false]], "parameters() (model_api.models.sam_models.samdecoder class method)": [[19, "model_api.models.sam_models.SAMDecoder.parameters", false]], "parameters() (model_api.models.sam_models.samimageencoder class method)": [[19, "model_api.models.sam_models.SAMImageEncoder.parameters", false]], "parameters() (model_api.models.segmentation.segmentationmodel class method)": [[20, "model_api.models.segmentation.SegmentationModel.parameters", false]], "parameters() (model_api.models.yolo.yolo class method)": [[25, "model_api.models.yolo.YOLO.parameters", false]], "parameters() (model_api.models.yolo.yolof class method)": [[25, "model_api.models.yolo.YOLOF.parameters", false]], "parameters() (model_api.models.yolo.yolov3onnx class method)": [[25, "model_api.models.yolo.YoloV3ONNX.parameters", false]], "parameters() (model_api.models.yolo.yolov4 class method)": [[25, "model_api.models.yolo.YoloV4.parameters", false]], "parameters() (model_api.models.yolo.yolov5 class method)": [[25, "model_api.models.yolo.YOLOv5.parameters", false]], "parameters() (model_api.models.yolo.yolox class method)": [[25, "model_api.models.yolo.YOLOX.parameters", false]], "parameters() (model_api.tilers.detection.detectiontiler class method)": [[28, "model_api.tilers.detection.DetectionTiler.parameters", false]], "parameters() (model_api.tilers.tiler.tiler class method)": [[32, "model_api.tilers.tiler.Tiler.parameters", false]], "parse_devices() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.parse_devices", false]], "parse_layouts() (model_api.adapters.utils.layout static method)": [[5, "model_api.adapters.utils.Layout.parse_layouts", false]], "parse_model_arg() (model_api.adapters.ovms_adapter.ovmsadapter static method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.parse_model_arg", false]], "parse_value_per_device() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.parse_value_per_device", false]], "permute_to_n_hwa_k() (in module model_api.models.yolo)": [[25, "model_api.models.yolo.permute_to_N_HWA_K", false]], "postprocess() (model_api.models.action_classification.actionclassificationmodel method)": [[10, "model_api.models.action_classification.ActionClassificationModel.postprocess", false]], "postprocess() (model_api.models.anomaly.anomalydetection method)": [[11, "model_api.models.anomaly.AnomalyDetection.postprocess", false]], "postprocess() (model_api.models.classification.classificationmodel method)": [[12, "model_api.models.classification.ClassificationModel.postprocess", false]], "postprocess() (model_api.models.instance_segmentation.maskrcnnmodel method)": [[16, "model_api.models.instance_segmentation.MaskRCNNModel.postprocess", false]], "postprocess() (model_api.models.keypoint_detection.keypointdetectionmodel method)": [[17, "model_api.models.keypoint_detection.KeypointDetectionModel.postprocess", false]], "postprocess() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.postprocess", false]], "postprocess() (model_api.models.sam_models.samdecoder method)": [[19, "model_api.models.sam_models.SAMDecoder.postprocess", false]], "postprocess() (model_api.models.sam_models.samimageencoder method)": [[19, "model_api.models.sam_models.SAMImageEncoder.postprocess", false]], "postprocess() (model_api.models.segmentation.segmentationmodel method)": [[20, "model_api.models.segmentation.SegmentationModel.postprocess", false]], "postprocess() (model_api.models.ssd.ssd method)": [[21, "model_api.models.ssd.SSD.postprocess", false]], "postprocess() (model_api.models.yolo.yolo method)": [[25, "model_api.models.yolo.YOLO.postprocess", false]], "postprocess() (model_api.models.yolo.yolov3onnx method)": [[25, "model_api.models.yolo.YoloV3ONNX.postprocess", false]], "postprocess() (model_api.models.yolo.yolov5 method)": [[25, "model_api.models.yolo.YOLOv5.postprocess", false]], "postprocess() (model_api.models.yolo.yolox method)": [[25, "model_api.models.yolo.YOLOX.postprocess", false]], "precision (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.precision", false]], "precisions (model_api.adapters.inference_adapter.inferenceadapter attribute)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.precisions", false]], "predict() (model_api.models.keypoint_detection.topdownkeypointdetectionpipeline method)": [[17, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline.predict", false]], "predict_crops() (model_api.models.keypoint_detection.topdownkeypointdetectionpipeline method)": [[17, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline.predict_crops", false]], "preprocess() (model_api.models.action_classification.actionclassificationmodel method)": [[10, "model_api.models.action_classification.ActionClassificationModel.preprocess", false]], "preprocess() (model_api.models.anomaly.anomalydetection method)": [[11, "model_api.models.anomaly.AnomalyDetection.preprocess", false]], "preprocess() (model_api.models.image_model.imagemodel method)": [[14, "model_api.models.image_model.ImageModel.preprocess", false]], "preprocess() (model_api.models.instance_segmentation.maskrcnnmodel method)": [[16, "model_api.models.instance_segmentation.MaskRCNNModel.preprocess", false]], "preprocess() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.preprocess", false]], "preprocess() (model_api.models.sam_models.samdecoder method)": [[19, "model_api.models.sam_models.SAMDecoder.preprocess", false]], "preprocess() (model_api.models.sam_models.samimageencoder method)": [[19, "model_api.models.sam_models.SAMImageEncoder.preprocess", false]], "preprocess() (model_api.models.ssd.ssd method)": [[21, "model_api.models.ssd.SSD.preprocess", false]], "preprocess() (model_api.models.yolo.yolov3onnx method)": [[25, "model_api.models.yolo.YoloV3ONNX.preprocess", false]], "preprocess() (model_api.models.yolo.yolox method)": [[25, "model_api.models.yolo.YOLOX.preprocess", false]], "probabilisticlabelsresolver (class in model_api.models.classification)": [[12, "model_api.models.classification.ProbabilisticLabelsResolver", false]], "prompt (class in model_api.models.visual_prompting)": [[24, "model_api.models.visual_prompting.Prompt", false]], "raise_error() (model_api.models.model.model class method)": [[18, "model_api.models.model.Model.raise_error", false]], "reference_features (model_api.models.visual_prompting.samlearnablevisualprompter property)": [[24, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.reference_features", false]], "reset_reference_info() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[24, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.reset_reference_info", false]], "reshape() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.reshape", false]], "reshape_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.reshape_model", false]], "resize (model_api.models.action_classification.actionclassificationmodel attribute)": [[10, "model_api.models.action_classification.ActionClassificationModel.resize", false]], "resize (model_api.models.image_model.imagemodel attribute)": [[14, "model_api.models.image_model.ImageModel.resize", false]], "resize() (model_api.models.utils.outputtransform method)": [[23, "model_api.models.utils.OutputTransform.resize", false]], "resize_image() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image", false]], "resize_image_graph() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image_graph", false]], "resize_image_letterbox() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image_letterbox", false]], "resize_image_letterbox_graph() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image_letterbox_graph", false]], "resize_image_letterbox_ocv() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image_letterbox_ocv", false]], "resize_image_ocv() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image_ocv", false]], "resize_image_with_aspect() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image_with_aspect", false]], "resize_image_with_aspect_ocv() (in module model_api.adapters.utils)": [[5, "model_api.adapters.utils.resize_image_with_aspect_ocv", false]], "resize_type (model_api.models.action_classification.actionclassificationmodel attribute)": [[10, "model_api.models.action_classification.ActionClassificationModel.resize_type", false]], "resize_type (model_api.models.image_model.imagemodel attribute)": [[14, "model_api.models.image_model.ImageModel.resize_type", false]], "resolve_labels() (model_api.models.classification.greedylabelsresolver method)": [[12, "model_api.models.classification.GreedyLabelsResolver.resolve_labels", false]], "resolve_labels() (model_api.models.classification.probabilisticlabelsresolver method)": [[12, "model_api.models.classification.ProbabilisticLabelsResolver.resolve_labels", false]], "samdecoder (class in model_api.models.sam_models)": [[19, "model_api.models.sam_models.SAMDecoder", false]], "samimageencoder (class in model_api.models.sam_models)": [[19, "model_api.models.sam_models.SAMImageEncoder", false]], "samlearnablevisualprompter (class in model_api.models.visual_prompting)": [[24, "model_api.models.visual_prompting.SAMLearnableVisualPrompter", false]], "samvisualprompter (class in model_api.models.visual_prompting)": [[24, "model_api.models.visual_prompting.SAMVisualPrompter", false]], "save() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.save", false]], "save_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.save_model", false]], "save_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.save_model", false]], "save_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.save_model", false]], "save_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.save_model", false]], "scale() (model_api.models.utils.outputtransform method)": [[23, "model_api.models.utils.OutputTransform.scale", false]], "segmentationmodel (class in model_api.models.segmentation)": [[20, "model_api.models.segmentation.SegmentationModel", false]], "semanticsegmentationtiler (class in model_api.tilers.semantic_segmentation)": [[31, "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler", false]], "set_callback() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.set_callback", false]], "set_callback() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.set_callback", false]], "set_callback() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.set_callback", false]], "set_callback() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.set_callback", false]], "set_callback() (model_api.models.model.model method)": [[18, "model_api.models.model.Model.set_callback", false]], "set_strides_grids() (model_api.models.yolo.yolox method)": [[25, "model_api.models.yolo.YOLOX.set_strides_grids", false]], "shape (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.shape", false]], "sigmoid() (in module model_api.models.yolo)": [[25, "model_api.models.yolo.sigmoid", false]], "sigmoid_numpy() (in module model_api.models.classification)": [[12, "model_api.models.classification.sigmoid_numpy", false]], "simplelabelsgraph (class in model_api.models.classification)": [[12, "model_api.models.classification.SimpleLabelsGraph", false]], "singleoutputparser (class in model_api.models.ssd)": [[21, "model_api.models.ssd.SingleOutputParser", false]], "softmax() (in module model_api.models.utils)": [[23, "model_api.models.utils.softmax", false]], "ssd (class in model_api.models.ssd)": [[21, "model_api.models.ssd.SSD", false]], "stringvalue (class in model_api.models.types)": [[22, "model_api.models.types.StringValue", false]], "submit_data() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[26, "model_api.pipelines.async_pipeline.AsyncPipeline.submit_data", false]], "tiler (class in model_api.tilers.tiler)": [[32, "model_api.tilers.tiler.Tiler", false]], "topdownkeypointdetectionpipeline (class in model_api.models.keypoint_detection)": [[17, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline", false]], "topological_sort() (model_api.models.classification.simplelabelsgraph method)": [[12, "model_api.models.classification.SimpleLabelsGraph.topological_sort", false]], "type (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.type", false]], "update_default_value() (model_api.models.types.basevalue method)": [[22, "model_api.models.types.BaseValue.update_default_value", false]], "update_model_info() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[4, "model_api.adapters.ovms_adapter.OVMSAdapter.update_model_info", false]], "used_indices (model_api.models.visual_prompting.visualpromptingfeatures attribute)": [[24, "model_api.models.visual_prompting.VisualPromptingFeatures.used_indices", false]], "validate() (model_api.models.types.basevalue method)": [[22, "model_api.models.types.BaseValue.validate", false]], "validate() (model_api.models.types.booleanvalue method)": [[22, "model_api.models.types.BooleanValue.validate", false]], "validate() (model_api.models.types.dictvalue method)": [[22, "model_api.models.types.DictValue.validate", false]], "validate() (model_api.models.types.listvalue method)": [[22, "model_api.models.types.ListValue.validate", false]], "validate() (model_api.models.types.numericalvalue method)": [[22, "model_api.models.types.NumericalValue.validate", false]], "validate() (model_api.models.types.stringvalue method)": [[22, "model_api.models.types.StringValue.validate", false]], "visualpromptingfeatures (class in model_api.models.visual_prompting)": [[24, "model_api.models.visual_prompting.VisualPromptingFeatures", false]], "w (model_api.models.yolo.detectionbox attribute)": [[25, "model_api.models.yolo.DetectionBox.w", false]], "wrappererror": [[18, "model_api.models.model.WrapperError", false]], "x (model_api.models.yolo.detectionbox attribute)": [[25, "model_api.models.yolo.DetectionBox.x", false]], "xywh2xyxy() (in module model_api.models.yolo)": [[25, "model_api.models.yolo.xywh2xyxy", false]], "y (model_api.models.yolo.detectionbox attribute)": [[25, "model_api.models.yolo.DetectionBox.y", false]], "yolo (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YOLO", false]], "yolo.params (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YOLO.Params", false]], "yolof (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YOLOF", false]], "yolof.params (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YOLOF.Params", false]], "yolov3onnx (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YoloV3ONNX", false]], "yolov4 (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YoloV4", false]], "yolov4.params (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YoloV4.Params", false]], "yolov5 (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YOLOv5", false]], "yolov8 (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YOLOv8", false]], "yolox (class in model_api.models.yolo)": [[25, "model_api.models.yolo.YOLOX", false]]}, "objects": {"model_api.adapters": [[1, 0, 0, "-", "inference_adapter"], [2, 0, 0, "-", "onnx_adapter"], [3, 0, 0, "-", "openvino_adapter"], [4, 0, 0, "-", "ovms_adapter"], [5, 0, 0, "-", "utils"]], "model_api.adapters.inference_adapter": [[1, 1, 1, "", "InferenceAdapter"], [1, 1, 1, "", "Metadata"]], "model_api.adapters.inference_adapter.InferenceAdapter": [[1, 2, 1, "", "await_all"], [1, 2, 1, "", "await_any"], [1, 2, 1, "", "embed_preprocessing"], [1, 2, 1, "", "get_input_layers"], [1, 2, 1, "", "get_model"], [1, 2, 1, "", "get_output_layers"], [1, 2, 1, "", "get_raw_result"], [1, 2, 1, "", "get_rt_info"], [1, 2, 1, "", "infer_async"], [1, 2, 1, "", "infer_sync"], [1, 2, 1, "", "is_ready"], [1, 2, 1, "", "load_model"], [1, 3, 1, "", "precisions"], [1, 2, 1, "", "reshape_model"], [1, 2, 1, "", "save_model"], [1, 2, 1, "", "set_callback"], [1, 2, 1, "", "update_model_info"]], "model_api.adapters.inference_adapter.Metadata": [[1, 3, 1, "", "layout"], [1, 3, 1, "", "meta"], [1, 3, 1, "", "names"], [1, 3, 1, "", "precision"], [1, 3, 1, "", "shape"], [1, 3, 1, "", "type"]], "model_api.adapters.onnx_adapter": [[2, 1, 1, "", "ONNXRuntimeAdapter"], [2, 4, 1, "", "change_layout"], [2, 4, 1, "", "get_shape_from_onnx"]], "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter": [[2, 2, 1, "", "await_all"], [2, 2, 1, "", "await_any"], [2, 2, 1, "", "embed_preprocessing"], [2, 2, 1, "", "get_input_layers"], [2, 2, 1, "", "get_model"], [2, 2, 1, "", "get_output_layers"], [2, 2, 1, "", "get_raw_result"], [2, 2, 1, "", "get_rt_info"], [2, 2, 1, "", "infer_async"], [2, 2, 1, "", "infer_sync"], [2, 2, 1, "", "is_ready"], [2, 2, 1, "", "load_model"], [2, 2, 1, "", "reshape_model"], [2, 2, 1, "", "save_model"], [2, 2, 1, "", "set_callback"], [2, 2, 1, "", "update_model_info"]], "model_api.adapters.openvino_adapter": [[3, 1, 1, "", "OpenvinoAdapter"], [3, 4, 1, "", "create_core"], [3, 4, 1, "", "get_input_shape"], [3, 4, 1, "", "get_user_config"], [3, 4, 1, "", "parse_devices"], [3, 4, 1, "", "parse_value_per_device"]], "model_api.adapters.openvino_adapter.OpenvinoAdapter": [[3, 2, 1, "", "await_all"], [3, 2, 1, "", "await_any"], [3, 2, 1, "", "copy_raw_result"], [3, 2, 1, "", "embed_preprocessing"], [3, 2, 1, "", "get_input_layers"], [3, 2, 1, "", "get_layout_for_input"], [3, 2, 1, "", "get_model"], [3, 2, 1, "", "get_output_layers"], [3, 2, 1, "", "get_raw_result"], [3, 2, 1, "", "get_rt_info"], [3, 2, 1, "", "infer_async"], [3, 2, 1, "", "infer_sync"], [3, 2, 1, "", "is_ready"], [3, 2, 1, "", "load_model"], [3, 2, 1, "", "log_runtime_settings"], [3, 2, 1, "", "operations_by_type"], [3, 2, 1, "", "reshape_model"], [3, 2, 1, "", "save_model"], [3, 2, 1, "", "set_callback"], [3, 2, 1, "", "update_model_info"]], "model_api.adapters.ovms_adapter": [[4, 1, 1, "", "OVMSAdapter"]], "model_api.adapters.ovms_adapter.OVMSAdapter": [[4, 2, 1, "", "await_all"], [4, 2, 1, "", "await_any"], [4, 2, 1, "", "embed_preprocessing"], [4, 2, 1, "", "get_input_layers"], [4, 2, 1, "", "get_model"], [4, 2, 1, "", "get_output_layers"], [4, 2, 1, "", "get_raw_result"], [4, 2, 1, "", "get_rt_info"], [4, 2, 1, "", "infer_async"], [4, 2, 1, "", "infer_sync"], [4, 2, 1, "", "is_ovms_model"], [4, 2, 1, "", "is_ready"], [4, 2, 1, "", "load_model"], [4, 2, 1, "", "parse_model_arg"], [4, 2, 1, "", "reshape_model"], [4, 2, 1, "", "save_model"], [4, 2, 1, "", "set_callback"], [4, 2, 1, "", "update_model_info"]], "model_api.adapters.utils": [[5, 1, 1, "", "InputTransform"], [5, 1, 1, "", "Layout"], [5, 4, 1, "", "crop_resize"], [5, 4, 1, "", "crop_resize_graph"], [5, 4, 1, "", "crop_resize_ocv"], [5, 4, 1, "", "get_rt_info_from_dict"], [5, 4, 1, "", "load_parameters_from_onnx"], [5, 4, 1, "", "resize_image"], [5, 4, 1, "", "resize_image_graph"], [5, 4, 1, "", "resize_image_letterbox"], [5, 4, 1, "", "resize_image_letterbox_graph"], [5, 4, 1, "", "resize_image_letterbox_ocv"], [5, 4, 1, "", "resize_image_ocv"], [5, 4, 1, "", "resize_image_with_aspect"], [5, 4, 1, "", "resize_image_with_aspect_ocv"]], "model_api.adapters.utils.InputTransform": [[5, 2, 1, "", "__call__"]], "model_api.adapters.utils.Layout": [[5, 2, 1, "", "from_openvino"], [5, 2, 1, "", "from_shape"], [5, 2, 1, "", "from_user_layouts"], [5, 2, 1, "", "parse_layouts"]], "model_api.models": [[10, 0, 0, "-", "action_classification"], [11, 0, 0, "-", "anomaly"], [12, 0, 0, "-", "classification"], [13, 0, 0, "-", "detection_model"], [14, 0, 0, "-", "image_model"], [16, 0, 0, "-", "instance_segmentation"], [17, 0, 0, "-", "keypoint_detection"], [18, 0, 0, "-", "model"], [19, 0, 0, "-", "sam_models"], [20, 0, 0, "-", "segmentation"], [21, 0, 0, "-", "ssd"], [22, 0, 0, "-", "types"], [23, 0, 0, "-", "utils"], [24, 0, 0, "-", "visual_prompting"], [25, 0, 0, "-", "yolo"]], "model_api.models.action_classification": [[10, 1, 1, "", "ActionClassificationModel"]], "model_api.models.action_classification.ActionClassificationModel": [[10, 5, 1, "", "clip_size"], [10, 3, 1, "", "image_blob_name"], [10, 3, 1, "", "image_blob_names"], [10, 3, 1, "", "input_transform"], [10, 2, 1, "", "parameters"], [10, 2, 1, "", "postprocess"], [10, 2, 1, "", "preprocess"], [10, 3, 1, "", "resize"], [10, 3, 1, "", "resize_type"]], "model_api.models.anomaly": [[11, 1, 1, "", "AnomalyDetection"]], "model_api.models.anomaly.AnomalyDetection": [[11, 2, 1, "", "parameters"], [11, 2, 1, "", "postprocess"], [11, 2, 1, "", "preprocess"]], "model_api.models.classification": [[12, 1, 1, "", "ClassificationModel"], [12, 1, 1, "", "GreedyLabelsResolver"], [12, 1, 1, "", "ProbabilisticLabelsResolver"], [12, 1, 1, "", "SimpleLabelsGraph"], [12, 4, 1, "", "addOrFindSoftmaxAndTopkOutputs"], [12, 4, 1, "", "sigmoid_numpy"]], "model_api.models.classification.ClassificationModel": [[12, 2, 1, "", "get_all_probs"], [12, 2, 1, "", "get_hierarchical_predictions"], [12, 2, 1, "", "get_multiclass_predictions"], [12, 2, 1, "", "get_multilabel_predictions"], [12, 2, 1, "", "get_saliency_maps"], [12, 2, 1, "", "parameters"], [12, 2, 1, "", "postprocess"]], "model_api.models.classification.GreedyLabelsResolver": [[12, 2, 1, "", "resolve_labels"]], "model_api.models.classification.ProbabilisticLabelsResolver": [[12, 2, 1, "", "resolve_labels"]], "model_api.models.classification.SimpleLabelsGraph": [[12, 2, 1, "", "add_edge"], [12, 2, 1, "", "clear_topological_cache"], [12, 2, 1, "", "get_ancestors"], [12, 2, 1, "", "get_children"], [12, 2, 1, "", "get_labels_in_topological_order"], [12, 2, 1, "", "get_parent"], [12, 2, 1, "", "topological_sort"]], "model_api.models.detection_model": [[13, 1, 1, "", "DetectionModel"]], "model_api.models.detection_model.DetectionModel": [[13, 2, 1, "", "parameters"]], "model_api.models.image_model": [[14, 1, 1, "", "ImageModel"]], "model_api.models.image_model.ImageModel": [[14, 2, 1, "", "get_label_name"], [14, 3, 1, "", "image_blob_name"], [14, 3, 1, "", "image_blob_names"], [14, 3, 1, "", "image_info_blob_names"], [14, 3, 1, "", "input_transform"], [14, 3, 1, "", "nchw_layout"], [14, 2, 1, "", "parameters"], [14, 2, 1, "", "preprocess"], [14, 3, 1, "", "resize"], [14, 3, 1, "", "resize_type"]], "model_api.models.instance_segmentation": [[16, 1, 1, "", "MaskRCNNModel"]], "model_api.models.instance_segmentation.MaskRCNNModel": [[16, 2, 1, "", "parameters"], [16, 2, 1, "", "postprocess"], [16, 2, 1, "", "preprocess"]], "model_api.models.keypoint_detection": [[17, 1, 1, "", "KeypointDetectionModel"], [17, 1, 1, "", "TopDownKeypointDetectionPipeline"]], "model_api.models.keypoint_detection.KeypointDetectionModel": [[17, 2, 1, "", "parameters"], [17, 2, 1, "", "postprocess"]], "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline": [[17, 2, 1, "", "predict"], [17, 2, 1, "", "predict_crops"]], "model_api.models.model": [[18, 1, 1, "", "Model"], [18, 6, 1, "", "WrapperError"]], "model_api.models.model.Model": [[18, 2, 1, "", "__call__"], [18, 2, 1, "", "available_wrappers"], [18, 2, 1, "", "await_all"], [18, 2, 1, "", "await_any"], [18, 2, 1, "", "create_model"], [18, 2, 1, "", "detect_model_type"], [18, 2, 1, "", "get_model"], [18, 2, 1, "", "get_model_class"], [18, 2, 1, "", "get_performance_metrics"], [18, 2, 1, "", "get_subclasses"], [18, 2, 1, "", "infer_async"], [18, 2, 1, "", "infer_async_raw"], [18, 2, 1, "", "infer_batch"], [18, 2, 1, "", "infer_sync"], [18, 3, 1, "", "inference_adapter"], [18, 3, 1, "", "inputs"], [18, 2, 1, "", "is_ready"], [18, 2, 1, "", "load"], [18, 2, 1, "", "log_layers_info"], [18, 3, 1, "", "logger"], [18, 3, 1, "", "model_loaded"], [18, 3, 1, "", "outputs"], [18, 2, 1, "", "parameters"], [18, 2, 1, "", "postprocess"], [18, 2, 1, "", "preprocess"], [18, 2, 1, "", "raise_error"], [18, 2, 1, "", "reshape"], [18, 2, 1, "", "save"], [18, 2, 1, "", "set_callback"]], "model_api.models.sam_models": [[19, 1, 1, "", "SAMDecoder"], [19, 1, 1, "", "SAMImageEncoder"]], "model_api.models.sam_models.SAMDecoder": [[19, 2, 1, "", "apply_coords"], [19, 2, 1, "", "parameters"], [19, 2, 1, "", "postprocess"], [19, 2, 1, "", "preprocess"]], "model_api.models.sam_models.SAMImageEncoder": [[19, 2, 1, "", "parameters"], [19, 2, 1, "", "postprocess"], [19, 2, 1, "", "preprocess"]], "model_api.models.segmentation": [[20, 1, 1, "", "SegmentationModel"], [20, 4, 1, "", "create_hard_prediction_from_soft_prediction"]], "model_api.models.segmentation.SegmentationModel": [[20, 2, 1, "", "get_contours"], [20, 2, 1, "", "parameters"], [20, 2, 1, "", "postprocess"]], "model_api.models.ssd": [[21, 1, 1, "", "BoxesLabelsParser"], [21, 1, 1, "", "MultipleOutputParser"], [21, 1, 1, "", "SSD"], [21, 1, 1, "", "SingleOutputParser"], [21, 4, 1, "", "find_layer_by_name"]], "model_api.models.ssd.BoxesLabelsParser": [[21, 2, 1, "", "__call__"], [21, 2, 1, "", "find_layer_bboxes_output"]], "model_api.models.ssd.MultipleOutputParser": [[21, 2, 1, "", "__call__"]], "model_api.models.ssd.SSD": [[21, 2, 1, "", "postprocess"], [21, 2, 1, "", "preprocess"]], "model_api.models.ssd.SingleOutputParser": [[21, 2, 1, "", "__call__"]], "model_api.models.types": [[22, 1, 1, "", "BaseValue"], [22, 1, 1, "", "BooleanValue"], [22, 6, 1, "", "ConfigurableValueError"], [22, 1, 1, "", "DictValue"], [22, 1, 1, "", "ListValue"], [22, 1, 1, "", "NumericalValue"], [22, 1, 1, "", "StringValue"]], "model_api.models.types.BaseValue": [[22, 2, 1, "", "build_error"], [22, 2, 1, "", "get_value"], [22, 2, 1, "", "update_default_value"], [22, 2, 1, "", "validate"]], "model_api.models.types.BooleanValue": [[22, 2, 1, "", "from_str"], [22, 2, 1, "", "validate"]], "model_api.models.types.DictValue": [[22, 2, 1, "", "from_str"], [22, 2, 1, "", "validate"]], "model_api.models.types.ListValue": [[22, 2, 1, "", "from_str"], [22, 2, 1, "", "validate"]], "model_api.models.types.NumericalValue": [[22, 2, 1, "", "from_str"], [22, 2, 1, "", "validate"]], "model_api.models.types.StringValue": [[22, 2, 1, "", "from_str"], [22, 2, 1, "", "validate"]], "model_api.models.utils": [[23, 1, 1, "", "OutputTransform"], [23, 4, 1, "", "add_rotated_rects"], [23, 4, 1, "", "clip_detections"], [23, 4, 1, "", "get_contours"], [23, 4, 1, "", "load_labels"], [23, 4, 1, "", "multiclass_nms"], [23, 4, 1, "", "nms"], [23, 4, 1, "", "softmax"]], "model_api.models.utils.OutputTransform": [[23, 2, 1, "", "compute_resolution"], [23, 2, 1, "", "resize"], [23, 2, 1, "", "scale"]], "model_api.models.visual_prompting": [[24, 1, 1, "", "Prompt"], [24, 1, 1, "", "SAMLearnableVisualPrompter"], [24, 1, 1, "", "SAMVisualPrompter"], [24, 1, 1, "", "VisualPromptingFeatures"]], "model_api.models.visual_prompting.Prompt": [[24, 3, 1, "", "data"], [24, 3, 1, "", "label"]], "model_api.models.visual_prompting.SAMLearnableVisualPrompter": [[24, 2, 1, "", "__call__"], [24, 2, 1, "", "has_reference_features"], [24, 2, 1, "", "infer"], [24, 2, 1, "", "learn"], [24, 5, 1, "", "reference_features"], [24, 2, 1, "", "reset_reference_info"]], "model_api.models.visual_prompting.SAMVisualPrompter": [[24, 2, 1, "", "__call__"], [24, 2, 1, "", "infer"]], "model_api.models.visual_prompting.VisualPromptingFeatures": [[24, 3, 1, "", "feature_vectors"], [24, 3, 1, "", "used_indices"]], "model_api.models.yolo": [[25, 1, 1, "", "DetectionBox"], [25, 1, 1, "", "YOLO"], [25, 1, 1, "", "YOLOF"], [25, 1, 1, "", "YOLOX"], [25, 1, 1, "", "YOLOv5"], [25, 1, 1, "", "YOLOv8"], [25, 1, 1, "", "YoloV3ONNX"], [25, 1, 1, "", "YoloV4"], [25, 4, 1, "", "permute_to_N_HWA_K"], [25, 4, 1, "", "sigmoid"], [25, 4, 1, "", "xywh2xyxy"]], "model_api.models.yolo.DetectionBox": [[25, 3, 1, "", "h"], [25, 3, 1, "", "w"], [25, 3, 1, "", "x"], [25, 3, 1, "", "y"]], "model_api.models.yolo.YOLO": [[25, 1, 1, "", "Params"], [25, 2, 1, "", "parameters"], [25, 2, 1, "", "postprocess"]], "model_api.models.yolo.YOLOF": [[25, 1, 1, "", "Params"], [25, 2, 1, "", "parameters"]], "model_api.models.yolo.YOLOX": [[25, 2, 1, "", "parameters"], [25, 2, 1, "", "postprocess"], [25, 2, 1, "", "preprocess"], [25, 2, 1, "", "set_strides_grids"]], "model_api.models.yolo.YOLOv5": [[25, 2, 1, "", "parameters"], [25, 2, 1, "", "postprocess"]], "model_api.models.yolo.YoloV3ONNX": [[25, 2, 1, "", "parameters"], [25, 2, 1, "", "postprocess"], [25, 2, 1, "", "preprocess"]], "model_api.models.yolo.YoloV4": [[25, 1, 1, "", "Params"], [25, 2, 1, "", "parameters"]], "model_api.pipelines": [[26, 0, 0, "-", "async_pipeline"]], "model_api.pipelines.async_pipeline": [[26, 1, 1, "", "AsyncPipeline"]], "model_api.pipelines.async_pipeline.AsyncPipeline": [[26, 2, 1, "", "await_all"], [26, 2, 1, "", "await_any"], [26, 2, 1, "", "callback"], [26, 2, 1, "", "get_raw_result"], [26, 2, 1, "", "get_result"], [26, 2, 1, "", "is_ready"], [26, 2, 1, "", "submit_data"]], "model_api.tilers": [[28, 0, 0, "-", "detection"], [30, 0, 0, "-", "instance_segmentation"], [31, 0, 0, "-", "semantic_segmentation"], [32, 0, 0, "-", "tiler"]], "model_api.tilers.detection": [[28, 1, 1, "", "DetectionTiler"]], "model_api.tilers.detection.DetectionTiler": [[28, 2, 1, "", "parameters"]], "model_api.tilers.instance_segmentation": [[30, 1, 1, "", "InstanceSegmentationTiler"]], "model_api.tilers.instance_segmentation.InstanceSegmentationTiler": [[30, 2, 1, "", "__call__"]], "model_api.tilers.semantic_segmentation": [[31, 1, 1, "", "SemanticSegmentationTiler"]], "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler": [[31, 2, 1, "", "__call__"]], "model_api.tilers.tiler": [[32, 1, 1, "", "Tiler"]], "model_api.tilers.tiler.Tiler": [[32, 3, 1, "", "EXECUTION_MODES"], [32, 2, 1, "", "__call__"], [32, 3, 1, "", "async_pipeline"], [32, 3, 1, "", "execution_mode"], [32, 2, 1, "", "get_model"], [32, 3, 1, "", "model"], [32, 3, 1, "", "model_loaded"], [32, 2, 1, "", "parameters"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"], "5": ["py", "property", "Python property"], "6": ["py", "exception", "Python exception"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function", "5": "py:property", "6": "py:exception"}, "terms": {"": [1, 2, 3, 4, 7, 8, 10, 12, 14], "0": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25], "000": 8, "001": 8, "020": 8, "02643": 19, "09": 23, "1": [1, 3, 5, 7, 8, 10, 11, 12, 13, 14, 17, 18, 20, 21, 24, 25], "10": 8, "100": [8, 17], "114640": 11, "128": [1, 3], "134": 11, "138": 11, "150": 11, "1e": 23, "2": [8, 24, 25], "200": 23, "2304": 19, "255": 17, "2d": 14, "2f": 8, "3": [1, 3, 12, 13, 16, 20, 25], "3d": [2, 14, 16, 21, 25], "3f": 8, "45": 23, "497": 8, "4d": [10, 14], "5": [7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25], "50": 8, "556": 8, "570": 8, "572": 8, "6": 12, "60699755": 12, "642": 8, "65": 24, "6d": 10, "7": 12, "75": 8, "8536462108391619": 11, "85433626": 12, "90176445": 12, "A": [4, 10, 12, 13, 16, 17, 20, 24, 25], "For": [7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25], "If": [7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25], "In": [1, 2, 3, 4, 12, 30], "It": [10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 32], "No": 22, "Not": 2, "OR": 24, "One": [7, 10], "The": [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25, 32], "To": 24, "_": 8, "__call__": [5, 18, 21, 24, 30, 31, 32], "__main__": 8, "__name__": 8, "_description_": 18, "_merge_result": 32, "_postprocess_til": 32, "_resize_detect": 13, "ab": 19, "abc": [1, 32], "about": [1, 2, 3, 4, 17], "abstract": [1, 13, 14, 18, 32], "accept": [10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 28, 30, 31, 32], "access": [1, 7], "accord": [10, 14, 16, 19, 21, 24, 25], "accumul": 8, "accur": 20, "across": 8, "act": [2, 11, 17], "action": 15, "action_classif": 10, "actionclassificationmodel": 10, "activ": [12, 20], "actual": [1, 4, 8], "ad": 12, "adapt": [5, 9, 11, 12, 17, 18, 20], "adaptor_paramet": 18, "add": [1, 2, 4, 7, 8, 12, 23], "add_edg": 12, "add_rotated_rect": 23, "addit": [7, 8, 10, 14, 16, 21, 24, 25, 30], "addorfindsoftmaxandtopkoutput": 12, "address": 4, "affect": 7, "after": [1, 2, 3, 8], "agnost": 7, "agnostic_nm": 7, "aim": [11, 13, 16, 17], "alia": [24, 25], "align": 2, "all": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 14, 17, 18, 23, 24, 32], "all_output": 21, "allow": [2, 4, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 30], "alongsid": 18, "alreadi": [7, 24], "also": [1, 2, 3, 10, 12, 13, 14, 16, 18, 21, 25], "alwai": 8, "an": [1, 2, 3, 4, 7, 10, 11, 12, 13, 14, 16, 17, 18, 23, 24, 30, 32], "analyze_model_perform": 8, "ancestor": 12, "anchor": [7, 25], "ani": [1, 2, 3, 4, 5, 10, 11, 14, 17, 18, 19, 22, 32], "anomal": 7, "anomali": [7, 15], "anomalib": 11, "anomaly_map": 11, "anomalybas": 7, "anomalydetect": 11, "anomalymodel": 11, "anomalyresult": 11, "anoth": 10, "api": [8, 17, 18], "appli": [1, 4, 5, 7, 17, 18, 24, 30, 31, 32], "apply_coord": 19, "apply_masks_refin": 24, "approach": [12, 17], "appropri": [10, 11, 12, 14, 16, 17, 19, 20], "ar": [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 28, 31, 32], "architectur": 3, "arg": 2, "argument": [7, 24], "arrai": [2, 10, 11, 12, 14, 16, 20, 21, 25], "arriv": 24, "arxiv": 19, "aspect": 7, "aspect_ratio": 7, "assum": 20, "astyp": 17, "async": [1, 2, 3, 4, 18, 27, 28, 30, 31, 32], "async_pipelin": [26, 32], "asynchron": [1, 2, 3, 4, 18, 32], "asyncpipelin": [26, 32], "attent": 8, "attribut": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 28, 31, 32], "auto": [14, 18], "automat": 8, "aux": 24, "avail": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 25], "available_wrapp": 18, "awai": 24, "await_al": [1, 2, 3, 4, 18, 26], "await_ani": [1, 2, 3, 4, 18, 26], "axi": 23, "b": [1, 4, 17], "b0": 8, "backbon": 7, "background": 8, "base": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32], "base_model": 17, "basevalu": 22, "basic": [10, 12, 14, 16, 17, 21, 25], "basicconfig": 8, "batch": [10, 17], "bbox": 21, "bboxes_lay": 21, "becom": [1, 2, 3, 4], "befor": [2, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25], "being": [1, 4, 18, 32], "below": 10, "benchmark": 8, "between": [8, 20], "bgr": [10, 14, 16, 21, 25], "bgr2rgb": [1, 4], "bicycl": 12, "bin": [3, 18], "binari": 24, "block": [1, 2, 3, 4, 18], "blur": 7, "blur_strength": [7, 20], "bool": [1, 3, 4, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 32], "boolean": [1, 2, 3, 4], "booleanvalu": 22, "bound": [7, 13, 16, 21, 23, 24], "box": [7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25], "boxeslabelspars": 21, "breakdown": 8, "brg2rgb": [1, 2, 3, 4], "build_error": 22, "built": 8, "busi": [1, 2, 3, 4], "byte": 2, "c": 10, "cache_dir": [3, 18], "call": [4, 5, 18, 24, 30, 31, 32], "callabl": [1, 2, 3, 4, 5, 18], "callback": [1, 2, 3, 4, 18, 26], "callback_arg": 26, "callback_data": [1, 2, 3, 4, 18], "callback_fn": [1, 2, 3, 4, 18], "can": [1, 2, 3, 4, 8, 10, 17, 18, 20, 24, 30], "capabl": 8, "car": 12, "case": [1, 2, 3, 4, 12], "cat": 12, "center": 7, "chang": [2, 10, 11, 14, 16, 21, 25], "change_layout": 2, "channel": [1, 4, 7, 10, 14, 16, 21, 25], "check": [1, 2, 3, 4, 8, 18, 24], "child": 12, "children": 12, "choic": 22, "circl": 17, "class": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32], "class_id": 17, "classaif": 10, "classif": [7, 15, 17], "classifi": [7, 30], "classificationmodel": [2, 8, 12], "classificationresult": [10, 12], "classmethod": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25, 28, 32], "clear_topological_cach": 12, "clip": [10, 13, 23], "clip_detect": 23, "clip_siz": 10, "collect": [8, 18], "color": 17, "come": 17, "comma": 7, "compar": 8, "compil": 18, "complet": [1, 2, 3, 4, 18], "comprehens": 8, "compute_resolut": 23, "condit": 8, "conduct": 10, "confid": [7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25], "confidence_threshold": [7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25], "config": 18, "configur": [2, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 28, 30, 31, 32], "configurablevalueerror": 22, "consequ": 24, "consid": [7, 8], "consist": 8, "consol": 8, "construct": 7, "constructor": [1, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 28, 30, 31, 32], "construtor": [13, 21, 25], "contain": [1, 2, 3, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 28, 30, 31, 32], "contour": [20, 23], "control": [24, 28, 30, 31, 32], "convert": 19, "coord": 19, "coordin": 17, "copy_raw_result": 3, "core": [3, 18], "correspond": [1, 2, 10, 14, 17, 24], "count": 8, "cpu": [3, 18], "creat": [1, 2, 3, 5, 7, 8, 18, 20, 24, 25, 28, 30, 31, 32], "create_cor": 3, "create_hard_prediction_from_soft_predict": 20, "create_model": [7, 8, 11, 12, 13, 16, 17, 18, 20], "crop": [7, 10, 17], "crop_res": 5, "crop_resize_graph": 5, "crop_resize_ocv": 5, "current": [8, 11], "custom": [7, 18], "cv": 11, "cv2": [8, 11, 12, 13, 16, 17, 20], "d1": 17, "d2": 17, "data": [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 28, 30, 31, 32], "data_1": [1, 2, 3, 18], "data_2": [1, 2, 3, 18], "dataset": 7, "decod": [7, 17, 19, 24], "decoder_model": 24, "decor": 18, "def": 8, "default": [1, 3, 4, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25], "default_label": 21, "default_valu": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 25], "defin": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 28, 30, 31, 32], "definit": 11, "degrad": 17, "delta": 7, "depend": [18, 23, 32], "deploy": 8, "descript": [9, 10, 11, 14, 18, 19, 20, 22, 25, 28, 32], "destroyallwindow": 16, "det": 23, "detail": 18, "detect": [8, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 23, 25, 29], "detect_model_typ": 18, "detectedkeypoint": 17, "detection_model": 13, "detection_result": 17, "detectionbox": 25, "detectionmodel": [8, 13, 21, 25], "detectionresult": [13, 21, 23, 25, 28], "detectiontil": [28, 30], "detector": 17, "deviat": 8, "devic": [1, 2, 3, 4, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 32], "device1": 3, "device2": 3, "device_str": 3, "dict": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 28, 30, 31, 32], "dict_data": [1, 2, 3, 4, 18], "dictionari": [1, 3, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 28, 32], "dictvalu": 22, "differ": [3, 8, 10, 23], "directori": 18, "discover": 18, "disk": 1, "divid": [7, 10, 14, 16, 21, 25], "do": 23, "document": 18, "doesn": 2, "done": 2, "down": [12, 17], "download": 18, "download_dir": [3, 18], "dtype": [1, 2, 3, 4, 11, 12], "due": 8, "durat": 8, "dure": [7, 24], "e": 18, "each": [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24, 25, 30], "edg": 12, "efficientnet": 8, "emb": [1, 3, 4], "embed": [1, 4, 7, 17], "embed_preprocess": [1, 2, 3, 4], "embedded_process": 7, "enabl": [20, 24], "enable_pad": 7, "encod": [19, 24], "encoder_model": 24, "end": [1, 2, 3], "enough": [17, 23], "ensur": 8, "enumer": 8, "environ": 8, "ep": 23, "error": 18, "etc": [8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 28, 30, 31, 32], "even": 18, "everi": 8, "exampl": [10, 11, 12, 14, 18, 19, 20, 25], "except": [4, 18, 22, 24], "exclud": 8, "exclus": 12, "execut": [1, 2, 3, 4, 18, 24, 32], "execution_mod": [28, 30, 31, 32], "executor": [10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 32], "exist": 20, "expect": [4, 11, 21, 28, 30], "export": [11, 12, 20], "extend": [11, 12, 13, 14, 16, 19, 20, 21, 25], "extens": [2, 12, 16, 20], "extern": 2, "extra": [1, 4, 24], "f": [8, 13, 16], "factori": 1, "fail": [10, 11, 12, 14, 16, 19, 20], "fals": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25], "featur": [7, 12, 20, 24], "feature_vector": [12, 20, 24], "few": 8, "field": [7, 24, 25], "file": [2, 3, 7, 11, 18], "filenam": 2, "filesystem": [1, 2, 18], "filter": [7, 23, 30], "final": 20, "find": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25], "find_layer_bboxes_output": 21, "find_layer_by_nam": 21, "first": [7, 8, 10, 14, 24], "fit": [1, 2, 3, 10, 14, 16, 18, 21, 25], "fit_to_window": 7, "fit_to_window_letterbox": 7, "flag": [1, 2, 3, 4, 7, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 24, 25, 32], "flags_d": 3, "flags_nstream": 3, "flags_nthread": 3, "float": [7, 12, 20, 22, 23, 24], "float32": 11, "float64": 12, "follow": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25], "forc": [17, 18, 24], "format": [1, 2, 3, 4, 5, 7, 8, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 30, 31, 32], "forward": [2, 13, 16], "found": 20, "fp": 8, "fp16": [1, 3, 18], "fp32": 1, "framework": [1, 2, 3, 4], "free": [18, 32], "from": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 32], "from_openvino": 5, "from_shap": 5, "from_str": 22, "from_user_layout": 5, "full": [17, 30, 31, 32], "function": [1, 2, 3, 4, 5, 7, 10, 14], "g": 18, "gener": [2, 11, 14, 24], "get": [1, 2, 3, 4, 8, 10, 12], "get_all_prob": 12, "get_ancestor": 12, "get_children": 12, "get_contour": [20, 23], "get_fp": 8, "get_hierarchical_predict": 12, "get_inference_tim": 8, "get_input_lay": [1, 2, 3, 4], "get_input_shap": 3, "get_label_nam": 14, "get_labels_in_topological_ord": 12, "get_layout_for_input": 3, "get_load_tim": 8, "get_model": [1, 2, 3, 4, 18, 32], "get_model_class": 18, "get_multiclass_predict": 12, "get_multilabel_predict": 12, "get_output_lay": [1, 2, 3, 4], "get_par": 12, "get_performance_metr": [8, 18], "get_postprocess_tim": 8, "get_preprocess_tim": 8, "get_raw_result": [1, 2, 3, 4, 26], "get_result": 26, "get_rt_info": [1, 2, 3, 4], "get_rt_info_from_dict": 5, "get_saliency_map": 12, "get_shape_from_onnx": 2, "get_subclass": 18, "get_total_fram": 8, "get_total_tim": 8, "get_total_time_max": 8, "get_total_time_min": 8, "get_user_config": 3, "get_valu": 22, "getter": 32, "given": [3, 4, 5, 7, 10, 17, 18, 24], "go": 7, "gpu": 18, "grab": [1, 2, 3, 4, 18], "greater": 24, "greedi": 12, "greedylabelsresolv": 12, "group": 12, "grpcclient": 4, "h": [10, 12, 13, 16, 20, 24, 25], "ha": [1, 2, 3, 7, 10, 13, 14, 16, 18, 21, 25, 30], "handl": [1, 2, 3], "hard": [19, 20], "has_reference_featur": 24, "have": [7, 10, 13, 17], "height": [7, 10, 12, 13, 16, 20, 23], "help": 8, "hierarch": [7, 12], "hierarchi": 7, "hierarchical_config": [7, 12], "higher": 20, "hole": 20, "http": 19, "hwc": [2, 14, 16, 21, 24, 25], "hxwxa": 25, "i": [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 30, 31, 32], "i16": 1, "i32": 1, "i8": 1, "id": 26, "ident": 25, "identifi": 8, "idx": 23, "ignor": 3, "imag": [1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 23, 24, 25, 32], "image1": 8, "image2": 8, "image3": 8, "image_blob_nam": [10, 14], "image_info_blob_nam": 14, "image_model": 14, "image_path": 8, "image_shap": 7, "image_threshold": 7, "imagemodel": [11, 12, 13, 14, 16, 17, 19, 20, 21, 25, 30], "imageresultwithsoftpredict": 20, "imit": 4, "implement": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24, 25, 32], "impli": [1, 4, 24], "import": [8, 11, 12, 13, 16, 17, 20], "imread": [8, 11, 12, 20], "imshow": 16, "includ": [8, 12, 18, 23], "include_boundari": 23, "include_nested_contour": 20, "incorrect": 18, "independ": 23, "index": [1, 4, 14, 20], "indic": 23, "inf": 7, "infer": [0, 2, 3, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 28, 30, 31, 32], "infer_async": [1, 2, 3, 4, 18], "infer_async_raw": 18, "infer_batch": 18, "infer_result": [1, 2, 3, 4], "infer_sync": [1, 2, 3, 4, 18], "inference_adapt": [1, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25], "inference_tim": 8, "inferenceadapt": [1, 2, 3, 4, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25], "inferencesess": 2, "info": [1, 2, 3, 4, 5, 8, 10, 14, 17], "inform": [1, 2, 3, 4, 8, 17, 18, 24], "inherit": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25, 32], "initi": [4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25], "input": [1, 2, 3, 4, 5, 7, 8, 10, 11, 14, 18, 19, 21, 23, 24, 25, 26, 30, 31, 32], "input0": [5, 7], "input1": [5, 7], "input_data": 18, "input_idx": [1, 2, 3, 4], "input_layer_nam": [10, 14, 16, 21, 25], "input_layer_name_1": [1, 2, 3, 18], "input_layer_name_2": [1, 2, 3, 18], "input_nam": [5, 7], "input_s": [7, 21, 23], "input_tensor": 3, "input_transform": [10, 14], "inputtransform": [5, 10, 14], "inst_seg_result": 23, "insta": [1, 4], "instanc": [1, 3, 4, 7, 8, 10, 14, 15, 18, 24, 25, 29, 32], "instance_segment": [16, 30], "instancesegmentationresult": 16, "instancesegmentationtil": 30, "int": [1, 2, 3, 4, 7, 10, 14, 18, 20, 23, 24], "int32": 17, "interest": 17, "interfac": [1, 11, 12, 16, 18, 19, 20, 21, 25], "intermedi": 7, "intern": [1, 2, 3, 4, 24], "interpol": [1, 4, 5], "interpolation_mod": [1, 2, 3, 4], "intersect": 7, "introduc": 7, "iou": [7, 23], "iou_threshold": [7, 23], "ir": [3, 7], "ir_v10": 3, "is_ovms_model": 4, "is_pad": 5, "is_readi": [1, 2, 3, 4, 18, 26], "isn": [7, 10], "item": 17, "iter": [13, 16, 17], "jpg": [8, 11, 12, 20], "just": [1, 3, 4], "k": 25, "keep": [10, 14, 16, 18, 21, 25], "keep_aspect_ratio": 5, "keep_top_k": 23, "keepdim": 23, "kei": [1, 3, 18], "kept": 23, "kernel": 7, "keypoint": 15, "keypoint_detect": 17, "keypointdetectionmodel": 17, "kp_model": 17, "kwarg": 22, "label": [7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25], "label_fil": 23, "label_id": 14, "label_nam": [13, 16], "labels_lay": 21, "larg": 23, "last": 24, "later": 30, "launch": 24, "layer": [2, 4, 7, 14, 21], "layout": [1, 2, 3, 4, 5, 7, 10, 14, 16, 18, 21, 25], "layout_str": 5, "lead": [1, 2, 3], "learn": [12, 20, 24], "len": [7, 8], "less": 20, "letter": 10, "level": [7, 8], "like": [7, 10, 12, 14], "limit": 2, "list": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 30], "listvalu": 22, "load": [1, 2, 3, 4, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 32], "load_label": 23, "load_model": [1, 2, 3, 4, 18], "load_parameters_from_onnx": 5, "load_tim": 8, "locat": 17, "log_layers_info": 18, "log_metr": 8, "log_runtime_set": 3, "logger": [18, 32], "logit": [12, 20, 23], "lsit": 28, "mai": [8, 14], "map": [7, 12, 20, 24], "mask": [7, 16, 20, 24, 25], "maskrcnnmodel": [2, 16], "mat": 20, "match": [7, 12, 24], "max": [7, 8, 12, 22, 23], "max_answer_token_num": 7, "max_num": 23, "max_num_request": [3, 18], "maximum": [7, 8], "maxmium": 8, "mean": [1, 2, 3, 4, 7, 8, 10, 14, 16, 21, 24, 25], "mean_valu": [5, 7, 10], "measur": 8, "median": 8, "member": 7, "merg": 32, "messag": [8, 18, 22], "meta": [1, 2, 3, 10, 11, 12, 16, 17, 18, 19, 20, 21, 25, 26], "metadata": [1, 2, 3, 4, 10, 12, 14, 16, 18, 19, 20, 21, 25], "method": [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 32], "metric": 18, "might": [10, 14, 16, 18, 21, 25], "min": [7, 8, 22], "minim": 8, "minimum": [8, 20], "mode": [1, 4, 28, 30, 31, 32], "model": [1, 2, 3, 4, 8, 10, 11, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32], "model_adapt": 19, "model_api": [1, 2, 3, 4, 5, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32], "model_info": [1, 2, 3, 4, 7], "model_load": [18, 32], "model_nam": 4, "model_paramet": 3, "model_path": 8, "model_typ": [7, 18], "model_vers": 4, "modeladaptor": 18, "modelapi": 2, "modifi": 4, "modul": [1, 3, 4], "more": [8, 10, 13, 14, 16, 20, 21, 25], "most": [7, 12], "multi": [12, 23], "multiclass": [7, 12], "multiclass_nm": 23, "multilabel": 7, "multipl": [7, 8], "multipleoutputpars": 21, "must": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 32], "n": [8, 10, 17, 25], "n_label": 24, "name": [1, 2, 3, 7, 10, 12, 13, 14, 16, 17, 18, 21], "namedtupl": 24, "nc": [5, 7], "nchw": [1, 4, 5, 7, 14, 17], "nchw_layout": 14, "ndarrai": [2, 5, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25], "need": [1, 4], "nest": [1, 2], "network": [7, 20], "new": [1, 3, 7, 18, 24, 25], "new_shap": [1, 2, 3, 4, 18], "newli": 24, "next": 18, "nhwc": 14, "ninfer": 8, "nm": [7, 23], "node": 5, "non": [7, 12], "none": [1, 2, 3, 4, 5, 11, 12, 18, 22, 23, 24, 30], "nor": 7, "noreturn": 18, "normal": [1, 4, 7, 10, 14, 16, 21, 25], "normalization_scal": 7, "note": [7, 11, 21], "now": 8, "np": [11, 13, 16, 17, 19, 23, 24], "nscthw": 10, "nsthwc": 10, "nstream": 18, "nthread": 18, "num": 25, "num_class": [7, 20], "number": [7, 8, 10, 17, 18, 23, 24, 25], "numericalvalu": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 25], "numpi": 20, "obj_keypoint": 17, "object": [1, 3, 5, 12, 13, 16, 17, 18, 21, 22, 23, 24, 25, 26, 28, 30], "obtain": [12, 16, 18, 19, 20, 21, 24, 25], "occur": 18, "offset": 23, "onc": 24, "one": [1, 2, 3, 4, 7, 10, 14, 16, 17, 18, 21, 24, 25, 28, 30, 31, 32], "ones": [13, 18, 24], "onli": [2, 7, 10, 14, 16, 21, 23, 25], "onnx": 0, "onnx_adapt": 2, "onnx_model": 5, "onnx_shap": 2, "onnxruntim": 2, "onnxruntimeadapt": 2, "openvino": [0, 1, 2, 4, 5, 10, 11, 12, 18, 20], "openvino_adapt": 3, "openvinoadapt": [3, 18], "openvinotoolkit": 2, "oper": [10, 12, 24], "operation_typ": 3, "operations_by_typ": 3, "option": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25], "order": [7, 12, 23], "org": 19, "organ": 17, "orig_s": 19, "origin": [10, 11, 13, 14, 16, 19, 21, 25], "original_shap": [10, 14, 16, 21, 25], "ort_opt": 2, "other": [1, 7], "otx": [2, 7, 11], "out": [14, 24], "output": [1, 2, 3, 4, 7, 8, 10, 11, 18, 19, 21, 25, 28, 30], "output_layer_name_1": [1, 2, 3, 4, 12, 16, 18, 19, 20, 21, 25], "output_layer_name_2": [1, 2, 3, 4, 12, 16, 18, 19, 20, 21, 25], "output_layout": 25, "output_nam": 7, "output_raw_scor": [7, 12], "output_resolut": 23, "outputtransform": 23, "ov": [3, 17], "ovani": [3, 5], "over": [7, 8, 13, 16, 17], "overal": 8, "overlap": 23, "overload": [7, 10, 14, 16, 21, 25], "overrid": [7, 17], "overridden": 24, "ovm": [0, 18], "ovms_adapt": 4, "ovmsadapt": 4, "pad": [1, 4, 7], "pad_valu": [1, 2, 3, 4, 5, 7], "padding_mod": 7, "padim": 11, "pai": 8, "param": 25, "paramet": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 32], "parent": 12, "pars": [4, 5, 21], "parse_devic": 3, "parse_layout": 5, "parse_model_arg": 4, "parse_value_per_devic": 3, "particular": 2, "pass": [13, 16, 18, 24], "path": [1, 2, 3, 4, 5, 7, 8, 18], "path_to_imag": [11, 12, 20], "path_to_label": 7, "path_to_model": [11, 12, 20], "per": [7, 8, 17, 20, 23, 24], "perform": [1, 2, 3, 4, 10, 14, 16, 18, 21, 23, 25], "performancemetr": [8, 18], "period": 8, "permute_to_n_hwa_k": 25, "perspect": 17, "pipelin": [8, 9, 17, 24, 28, 30, 31, 32], "pixel": [7, 20], "pixel_threshold": 7, "place": 1, "plugin_config": 3, "point": [17, 20, 24], "polygon": 24, "popul": 3, "port": 4, "pose": 7, "possibl": [1, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25], "post": [10, 11], "postprocess": [7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 30, 31, 32], "postprocess_semantic_mask": 7, "postprocess_tim": 8, "pre": [7, 17], "precis": [1, 2, 3, 18], "pred_box": 11, "pred_i": 17, "pred_label": 11, "pred_mask": 11, "pred_scor": 11, "pred_x": 17, "predecessor": 12, "predict": [7, 11, 12, 13, 16, 17, 19, 20, 24, 30], "predict_crop": 17, "prefix": 22, "preload": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25], "prepar": [18, 24], "prepostprocessor": [3, 10], "preprocess": [1, 2, 4, 7, 8, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25], "preprocess_tim": 8, "preprocessed_imag": [10, 14, 16, 21, 25], "present": [17, 18, 24], "previou": 24, "previous": 24, "print": [8, 13, 16, 18], "prioriti": 7, "probabilisticlabelsresolv": 12, "probabl": [7, 12], "process": [7, 10, 11, 18, 19], "produc": 20, "product": 8, "progress": 8, "prompt": [15, 19], "prompter": 24, "properti": [10, 18, 24], "provid": [1, 2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 24, 25, 32], "py": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25], "python": [1, 4, 7, 17], "pytorch": 8, "qualiti": 17, "r": [1, 4], "radiu": 17, "rais": [4, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25], "raise_error": 18, "rang": [8, 11, 14], "ratio": 7, "raw": [1, 2, 3, 4, 7, 11, 12, 16, 17, 18, 19, 20, 21, 25, 30, 31, 32], "raw_result_1": [1, 2, 3, 4, 12, 16, 18, 19, 20, 21, 25], "raw_result_2": [1, 2, 3, 4, 12, 16, 18, 19, 20, 21, 25], "raw_scor": 12, "read": 1, "readi": 18, "reason": 10, "reduc": 18, "refer": [2, 4, 24], "reference_featur": 24, "refin": 24, "reflect": 24, "region": 7, "regress": 17, "reimplement": 25, "relat": 24, "remot": 4, "remov": 12, "reorder": 12, "report": 8, "repres": [3, 12, 17, 20, 24], "represent": [1, 2, 3, 4, 7, 17], "request": [1, 2, 3, 4, 18, 26], "reset": 8, "reset_featur": 24, "reset_reference_info": 24, "reshap": [1, 2, 3, 7, 18, 25], "reshape_model": [1, 2, 3, 4], "resiz": [1, 4, 7, 10, 13, 14, 16, 21, 23, 25], "resize_imag": 5, "resize_image_graph": 5, "resize_image_letterbox": [5, 7], "resize_image_letterbox_graph": 5, "resize_image_letterbox_ocv": 5, "resize_image_ocv": 5, "resize_image_with_aspect": 5, "resize_image_with_aspect_ocv": 5, "resize_mod": [1, 2, 3, 4], "resize_typ": [7, 10, 14], "resized_shap": [10, 14, 16, 21, 25], "resolut": 7, "resolv": 12, "resolve_label": 12, "respect": [12, 13, 16, 20], "result": [1, 2, 3, 4, 8, 11, 12, 13, 18, 20, 23, 24, 32], "resultimag": 20, "retriev": [4, 18], "return": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 31, 32], "return_soft_predict": 7, "revers": 7, "reverse_input_channel": [5, 7], "rgb": [10, 14, 16, 21, 25], "right": 24, "right_bottom": 7, "rotatedsegmentationresult": 23, "routin": 18, "rt": [3, 17], "rt_info": 7, "rt_info_dict": 5, "run": [2, 8, 18, 24], "salienc": [12, 20], "saliency_map": [12, 20], "sam": [15, 24], "sam_model": 19, "samdecod": [19, 24], "same": 24, "samimageencod": [19, 24], "samlearnablevisualprompt": 24, "samvisualprompt": 24, "save": [1, 2, 3, 18], "save_model": [1, 2, 3, 4], "scale": [1, 2, 3, 4, 7, 10, 14, 16, 21, 23, 25], "scale_valu": [5, 7], "scc": 17, "scope": 2, "score": [7, 12, 13, 16, 17, 21, 23, 30], "scoredlabel": 12, "scores_lay": 21, "scratch": 24, "search": 20, "second": 8, "secondari": 14, "section": 7, "see": [10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 25], "seg_result": 23, "segment": [7, 15, 24, 29], "segmentationmodel": [2, 19, 20], "segmentedobject": 30, "select": 12, "self": [5, 12], "semant": [29, 30], "semantic_segment": 31, "semanticsegmentationtil": 31, "separ": [1, 7, 16, 18], "sequenc": [1, 2, 7, 24], "serial": [1, 2, 3, 7, 18], "serv": 4, "server": 4, "session": 2, "set": [1, 2, 3, 4, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25, 28, 31, 32], "set_callback": [1, 2, 3, 4, 18], "set_strides_grid": 25, "shape": [1, 2, 3, 4, 5, 7, 11, 12, 13, 16, 18, 20, 24], "should": [1, 2, 3, 7, 10, 13, 14, 16, 18, 21, 24, 25], "shown": 18, "side": 25, "sigmoid": 25, "sigmoid_numpi": 12, "signific": 8, "simcc": 17, "similar": 32, "simpl": 17, "simplelabelsgraph": 12, "simplest": 8, "singl": [2, 10, 11, 12, 13, 14, 16, 17, 20, 21, 25], "singleoutputpars": 21, "size": [5, 7, 10, 14, 16, 17, 19, 21, 23, 25], "size_divisor": 7, "skip": [18, 24], "slower": 8, "smoother": 20, "so": [10, 23], "soft": [19, 20], "soft_predict": 20, "soft_threshold": [7, 20], "softmax": 23, "some": [1, 4], "sort": 8, "sourc": [4, 24], "specif": [1, 2, 3, 4, 8, 10, 11, 14, 18, 19, 21, 25, 28, 30, 31, 32], "specifi": [7, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25], "spent": 8, "squad": 7, "squad_ver": 7, "ssd": [2, 13, 15, 18], "stage": [8, 24], "standard": [7, 8], "start": [8, 24], "state": [8, 24], "static": [4, 5, 7, 21], "std": 8, "stddev": 8, "step": [1, 2, 4, 12], "stfpm": 11, "store": [1, 2, 4, 7, 18, 24], "str": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 22, 31, 32], "strategi": 23, "stream": 18, "strict": 20, "stricter": 24, "string": [2, 4, 7], "stringvalu": 22, "structur": [1, 2, 3, 18, 32], "stub": 4, "style": 2, "subclass": 18, "submiss": [1, 2, 3, 4], "submit": [1, 2, 3, 4, 18], "submit_data": 26, "subtract": [7, 10, 14, 16, 21, 25], "summari": 8, "support": [2, 10, 11, 12, 14, 16, 21, 25], "suppress": 7, "suquenc": 3, "swap": [1, 4], "switch": [10, 14, 16, 21, 25], "sync": [28, 30, 31, 32], "synchron": [1, 2, 3, 4, 18], "system": 8, "t": [2, 7, 10], "tag": [1, 2, 3], "take": 7, "taken": [1, 2, 3, 7, 12], "target": [1, 4], "target_model": 4, "target_s": 7, "target_shap": [1, 2, 3, 4], "task": 7, "tensor": [10, 14, 17, 25], "term": 25, "test": 8, "test_imag": 8, "test_run": 8, "than": [13, 21, 25], "thei": [1, 7, 12, 18], "them": 8, "thi": [1, 2, 4, 7, 8, 10, 11, 12, 17, 20, 28, 30], "thick": 17, "thread": 18, "thresh": 23, "threshold": [7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25], "through": 8, "thrown": 24, "tight": 17, "tile": [28, 30, 31, 32], "tile_classifier_model": 30, "tile_prob": 30, "tile_s": [28, 30, 31, 32], "tiler": [9, 28, 30, 31], "tiles_overlap": [28, 30, 31, 32], "time": [10, 18, 24], "todo": [0, 9, 15, 27, 29], "token": 7, "top": [2, 12, 17], "top_down_detector": 17, "top_down_pipelin": 17, "top_label": 12, "topdownkeypointdetectionpipelin": 17, "topk": [7, 12], "topological_sort": 12, "torchvis": 24, "total": 8, "total_fram": 8, "total_max_tim": 8, "total_min_tim": 8, "total_tim": 8, "train": [2, 7, 12, 20], "training_extens": 2, "transpos": 25, "tree": 12, "true": [7, 12, 18, 20, 24], "tupl": [1, 4, 12, 23, 24, 25], "two": [3, 7, 10, 12, 17], "type": [1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 28, 30, 31, 32], "typic": 11, "u8": 1, "uint8": 11, "ultralyt": 25, "under": [1, 2], "underli": [17, 18, 28, 30, 31, 32], "union": 7, "until": [1, 2, 3, 4], "updat": [1, 2, 4, 19, 24], "update_default_valu": 22, "update_model_info": [1, 2, 3, 4], "upgrad": 11, "upsampl": 7, "upsample_ratio": 7, "url": [4, 18], "us": [1, 2, 4, 7, 8, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 30], "usag": 24, "used_indic": 24, "user": 5, "user_data": 18, "user_layout": 5, "usual": 20, "util": [0, 15], "v": 24, "v2": 4, "valid": [4, 22], "valu": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 30, 31, 32], "value1": 3, "value2": 3, "value_typ": 22, "valueerror": 22, "values_str": 3, "variabl": 18, "vector": [12, 17, 20], "version": [1, 2, 3, 4, 7, 18], "vertic": 12, "via": [2, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 25], "video": 10, "view": 8, "visual": 15, "visual_prompt": 24, "visualpromptingfeatur": 24, "visualpromptingresult": 24, "vocab": 7, "vpt": 24, "w": [10, 12, 13, 16, 20, 24, 25], "wai": 8, "wait": [1, 2, 3, 4, 18], "waitkei": 16, "warmup_cach": 12, "warmup_run": 8, "we": [1, 4, 23], "weight": [1, 3, 18], "weights_path": [1, 2, 3, 4, 18], "well": 12, "what": 10, "when": [8, 11, 24], "where": [12, 13, 16, 17, 18, 20, 24], "whether": [1, 2, 3, 4, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25, 32], "which": [1, 2, 3, 7, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 24, 25, 28, 30, 31, 32], "while": [10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25], "width": [7, 10, 12, 13, 16, 20, 23], "within": 17, "without": 24, "work": [3, 4, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25], "workflow": 24, "would": [1, 4], "wrap": [3, 21], "wrapper": [2, 7, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 28, 30, 31, 32], "wrapper_nam": 18, "wrappererror": [10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 25], "wrappernam": 18, "write": [1, 2, 18], "x": [10, 12, 17, 24, 25], "x1": [13, 16, 23], "x2": [13, 16, 23], "x_max": 17, "x_min": 17, "xmax": 21, "xmin": 21, "xml": [3, 7, 8, 11, 12, 13, 16, 17, 20], "xy": 24, "xywh": 25, "xywh2xyxi": 25, "xyxi": 24, "y": [17, 25], "y1": [13, 16, 23], "y2": [13, 16, 23], "y_max": 17, "y_min": 17, "ymax": 21, "ymin": 21, "yolo": 15, "yolof": 25, "yolov3onnx": 25, "yolov4": 25, "yolov5": 25, "yolov8": 25, "yolox": 25, "you": 8, "your": 8, "zip": [13, 16], "zoo": 18, "zsl": 24, "zslvisualpromptingresult": 24}, "titles": ["Adapters", "Inference Adapter", "Onnx Adapter", "Openvino Adapter", "Ovms Adapter", "Utils", "Guides", "Model configuration", "Performance Metrics", "Model API Documentation", "Action Classification", "Anomaly", "Classification", "Detection Model", "Image Model", "Models", "Instance Segmentation", "Keypoint Detection", "Model", "Sam Models", "Segmentation", "Ssd", "Types", "Utils", "Visual Prompting", "Yolo", "Async Pipeline", "Pipelines", "Detection", "Tilers", "Instance Segmentation", "Semantic Segmentation", "Tiler"], "titleterms": {"access": 8, "action": 10, "actionclassificationmodel": 7, "adapt": [0, 1, 2, 3, 4], "advanc": 8, "analysi": 8, "analyz": 8, "anomali": 11, "anomalydetect": 7, "api": 9, "async": 26, "basic": 8, "batch": 8, "bert": 7, "bertquestionansw": 7, "best": 8, "bottleneck": 8, "classif": [10, 12], "classificationmodel": 7, "complet": 8, "configur": 7, "consider": 8, "ctpn": 7, "descript": [12, 13, 16, 17], "detail": 8, "detect": [13, 17, 28], "detectionmodel": 7, "document": 9, "dure": 8, "exampl": [8, 13, 16, 17], "facebox": 7, "frame": 8, "guid": 6, "hpeassociativeembed": 7, "imag": 14, "imagemodel": 7, "individu": 8, "infer": [1, 8], "input": [12, 13, 16, 17, 20], "instanc": [16, 30], "its": 7, "keypoint": 17, "list": 7, "log": 8, "maskrcnnmodel": 7, "metric": 8, "model": [7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20], "monitor": 8, "nanodet": 7, "onnx": 2, "openpos": 7, "openvino": [3, 13, 16, 17], "optim": 8, "output": [12, 13, 16, 17, 20], "overview": 8, "ovm": 4, "paramet": 17, "perform": 8, "pipelin": [26, 27], "practic": 8, "process": 8, "prompt": 24, "rate": 8, "refer": 9, "sam": 19, "segment": [16, 20, 30, 31], "segmentationmodel": 7, "semant": 31, "specif": [12, 13, 16, 17, 20], "ssd": 21, "statist": 8, "subclass": 7, "throughput": 8, "tiler": [29, 32], "time": 8, "tip": 8, "type": 22, "ultralightweightfacedetect": 7, "up": 8, "usag": 8, "util": [5, 23], "valu": 7, "visual": 24, "warm": 8, "yolo": [7, 25], "yolov4": 7, "yolov5": 7, "yolov8": 7, "yolox": 7}})