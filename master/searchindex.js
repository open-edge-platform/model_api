Search.setIndex({"alltitles": {"API Reference": [[8, "api-reference"]], "Accessing Performance Metrics": [[7, "accessing-performance-metrics"]], "Action Classification": [[9, null]], "ActionClassificationModel": [[6, "actionclassificationmodel"]], "Adapters": [[0, null]], "Advanced Usage": [[7, "advanced-usage"]], "Analyzing Bottlenecks": [[7, "analyzing-bottlenecks"]], "Anomaly": [[10, null]], "AnomalyDetection": [[6, "anomalydetection"]], "Async Pipeline": [[25, null]], "Basic Usage": [[7, "basic-usage"]], "Batch Processing Performance": [[7, "batch-processing-performance"]], "Bert and its subclasses": [[6, "bert-and-its-subclasses"]], "BertQuestionAnswering": [[6, "bertquestionanswering"]], "Best Practices": [[7, "best-practices"]], "CTPN": [[6, "ctpn"]], "Classification": [[11, null]], "ClassificationModel": [[6, "classificationmodel"]], "Description": [[11, "description"], [12, "description"], [15, "description"], [16, "description"]], "Detailed Metrics Access": [[7, "detailed-metrics-access"]], "Detection": [[27, null]], "Detection Model": [[12, null]], "DetectionModel and its subclasses": [[6, "detectionmodel-and-its-subclasses"]], "Example": [[12, "example"], [15, "example"], [16, "example"]], "Example: Complete Performance Analysis": [[7, "example-complete-performance-analysis"]], "FaceBoxes": [[6, "faceboxes"]], "Frame Rate and Throughput": [[7, "frame-rate-and-throughput"]], "Guides": [[5, null]], "HpeAssociativeEmbedding": [[6, "hpeassociativeembedding"]], "Image Model": [[13, null]], "ImageModel and its subclasses": [[6, "imagemodel-and-its-subclasses"]], "Individual Timing Statistics": [[7, "individual-timing-statistics"]], "Inference Adapter": [[1, null]], "Inputs": [[11, "inputs"], [12, "inputs"], [15, "inputs"], [16, "inputs"], [19, "inputs"]], "Instance Segmentation": [[15, null], [29, null]], "Keypoint Detection": [[16, null]], "List of values": [[6, "list-of-values"]], "Logging Performance Metrics": [[7, "logging-performance-metrics"]], "MaskRCNNModel": [[6, "maskrcnnmodel"]], "Model": [[17, null]], "Model API Documentation": [[8, null]], "Model Specifications": [[11, "model-specifications"], [19, "model-specifications"]], "Model configuration": [[6, null]], "Models": [[14, null], [16, "models"]], "NanoDet": [[6, "nanodet"]], "Onnx Adapter": [[2, null]], "OpenPose": [[6, "openpose"]], "OpenVINO Model Specifications": [[12, "openvino-model-specifications"], [15, "openvino-model-specifications"], [16, "openvino-model-specifications"]], "Openvino Adapter": [[3, null]], "Outputs": [[11, "outputs"], [12, "outputs"], [15, "outputs"], [16, "outputs"], [19, "outputs"]], "Overview": [[7, "overview"]], "Parameters": [[16, "parameters"]], "Performance Metrics": [[7, null]], "Performance Monitoring During Inference": [[7, "performance-monitoring-during-inference"]], "Performance Optimization Tips": [[7, "performance-optimization-tips"]], "Pipelines": [[26, null]], "Sam Models": [[18, null]], "Segmentation": [[19, null]], "SegmentationModel and its subclasses": [[6, "segmentationmodel-and-its-subclasses"]], "Semantic Segmentation": [[30, null]], "Ssd": [[20, null]], "Tiler": [[31, null]], "Tilers": [[28, null]], "Types": [[21, null]], "UltraLightweightFaceDetection": [[6, "ultralightweightfacedetection"]], "Utils": [[4, null], [22, null]], "Visual Prompting": [[23, null]], "Warm-up Considerations": [[7, "warm-up-considerations"]], "YOLO and its subclasses": [[6, "yolo-and-its-subclasses"]], "YOLOX": [[6, "yolox"]], "YOLOv5, YOLOv8": [[6, "yolov5-yolov8"]], "Yolo": [[24, null]], "YoloV4": [[6, "yolov4"]]}, "docnames": ["adapters/index", "adapters/inference_adapter", "adapters/onnx_adapter", "adapters/openvino_adapter", "adapters/utils", "guides/index", "guides/model-configuration", "guides/performance_metrics", "index", "models/action_classification", "models/anomaly", "models/classification", "models/detection_model", "models/image_model", "models/index", "models/instance_segmentation", "models/keypoint_detection", "models/model", "models/sam_models", "models/segmentation", "models/ssd", "models/types", "models/utils", "models/visual_prompting", "models/yolo", "pipelines/async_pipeline", "pipelines/index", "tilers/detection", "tilers/index", "tilers/instance_segmentation", "tilers/semantic_segmentation", "tilers/tiler"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["adapters/index.md", "adapters/inference_adapter.md", "adapters/onnx_adapter.md", "adapters/openvino_adapter.md", "adapters/utils.md", "guides/index.md", "guides/model-configuration.md", "guides/performance_metrics.md", "index.md", "models/action_classification.md", "models/anomaly.md", "models/classification.md", "models/detection_model.md", "models/image_model.md", "models/index.md", "models/instance_segmentation.md", "models/keypoint_detection.md", "models/model.md", "models/sam_models.md", "models/segmentation.md", "models/ssd.md", "models/types.md", "models/utils.md", "models/visual_prompting.md", "models/yolo.md", "pipelines/async_pipeline.md", "pipelines/index.md", "tilers/detection.md", "tilers/index.md", "tilers/instance_segmentation.md", "tilers/semantic_segmentation.md", "tilers/tiler.md"], "indexentries": {"__call__() (model_api.adapters.utils.inputtransform method)": [[4, "model_api.adapters.utils.InputTransform.__call__", false]], "__call__() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.__call__", false]], "__call__() (model_api.models.ssd.boxeslabelsparser method)": [[20, "model_api.models.ssd.BoxesLabelsParser.__call__", false]], "__call__() (model_api.models.ssd.multipleoutputparser method)": [[20, "model_api.models.ssd.MultipleOutputParser.__call__", false]], "__call__() (model_api.models.ssd.singleoutputparser method)": [[20, "model_api.models.ssd.SingleOutputParser.__call__", false]], "__call__() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[23, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.__call__", false]], "__call__() (model_api.models.visual_prompting.samvisualprompter method)": [[23, "model_api.models.visual_prompting.SAMVisualPrompter.__call__", false]], "__call__() (model_api.tilers.instance_segmentation.instancesegmentationtiler method)": [[29, "model_api.tilers.instance_segmentation.InstanceSegmentationTiler.__call__", false]], "__call__() (model_api.tilers.semantic_segmentation.semanticsegmentationtiler method)": [[30, "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler.__call__", false]], "__call__() (model_api.tilers.tiler.tiler method)": [[31, "model_api.tilers.tiler.Tiler.__call__", false]], "actionclassificationmodel (class in model_api.models.action_classification)": [[9, "model_api.models.action_classification.ActionClassificationModel", false]], "add_edge() (model_api.models.classification.simplelabelsgraph method)": [[11, "model_api.models.classification.SimpleLabelsGraph.add_edge", false]], "add_rotated_rects() (in module model_api.models.utils)": [[22, "model_api.models.utils.add_rotated_rects", false]], "addorfindsoftmaxandtopkoutputs() (in module model_api.models.classification)": [[11, "model_api.models.classification.addOrFindSoftmaxAndTopkOutputs", false]], "anomalydetection (class in model_api.models.anomaly)": [[10, "model_api.models.anomaly.AnomalyDetection", false]], "apply_coords() (model_api.models.sam_models.samdecoder method)": [[18, "model_api.models.sam_models.SAMDecoder.apply_coords", false]], "async_pipeline (model_api.tilers.tiler.tiler attribute)": [[31, "model_api.tilers.tiler.Tiler.async_pipeline", false]], "asyncpipeline (class in model_api.pipelines.async_pipeline)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline", false]], "available_wrappers() (model_api.models.model.model class method)": [[17, "model_api.models.model.Model.available_wrappers", false]], "await_all() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.await_all", false]], "await_all() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.await_all", false]], "await_all() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.await_all", false]], "await_all() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.await_all", false]], "await_all() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline.await_all", false]], "await_any() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.await_any", false]], "await_any() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.await_any", false]], "await_any() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.await_any", false]], "await_any() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.await_any", false]], "await_any() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline.await_any", false]], "base_preprocess() (model_api.models.action_classification.actionclassificationmodel method)": [[9, "model_api.models.action_classification.ActionClassificationModel.base_preprocess", false]], "base_preprocess() (model_api.models.image_model.imagemodel method)": [[13, "model_api.models.image_model.ImageModel.base_preprocess", false]], "base_preprocess() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.base_preprocess", false]], "base_preprocess() (model_api.models.sam_models.samdecoder method)": [[18, "model_api.models.sam_models.SAMDecoder.base_preprocess", false]], "basevalue (class in model_api.models.types)": [[21, "model_api.models.types.BaseValue", false]], "booleanvalue (class in model_api.models.types)": [[21, "model_api.models.types.BooleanValue", false]], "boxeslabelsparser (class in model_api.models.ssd)": [[20, "model_api.models.ssd.BoxesLabelsParser", false]], "build_error() (model_api.models.types.basevalue method)": [[21, "model_api.models.types.BaseValue.build_error", false]], "callback() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline.callback", false]], "change_layout() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.change_layout", false]], "classificationmodel (class in model_api.models.classification)": [[11, "model_api.models.classification.ClassificationModel", false]], "clear_topological_cache() (model_api.models.classification.simplelabelsgraph method)": [[11, "model_api.models.classification.SimpleLabelsGraph.clear_topological_cache", false]], "clip_detections() (in module model_api.models.utils)": [[22, "model_api.models.utils.clip_detections", false]], "clip_size (model_api.models.action_classification.actionclassificationmodel property)": [[9, "model_api.models.action_classification.ActionClassificationModel.clip_size", false]], "compute() (model_api.models.utils.resizemetadata class method)": [[22, "model_api.models.utils.ResizeMetadata.compute", false]], "compute_resolution() (model_api.models.utils.outputtransform method)": [[22, "model_api.models.utils.OutputTransform.compute_resolution", false]], "configurablevalueerror": [[21, "model_api.models.types.ConfigurableValueError", false]], "copy_raw_result() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.copy_raw_result", false]], "create_core() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.create_core", false]], "create_hard_prediction_from_soft_prediction() (in module model_api.models.segmentation)": [[19, "model_api.models.segmentation.create_hard_prediction_from_soft_prediction", false]], "create_model() (model_api.models.model.model class method)": [[17, "model_api.models.model.Model.create_model", false]], "crop_resize() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.crop_resize", false]], "crop_resize_graph() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.crop_resize_graph", false]], "crop_resize_ocv() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.crop_resize_ocv", false]], "data (model_api.models.visual_prompting.prompt attribute)": [[23, "model_api.models.visual_prompting.Prompt.data", false]], "detect_model_type() (model_api.models.model.model class method)": [[17, "model_api.models.model.Model.detect_model_type", false]], "detectionbox (class in model_api.models.yolo)": [[24, "model_api.models.yolo.DetectionBox", false]], "detectionmodel (class in model_api.models.detection_model)": [[12, "model_api.models.detection_model.DetectionModel", false]], "detectiontiler (class in model_api.tilers.detection)": [[27, "model_api.tilers.detection.DetectionTiler", false]], "dictvalue (class in model_api.models.types)": [[21, "model_api.models.types.DictValue", false]], "embed_preprocessing() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.embed_preprocessing", false]], "execution_mode (model_api.tilers.tiler.tiler attribute)": [[31, "model_api.tilers.tiler.Tiler.execution_mode", false]], "execution_modes (model_api.tilers.tiler.tiler attribute)": [[31, "model_api.tilers.tiler.Tiler.EXECUTION_MODES", false]], "feature_vectors (model_api.models.visual_prompting.visualpromptingfeatures attribute)": [[23, "model_api.models.visual_prompting.VisualPromptingFeatures.feature_vectors", false]], "find_layer_bboxes_output() (model_api.models.ssd.boxeslabelsparser static method)": [[20, "model_api.models.ssd.BoxesLabelsParser.find_layer_bboxes_output", false]], "find_layer_by_name() (in module model_api.models.ssd)": [[20, "model_api.models.ssd.find_layer_by_name", false]], "from_dict() (model_api.models.utils.resizemetadata class method)": [[22, "model_api.models.utils.ResizeMetadata.from_dict", false]], "from_openvino() (model_api.adapters.utils.layout static method)": [[4, "model_api.adapters.utils.Layout.from_openvino", false]], "from_shape() (model_api.adapters.utils.layout static method)": [[4, "model_api.adapters.utils.Layout.from_shape", false]], "from_str() (model_api.models.types.booleanvalue method)": [[21, "model_api.models.types.BooleanValue.from_str", false]], "from_str() (model_api.models.types.dictvalue method)": [[21, "model_api.models.types.DictValue.from_str", false]], "from_str() (model_api.models.types.listvalue method)": [[21, "model_api.models.types.ListValue.from_str", false]], "from_str() (model_api.models.types.numericalvalue method)": [[21, "model_api.models.types.NumericalValue.from_str", false]], "from_str() (model_api.models.types.stringvalue method)": [[21, "model_api.models.types.StringValue.from_str", false]], "from_user_layouts() (model_api.adapters.utils.layout static method)": [[4, "model_api.adapters.utils.Layout.from_user_layouts", false]], "get_all_probs() (model_api.models.classification.classificationmodel method)": [[11, "model_api.models.classification.ClassificationModel.get_all_probs", false]], "get_ancestors() (model_api.models.classification.simplelabelsgraph method)": [[11, "model_api.models.classification.SimpleLabelsGraph.get_ancestors", false]], "get_cached_parameters() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.get_cached_parameters", false]], "get_children() (model_api.models.classification.simplelabelsgraph method)": [[11, "model_api.models.classification.SimpleLabelsGraph.get_children", false]], "get_contours() (in module model_api.models.utils)": [[22, "model_api.models.utils.get_contours", false]], "get_contours() (model_api.models.segmentation.segmentationmodel method)": [[19, "model_api.models.segmentation.SegmentationModel.get_contours", false]], "get_hierarchical_predictions() (model_api.models.classification.classificationmodel method)": [[11, "model_api.models.classification.ClassificationModel.get_hierarchical_predictions", false]], "get_input_layers() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_input_layers", false]], "get_input_shape() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.get_input_shape", false]], "get_label_name() (model_api.models.image_model.imagemodel method)": [[13, "model_api.models.image_model.ImageModel.get_label_name", false]], "get_labels_in_topological_order() (model_api.models.classification.simplelabelsgraph method)": [[11, "model_api.models.classification.SimpleLabelsGraph.get_labels_in_topological_order", false]], "get_layout_for_input() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_layout_for_input", false]], "get_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_model", false]], "get_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_model", false]], "get_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_model", false]], "get_model() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.get_model", false]], "get_model() (model_api.tilers.tiler.tiler method)": [[31, "model_api.tilers.tiler.Tiler.get_model", false]], "get_model_class() (model_api.models.model.model class method)": [[17, "model_api.models.model.Model.get_model_class", false]], "get_multiclass_predictions() (model_api.models.classification.classificationmodel method)": [[11, "model_api.models.classification.ClassificationModel.get_multiclass_predictions", false]], "get_multilabel_predictions() (model_api.models.classification.classificationmodel method)": [[11, "model_api.models.classification.ClassificationModel.get_multilabel_predictions", false]], "get_output_layers() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_output_layers", false]], "get_param() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.get_param", false]], "get_parent() (model_api.models.classification.simplelabelsgraph method)": [[11, "model_api.models.classification.SimpleLabelsGraph.get_parent", false]], "get_performance_metrics() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.get_performance_metrics", false]], "get_python_type() (in module model_api.models.types)": [[21, "model_api.models.types.get_python_type", false]], "get_raw_result() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_raw_result", false]], "get_raw_result() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline.get_raw_result", false]], "get_result() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline.get_result", false]], "get_rt_info() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_rt_info", false]], "get_rt_info_from_dict() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.get_rt_info_from_dict", false]], "get_saliency_maps() (model_api.models.classification.classificationmodel method)": [[11, "model_api.models.classification.ClassificationModel.get_saliency_maps", false]], "get_shape_from_onnx() (in module model_api.adapters.onnx_adapter)": [[2, "model_api.adapters.onnx_adapter.get_shape_from_onnx", false]], "get_subclasses() (model_api.models.model.model class method)": [[17, "model_api.models.model.Model.get_subclasses", false]], "get_user_config() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.get_user_config", false]], "get_value() (model_api.models.types.basevalue method)": [[21, "model_api.models.types.BaseValue.get_value", false]], "greedylabelsresolver (class in model_api.models.classification)": [[11, "model_api.models.classification.GreedyLabelsResolver", false]], "h (model_api.models.yolo.detectionbox attribute)": [[24, "model_api.models.yolo.DetectionBox.h", false]], "has_reference_features() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[23, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.has_reference_features", false]], "image_blob_name (model_api.models.action_classification.actionclassificationmodel attribute)": [[9, "model_api.models.action_classification.ActionClassificationModel.image_blob_name", false]], "image_blob_name (model_api.models.image_model.imagemodel attribute)": [[13, "model_api.models.image_model.ImageModel.image_blob_name", false]], "image_blob_names (model_api.models.action_classification.actionclassificationmodel attribute)": [[9, "model_api.models.action_classification.ActionClassificationModel.image_blob_names", false]], "image_blob_names (model_api.models.image_model.imagemodel attribute)": [[13, "model_api.models.image_model.ImageModel.image_blob_names", false]], "image_info_blob_names (model_api.models.image_model.imagemodel attribute)": [[13, "model_api.models.image_model.ImageModel.image_info_blob_names", false]], "imagemodel (class in model_api.models.image_model)": [[13, "model_api.models.image_model.ImageModel", false]], "infer() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[23, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.infer", false]], "infer() (model_api.models.visual_prompting.samvisualprompter method)": [[23, "model_api.models.visual_prompting.SAMVisualPrompter.infer", false]], "infer_async() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.infer_async", false]], "infer_async() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.infer_async", false]], "infer_async() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.infer_async", false]], "infer_async() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.infer_async", false]], "infer_async_raw() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.infer_async_raw", false]], "infer_batch() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.infer_batch", false]], "infer_sync() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.infer_sync", false]], "infer_sync() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.infer_sync", false]], "inference_adapter (model_api.models.model.model attribute)": [[17, "model_api.models.model.Model.inference_adapter", false]], "inferenceadapter (class in model_api.adapters.inference_adapter)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter", false]], "input_transform (model_api.models.action_classification.actionclassificationmodel attribute)": [[9, "model_api.models.action_classification.ActionClassificationModel.input_transform", false]], "input_transform (model_api.models.image_model.imagemodel attribute)": [[13, "model_api.models.image_model.ImageModel.input_transform", false]], "inputs (model_api.models.model.model attribute)": [[17, "model_api.models.model.Model.inputs", false]], "inputtransform (class in model_api.adapters.utils)": [[4, "model_api.adapters.utils.InputTransform", false]], "instancesegmentationtiler (class in model_api.tilers.instance_segmentation)": [[29, "model_api.tilers.instance_segmentation.InstanceSegmentationTiler", false]], "inverted_scale_x (model_api.models.utils.resizemetadata attribute)": [[22, "id0", false], [22, "model_api.models.utils.ResizeMetadata.inverted_scale_x", false]], "inverted_scale_y (model_api.models.utils.resizemetadata attribute)": [[22, "id1", false], [22, "model_api.models.utils.ResizeMetadata.inverted_scale_y", false]], "is_ready() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.is_ready", false]], "is_ready() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.is_ready", false]], "is_ready() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.is_ready", false]], "is_ready() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.is_ready", false]], "is_ready() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline.is_ready", false]], "keypointdetectionmodel (class in model_api.models.keypoint_detection)": [[16, "model_api.models.keypoint_detection.KeypointDetectionModel", false]], "label (model_api.models.visual_prompting.prompt attribute)": [[23, "model_api.models.visual_prompting.Prompt.label", false]], "layout (class in model_api.adapters.utils)": [[4, "model_api.adapters.utils.Layout", false]], "layout (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.layout", false]], "learn() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[23, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.learn", false]], "listvalue (class in model_api.models.types)": [[21, "model_api.models.types.ListValue", false]], "load() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.load", false]], "load_labels() (in module model_api.models.utils)": [[22, "model_api.models.utils.load_labels", false]], "load_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.load_model", false]], "load_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.load_model", false]], "load_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.load_model", false]], "load_parameters_from_onnx() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.load_parameters_from_onnx", false]], "log_layers_info() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.log_layers_info", false]], "log_runtime_settings() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.log_runtime_settings", false]], "logger (model_api.models.model.model attribute)": [[17, "model_api.models.model.Model.logger", false]], "maskrcnnmodel (class in model_api.models.instance_segmentation)": [[15, "model_api.models.instance_segmentation.MaskRCNNModel", false]], "meta (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.meta", false]], "metadata (class in model_api.adapters.inference_adapter)": [[1, "model_api.adapters.inference_adapter.Metadata", false]], "model (class in model_api.models.model)": [[17, "model_api.models.model.Model", false]], "model (model_api.tilers.tiler.tiler attribute)": [[31, "model_api.tilers.tiler.Tiler.model", false]], "model_api.adapters.inference_adapter": [[1, "module-model_api.adapters.inference_adapter", false]], "model_api.adapters.onnx_adapter": [[2, "module-model_api.adapters.onnx_adapter", false]], "model_api.adapters.openvino_adapter": [[3, "module-model_api.adapters.openvino_adapter", false]], "model_api.adapters.utils": [[4, "module-model_api.adapters.utils", false]], "model_api.models.action_classification": [[9, "module-model_api.models.action_classification", false]], "model_api.models.anomaly": [[10, "module-model_api.models.anomaly", false]], "model_api.models.classification": [[11, "module-model_api.models.classification", false]], "model_api.models.detection_model": [[12, "module-model_api.models.detection_model", false]], "model_api.models.image_model": [[13, "module-model_api.models.image_model", false]], "model_api.models.instance_segmentation": [[15, "module-model_api.models.instance_segmentation", false]], "model_api.models.keypoint_detection": [[16, "module-model_api.models.keypoint_detection", false]], "model_api.models.model": [[17, "module-model_api.models.model", false]], "model_api.models.sam_models": [[18, "module-model_api.models.sam_models", false]], "model_api.models.segmentation": [[19, "module-model_api.models.segmentation", false]], "model_api.models.ssd": [[20, "module-model_api.models.ssd", false]], "model_api.models.types": [[21, "module-model_api.models.types", false]], "model_api.models.utils": [[22, "module-model_api.models.utils", false]], "model_api.models.visual_prompting": [[23, "module-model_api.models.visual_prompting", false]], "model_api.models.yolo": [[24, "module-model_api.models.yolo", false]], "model_api.pipelines.async_pipeline": [[25, "module-model_api.pipelines.async_pipeline", false]], "model_api.tilers.detection": [[27, "module-model_api.tilers.detection", false]], "model_api.tilers.instance_segmentation": [[29, "module-model_api.tilers.instance_segmentation", false]], "model_api.tilers.semantic_segmentation": [[30, "module-model_api.tilers.semantic_segmentation", false]], "model_api.tilers.tiler": [[31, "module-model_api.tilers.tiler", false]], "model_loaded (model_api.models.model.model attribute)": [[17, "model_api.models.model.Model.model_loaded", false]], "model_loaded (model_api.tilers.tiler.tiler attribute)": [[31, "model_api.tilers.tiler.Tiler.model_loaded", false]], "module": [[1, "module-model_api.adapters.inference_adapter", false], [2, "module-model_api.adapters.onnx_adapter", false], [3, "module-model_api.adapters.openvino_adapter", false], [4, "module-model_api.adapters.utils", false], [9, "module-model_api.models.action_classification", false], [10, "module-model_api.models.anomaly", false], [11, "module-model_api.models.classification", false], [12, "module-model_api.models.detection_model", false], [13, "module-model_api.models.image_model", false], [15, "module-model_api.models.instance_segmentation", false], [16, "module-model_api.models.keypoint_detection", false], [17, "module-model_api.models.model", false], [18, "module-model_api.models.sam_models", false], [19, "module-model_api.models.segmentation", false], [20, "module-model_api.models.ssd", false], [21, "module-model_api.models.types", false], [22, "module-model_api.models.utils", false], [23, "module-model_api.models.visual_prompting", false], [24, "module-model_api.models.yolo", false], [25, "module-model_api.pipelines.async_pipeline", false], [27, "module-model_api.tilers.detection", false], [29, "module-model_api.tilers.instance_segmentation", false], [30, "module-model_api.tilers.semantic_segmentation", false], [31, "module-model_api.tilers.tiler", false]], "multiclass_nms() (in module model_api.models.utils)": [[22, "model_api.models.utils.multiclass_nms", false]], "multipleoutputparser (class in model_api.models.ssd)": [[20, "model_api.models.ssd.MultipleOutputParser", false]], "names (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.names", false]], "nchw_layout (model_api.models.image_model.imagemodel attribute)": [[13, "model_api.models.image_model.ImageModel.nchw_layout", false]], "nms() (in module model_api.models.utils)": [[22, "model_api.models.utils.nms", false]], "numericalvalue (class in model_api.models.types)": [[21, "model_api.models.types.NumericalValue", false]], "onnxruntimeadapter (class in model_api.adapters.onnx_adapter)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter", false]], "openvinoadapter (class in model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter", false]], "operations_by_type() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.operations_by_type", false]], "outputs (model_api.models.model.model attribute)": [[17, "model_api.models.model.Model.outputs", false]], "outputtransform (class in model_api.models.utils)": [[22, "model_api.models.utils.OutputTransform", false]], "pad_left (model_api.models.utils.resizemetadata attribute)": [[22, "id2", false], [22, "model_api.models.utils.ResizeMetadata.pad_left", false]], "pad_top (model_api.models.utils.resizemetadata attribute)": [[22, "id3", false], [22, "model_api.models.utils.ResizeMetadata.pad_top", false]], "parameters() (model_api.models.action_classification.actionclassificationmodel class method)": [[9, "model_api.models.action_classification.ActionClassificationModel.parameters", false]], "parameters() (model_api.models.anomaly.anomalydetection class method)": [[10, "model_api.models.anomaly.AnomalyDetection.parameters", false]], "parameters() (model_api.models.classification.classificationmodel class method)": [[11, "model_api.models.classification.ClassificationModel.parameters", false]], "parameters() (model_api.models.detection_model.detectionmodel class method)": [[12, "model_api.models.detection_model.DetectionModel.parameters", false]], "parameters() (model_api.models.image_model.imagemodel class method)": [[13, "model_api.models.image_model.ImageModel.parameters", false]], "parameters() (model_api.models.instance_segmentation.maskrcnnmodel class method)": [[15, "model_api.models.instance_segmentation.MaskRCNNModel.parameters", false]], "parameters() (model_api.models.keypoint_detection.keypointdetectionmodel class method)": [[16, "model_api.models.keypoint_detection.KeypointDetectionModel.parameters", false]], "parameters() (model_api.models.model.model class method)": [[17, "model_api.models.model.Model.parameters", false]], "parameters() (model_api.models.sam_models.samdecoder class method)": [[18, "model_api.models.sam_models.SAMDecoder.parameters", false]], "parameters() (model_api.models.sam_models.samimageencoder class method)": [[18, "model_api.models.sam_models.SAMImageEncoder.parameters", false]], "parameters() (model_api.models.segmentation.segmentationmodel class method)": [[19, "model_api.models.segmentation.SegmentationModel.parameters", false]], "parameters() (model_api.models.yolo.yolo class method)": [[24, "model_api.models.yolo.YOLO.parameters", false]], "parameters() (model_api.models.yolo.yolof class method)": [[24, "model_api.models.yolo.YOLOF.parameters", false]], "parameters() (model_api.models.yolo.yolov3onnx class method)": [[24, "model_api.models.yolo.YoloV3ONNX.parameters", false]], "parameters() (model_api.models.yolo.yolov4 class method)": [[24, "model_api.models.yolo.YoloV4.parameters", false]], "parameters() (model_api.models.yolo.yolov5 class method)": [[24, "model_api.models.yolo.YOLOv5.parameters", false]], "parameters() (model_api.models.yolo.yolox class method)": [[24, "model_api.models.yolo.YOLOX.parameters", false]], "parameters() (model_api.tilers.detection.detectiontiler class method)": [[27, "model_api.tilers.detection.DetectionTiler.parameters", false]], "parameters() (model_api.tilers.tiler.tiler class method)": [[31, "model_api.tilers.tiler.Tiler.parameters", false]], "params (model_api.models.model.model attribute)": [[17, "id0", false], [17, "model_api.models.model.Model.params", false]], "parse_devices() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.parse_devices", false]], "parse_layouts() (model_api.adapters.utils.layout static method)": [[4, "model_api.adapters.utils.Layout.parse_layouts", false]], "parse_value_per_device() (in module model_api.adapters.openvino_adapter)": [[3, "model_api.adapters.openvino_adapter.parse_value_per_device", false]], "permute_to_n_hwa_k() (in module model_api.models.yolo)": [[24, "model_api.models.yolo.permute_to_N_HWA_K", false]], "postprocess() (model_api.models.action_classification.actionclassificationmodel method)": [[9, "model_api.models.action_classification.ActionClassificationModel.postprocess", false]], "postprocess() (model_api.models.anomaly.anomalydetection method)": [[10, "model_api.models.anomaly.AnomalyDetection.postprocess", false]], "postprocess() (model_api.models.classification.classificationmodel method)": [[11, "model_api.models.classification.ClassificationModel.postprocess", false]], "postprocess() (model_api.models.instance_segmentation.maskrcnnmodel method)": [[15, "model_api.models.instance_segmentation.MaskRCNNModel.postprocess", false]], "postprocess() (model_api.models.keypoint_detection.keypointdetectionmodel method)": [[16, "model_api.models.keypoint_detection.KeypointDetectionModel.postprocess", false]], "postprocess() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.postprocess", false]], "postprocess() (model_api.models.sam_models.samdecoder method)": [[18, "model_api.models.sam_models.SAMDecoder.postprocess", false]], "postprocess() (model_api.models.sam_models.samimageencoder method)": [[18, "model_api.models.sam_models.SAMImageEncoder.postprocess", false]], "postprocess() (model_api.models.segmentation.segmentationmodel method)": [[19, "model_api.models.segmentation.SegmentationModel.postprocess", false]], "postprocess() (model_api.models.ssd.ssd method)": [[20, "model_api.models.ssd.SSD.postprocess", false]], "postprocess() (model_api.models.yolo.yolo method)": [[24, "model_api.models.yolo.YOLO.postprocess", false]], "postprocess() (model_api.models.yolo.yolov3onnx method)": [[24, "model_api.models.yolo.YoloV3ONNX.postprocess", false]], "postprocess() (model_api.models.yolo.yolov5 method)": [[24, "model_api.models.yolo.YOLOv5.postprocess", false]], "postprocess() (model_api.models.yolo.yolox method)": [[24, "model_api.models.yolo.YOLOX.postprocess", false]], "precision (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.precision", false]], "precisions (model_api.adapters.inference_adapter.inferenceadapter attribute)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.precisions", false]], "predict() (model_api.models.keypoint_detection.topdownkeypointdetectionpipeline method)": [[16, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline.predict", false]], "predict_crops() (model_api.models.keypoint_detection.topdownkeypointdetectionpipeline method)": [[16, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline.predict_crops", false]], "preprocess() (model_api.models.detection_model.detectionmodel method)": [[12, "model_api.models.detection_model.DetectionModel.preprocess", false]], "preprocess() (model_api.models.image_model.imagemodel method)": [[13, "model_api.models.image_model.ImageModel.preprocess", false]], "preprocess() (model_api.models.instance_segmentation.maskrcnnmodel method)": [[15, "model_api.models.instance_segmentation.MaskRCNNModel.preprocess", false]], "preprocess() (model_api.models.keypoint_detection.keypointdetectionmodel method)": [[16, "model_api.models.keypoint_detection.KeypointDetectionModel.preprocess", false]], "preprocess() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.preprocess", false]], "preprocess() (model_api.models.sam_models.samimageencoder method)": [[18, "model_api.models.sam_models.SAMImageEncoder.preprocess", false]], "preprocess() (model_api.models.ssd.ssd method)": [[20, "model_api.models.ssd.SSD.preprocess", false]], "preprocess() (model_api.models.yolo.yolov3onnx method)": [[24, "model_api.models.yolo.YoloV3ONNX.preprocess", false]], "probabilisticlabelsresolver (class in model_api.models.classification)": [[11, "model_api.models.classification.ProbabilisticLabelsResolver", false]], "prompt (class in model_api.models.visual_prompting)": [[23, "model_api.models.visual_prompting.Prompt", false]], "raise_error() (model_api.models.model.model class method)": [[17, "model_api.models.model.Model.raise_error", false]], "reference_features (model_api.models.visual_prompting.samlearnablevisualprompter property)": [[23, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.reference_features", false]], "reset_reference_info() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[23, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.reset_reference_info", false]], "reshape() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.reshape", false]], "reshape_dynamic_inputs() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.reshape_dynamic_inputs", false]], "reshape_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.reshape_model", false]], "resize (model_api.models.action_classification.actionclassificationmodel attribute)": [[9, "model_api.models.action_classification.ActionClassificationModel.resize", false]], "resize (model_api.models.image_model.imagemodel attribute)": [[13, "model_api.models.image_model.ImageModel.resize", false]], "resize() (model_api.models.utils.outputtransform method)": [[22, "model_api.models.utils.OutputTransform.resize", false]], "resize_image() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image", false]], "resize_image_graph() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image_graph", false]], "resize_image_letterbox() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image_letterbox", false]], "resize_image_letterbox_graph() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image_letterbox_graph", false]], "resize_image_letterbox_ocv() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image_letterbox_ocv", false]], "resize_image_ocv() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image_ocv", false]], "resize_image_with_aspect() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image_with_aspect", false]], "resize_image_with_aspect_ocv() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.resize_image_with_aspect_ocv", false]], "resize_type (model_api.models.action_classification.actionclassificationmodel attribute)": [[9, "model_api.models.action_classification.ActionClassificationModel.resize_type", false]], "resize_type (model_api.models.image_model.imagemodel attribute)": [[13, "model_api.models.image_model.ImageModel.resize_type", false]], "resizemetadata (class in model_api.models.utils)": [[22, "model_api.models.utils.ResizeMetadata", false]], "resolve_labels() (model_api.models.classification.greedylabelsresolver method)": [[11, "model_api.models.classification.GreedyLabelsResolver.resolve_labels", false]], "resolve_labels() (model_api.models.classification.probabilisticlabelsresolver method)": [[11, "model_api.models.classification.ProbabilisticLabelsResolver.resolve_labels", false]], "samdecoder (class in model_api.models.sam_models)": [[18, "model_api.models.sam_models.SAMDecoder", false]], "samimageencoder (class in model_api.models.sam_models)": [[18, "model_api.models.sam_models.SAMImageEncoder", false]], "samlearnablevisualprompter (class in model_api.models.visual_prompting)": [[23, "model_api.models.visual_prompting.SAMLearnableVisualPrompter", false]], "samvisualprompter (class in model_api.models.visual_prompting)": [[23, "model_api.models.visual_prompting.SAMVisualPrompter", false]], "save() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.save", false]], "save_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.save_model", false]], "save_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.save_model", false]], "save_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.save_model", false]], "scale() (model_api.models.utils.outputtransform method)": [[22, "model_api.models.utils.OutputTransform.scale", false]], "segmentationmodel (class in model_api.models.segmentation)": [[19, "model_api.models.segmentation.SegmentationModel", false]], "semanticsegmentationtiler (class in model_api.tilers.semantic_segmentation)": [[30, "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler", false]], "set_callback() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.set_callback", false]], "set_callback() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.set_callback", false]], "set_callback() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.set_callback", false]], "set_callback() (model_api.models.model.model method)": [[17, "model_api.models.model.Model.set_callback", false]], "set_strides_grids() (model_api.models.yolo.yolox method)": [[24, "model_api.models.yolo.YOLOX.set_strides_grids", false]], "setup_python_preprocessing_pipeline() (in module model_api.adapters.utils)": [[4, "model_api.adapters.utils.setup_python_preprocessing_pipeline", false]], "shape (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.shape", false]], "sigmoid() (in module model_api.models.yolo)": [[24, "model_api.models.yolo.sigmoid", false]], "sigmoid_numpy() (in module model_api.models.classification)": [[11, "model_api.models.classification.sigmoid_numpy", false]], "simplelabelsgraph (class in model_api.models.classification)": [[11, "model_api.models.classification.SimpleLabelsGraph", false]], "singleoutputparser (class in model_api.models.ssd)": [[20, "model_api.models.ssd.SingleOutputParser", false]], "softmax() (in module model_api.models.utils)": [[22, "model_api.models.utils.softmax", false]], "ssd (class in model_api.models.ssd)": [[20, "model_api.models.ssd.SSD", false]], "stringvalue (class in model_api.models.types)": [[21, "model_api.models.types.StringValue", false]], "submit_data() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[25, "model_api.pipelines.async_pipeline.AsyncPipeline.submit_data", false]], "tiler (class in model_api.tilers.tiler)": [[31, "model_api.tilers.tiler.Tiler", false]], "to_dict() (model_api.models.utils.resizemetadata method)": [[22, "model_api.models.utils.ResizeMetadata.to_dict", false]], "topdownkeypointdetectionpipeline (class in model_api.models.keypoint_detection)": [[16, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline", false]], "topological_sort() (model_api.models.classification.simplelabelsgraph method)": [[11, "model_api.models.classification.SimpleLabelsGraph.topological_sort", false]], "type (model_api.adapters.inference_adapter.metadata attribute)": [[1, "model_api.adapters.inference_adapter.Metadata.type", false]], "update_default_value() (model_api.models.types.basevalue method)": [[21, "model_api.models.types.BaseValue.update_default_value", false]], "update_model_info() (model_api.adapters.inference_adapter.inferenceadapter method)": [[1, "model_api.adapters.inference_adapter.InferenceAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[2, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[3, "model_api.adapters.openvino_adapter.OpenvinoAdapter.update_model_info", false]], "used_indices (model_api.models.visual_prompting.visualpromptingfeatures attribute)": [[23, "model_api.models.visual_prompting.VisualPromptingFeatures.used_indices", false]], "validate() (model_api.models.types.basevalue method)": [[21, "model_api.models.types.BaseValue.validate", false]], "validate() (model_api.models.types.booleanvalue method)": [[21, "model_api.models.types.BooleanValue.validate", false]], "validate() (model_api.models.types.dictvalue method)": [[21, "model_api.models.types.DictValue.validate", false]], "validate() (model_api.models.types.listvalue method)": [[21, "model_api.models.types.ListValue.validate", false]], "validate() (model_api.models.types.numericalvalue method)": [[21, "model_api.models.types.NumericalValue.validate", false]], "validate() (model_api.models.types.stringvalue method)": [[21, "model_api.models.types.StringValue.validate", false]], "visualpromptingfeatures (class in model_api.models.visual_prompting)": [[23, "model_api.models.visual_prompting.VisualPromptingFeatures", false]], "w (model_api.models.yolo.detectionbox attribute)": [[24, "model_api.models.yolo.DetectionBox.w", false]], "wrappererror": [[17, "model_api.models.model.WrapperError", false]], "x (model_api.models.yolo.detectionbox attribute)": [[24, "model_api.models.yolo.DetectionBox.x", false]], "xywh2xyxy() (in module model_api.models.yolo)": [[24, "model_api.models.yolo.xywh2xyxy", false]], "y (model_api.models.yolo.detectionbox attribute)": [[24, "model_api.models.yolo.DetectionBox.y", false]], "yolo (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YOLO", false]], "yolo.params (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YOLO.Params", false]], "yolof (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YOLOF", false]], "yolof.params (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YOLOF.Params", false]], "yolov3onnx (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YoloV3ONNX", false]], "yolov4 (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YoloV4", false]], "yolov4.params (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YoloV4.Params", false]], "yolov5 (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YOLOv5", false]], "yolov8 (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YOLOv8", false]], "yolox (class in model_api.models.yolo)": [[24, "model_api.models.yolo.YOLOX", false]]}, "objects": {"model_api.adapters": [[1, 0, 0, "-", "inference_adapter"], [2, 0, 0, "-", "onnx_adapter"], [3, 0, 0, "-", "openvino_adapter"], [4, 0, 0, "-", "utils"]], "model_api.adapters.inference_adapter": [[1, 1, 1, "", "InferenceAdapter"], [1, 1, 1, "", "Metadata"]], "model_api.adapters.inference_adapter.InferenceAdapter": [[1, 2, 1, "", "await_all"], [1, 2, 1, "", "await_any"], [1, 2, 1, "", "embed_preprocessing"], [1, 2, 1, "", "get_input_layers"], [1, 2, 1, "", "get_model"], [1, 2, 1, "", "get_output_layers"], [1, 2, 1, "", "get_raw_result"], [1, 2, 1, "", "get_rt_info"], [1, 2, 1, "", "infer_async"], [1, 2, 1, "", "infer_sync"], [1, 2, 1, "", "is_ready"], [1, 2, 1, "", "load_model"], [1, 3, 1, "", "precisions"], [1, 2, 1, "", "reshape_model"], [1, 2, 1, "", "save_model"], [1, 2, 1, "", "set_callback"], [1, 2, 1, "", "update_model_info"]], "model_api.adapters.inference_adapter.Metadata": [[1, 3, 1, "", "layout"], [1, 3, 1, "", "meta"], [1, 3, 1, "", "names"], [1, 3, 1, "", "precision"], [1, 3, 1, "", "shape"], [1, 3, 1, "", "type"]], "model_api.adapters.onnx_adapter": [[2, 1, 1, "", "ONNXRuntimeAdapter"], [2, 4, 1, "", "get_shape_from_onnx"]], "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter": [[2, 2, 1, "", "await_all"], [2, 2, 1, "", "await_any"], [2, 2, 1, "", "embed_preprocessing"], [2, 2, 1, "", "get_input_layers"], [2, 2, 1, "", "get_model"], [2, 2, 1, "", "get_output_layers"], [2, 2, 1, "", "get_raw_result"], [2, 2, 1, "", "get_rt_info"], [2, 2, 1, "", "infer_async"], [2, 2, 1, "", "infer_sync"], [2, 2, 1, "", "is_ready"], [2, 2, 1, "", "load_model"], [2, 2, 1, "", "reshape_model"], [2, 2, 1, "", "save_model"], [2, 2, 1, "", "set_callback"], [2, 2, 1, "", "update_model_info"]], "model_api.adapters.openvino_adapter": [[3, 1, 1, "", "OpenvinoAdapter"], [3, 4, 1, "", "create_core"], [3, 4, 1, "", "get_input_shape"], [3, 4, 1, "", "get_user_config"], [3, 4, 1, "", "parse_devices"], [3, 4, 1, "", "parse_value_per_device"]], "model_api.adapters.openvino_adapter.OpenvinoAdapter": [[3, 2, 1, "", "await_all"], [3, 2, 1, "", "await_any"], [3, 2, 1, "", "copy_raw_result"], [3, 2, 1, "", "embed_preprocessing"], [3, 2, 1, "", "get_input_layers"], [3, 2, 1, "", "get_layout_for_input"], [3, 2, 1, "", "get_model"], [3, 2, 1, "", "get_output_layers"], [3, 2, 1, "", "get_raw_result"], [3, 2, 1, "", "get_rt_info"], [3, 2, 1, "", "infer_async"], [3, 2, 1, "", "infer_sync"], [3, 2, 1, "", "is_ready"], [3, 2, 1, "", "load_model"], [3, 2, 1, "", "log_runtime_settings"], [3, 2, 1, "", "operations_by_type"], [3, 2, 1, "", "reshape_dynamic_inputs"], [3, 2, 1, "", "reshape_model"], [3, 2, 1, "", "save_model"], [3, 2, 1, "", "set_callback"], [3, 2, 1, "", "update_model_info"]], "model_api.adapters.utils": [[4, 1, 1, "", "InputTransform"], [4, 1, 1, "", "Layout"], [4, 4, 1, "", "change_layout"], [4, 4, 1, "", "crop_resize"], [4, 4, 1, "", "crop_resize_graph"], [4, 4, 1, "", "crop_resize_ocv"], [4, 4, 1, "", "get_rt_info_from_dict"], [4, 4, 1, "", "load_parameters_from_onnx"], [4, 4, 1, "", "resize_image"], [4, 4, 1, "", "resize_image_graph"], [4, 4, 1, "", "resize_image_letterbox"], [4, 4, 1, "", "resize_image_letterbox_graph"], [4, 4, 1, "", "resize_image_letterbox_ocv"], [4, 4, 1, "", "resize_image_ocv"], [4, 4, 1, "", "resize_image_with_aspect"], [4, 4, 1, "", "resize_image_with_aspect_ocv"], [4, 4, 1, "", "setup_python_preprocessing_pipeline"]], "model_api.adapters.utils.InputTransform": [[4, 2, 1, "", "__call__"]], "model_api.adapters.utils.Layout": [[4, 2, 1, "", "from_openvino"], [4, 2, 1, "", "from_shape"], [4, 2, 1, "", "from_user_layouts"], [4, 2, 1, "", "parse_layouts"]], "model_api.models": [[9, 0, 0, "-", "action_classification"], [10, 0, 0, "-", "anomaly"], [11, 0, 0, "-", "classification"], [12, 0, 0, "-", "detection_model"], [13, 0, 0, "-", "image_model"], [15, 0, 0, "-", "instance_segmentation"], [16, 0, 0, "-", "keypoint_detection"], [17, 0, 0, "-", "model"], [18, 0, 0, "-", "sam_models"], [19, 0, 0, "-", "segmentation"], [20, 0, 0, "-", "ssd"], [21, 0, 0, "-", "types"], [22, 0, 0, "-", "utils"], [23, 0, 0, "-", "visual_prompting"], [24, 0, 0, "-", "yolo"]], "model_api.models.action_classification": [[9, 1, 1, "", "ActionClassificationModel"]], "model_api.models.action_classification.ActionClassificationModel": [[9, 2, 1, "", "base_preprocess"], [9, 5, 1, "", "clip_size"], [9, 3, 1, "", "image_blob_name"], [9, 3, 1, "", "image_blob_names"], [9, 3, 1, "", "input_transform"], [9, 2, 1, "", "parameters"], [9, 2, 1, "", "postprocess"], [9, 3, 1, "", "resize"], [9, 3, 1, "", "resize_type"]], "model_api.models.anomaly": [[10, 1, 1, "", "AnomalyDetection"]], "model_api.models.anomaly.AnomalyDetection": [[10, 2, 1, "", "parameters"], [10, 2, 1, "", "postprocess"]], "model_api.models.classification": [[11, 1, 1, "", "ClassificationModel"], [11, 1, 1, "", "GreedyLabelsResolver"], [11, 1, 1, "", "ProbabilisticLabelsResolver"], [11, 1, 1, "", "SimpleLabelsGraph"], [11, 4, 1, "", "addOrFindSoftmaxAndTopkOutputs"], [11, 4, 1, "", "sigmoid_numpy"]], "model_api.models.classification.ClassificationModel": [[11, 2, 1, "", "get_all_probs"], [11, 2, 1, "", "get_hierarchical_predictions"], [11, 2, 1, "", "get_multiclass_predictions"], [11, 2, 1, "", "get_multilabel_predictions"], [11, 2, 1, "", "get_saliency_maps"], [11, 2, 1, "", "parameters"], [11, 2, 1, "", "postprocess"]], "model_api.models.classification.GreedyLabelsResolver": [[11, 2, 1, "", "resolve_labels"]], "model_api.models.classification.ProbabilisticLabelsResolver": [[11, 2, 1, "", "resolve_labels"]], "model_api.models.classification.SimpleLabelsGraph": [[11, 2, 1, "", "add_edge"], [11, 2, 1, "", "clear_topological_cache"], [11, 2, 1, "", "get_ancestors"], [11, 2, 1, "", "get_children"], [11, 2, 1, "", "get_labels_in_topological_order"], [11, 2, 1, "", "get_parent"], [11, 2, 1, "", "topological_sort"]], "model_api.models.detection_model": [[12, 1, 1, "", "DetectionModel"]], "model_api.models.detection_model.DetectionModel": [[12, 2, 1, "", "parameters"], [12, 2, 1, "", "preprocess"]], "model_api.models.image_model": [[13, 1, 1, "", "ImageModel"]], "model_api.models.image_model.ImageModel": [[13, 2, 1, "", "base_preprocess"], [13, 2, 1, "", "get_label_name"], [13, 3, 1, "", "image_blob_name"], [13, 3, 1, "", "image_blob_names"], [13, 3, 1, "", "image_info_blob_names"], [13, 3, 1, "", "input_transform"], [13, 3, 1, "", "nchw_layout"], [13, 2, 1, "", "parameters"], [13, 2, 1, "", "preprocess"], [13, 3, 1, "", "resize"], [13, 3, 1, "", "resize_type"]], "model_api.models.instance_segmentation": [[15, 1, 1, "", "MaskRCNNModel"]], "model_api.models.instance_segmentation.MaskRCNNModel": [[15, 2, 1, "", "parameters"], [15, 2, 1, "", "postprocess"], [15, 2, 1, "", "preprocess"]], "model_api.models.keypoint_detection": [[16, 1, 1, "", "KeypointDetectionModel"], [16, 1, 1, "", "TopDownKeypointDetectionPipeline"]], "model_api.models.keypoint_detection.KeypointDetectionModel": [[16, 2, 1, "", "parameters"], [16, 2, 1, "", "postprocess"], [16, 2, 1, "", "preprocess"]], "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline": [[16, 2, 1, "", "predict"], [16, 2, 1, "", "predict_crops"]], "model_api.models.model": [[17, 1, 1, "", "Model"], [17, 6, 1, "", "WrapperError"]], "model_api.models.model.Model": [[17, 2, 1, "", "__call__"], [17, 2, 1, "", "available_wrappers"], [17, 2, 1, "", "await_all"], [17, 2, 1, "", "await_any"], [17, 2, 1, "", "base_preprocess"], [17, 2, 1, "", "create_model"], [17, 2, 1, "", "detect_model_type"], [17, 2, 1, "", "get_cached_parameters"], [17, 2, 1, "", "get_model"], [17, 2, 1, "", "get_model_class"], [17, 2, 1, "", "get_param"], [17, 2, 1, "", "get_performance_metrics"], [17, 2, 1, "", "get_subclasses"], [17, 2, 1, "", "infer_async"], [17, 2, 1, "", "infer_async_raw"], [17, 2, 1, "", "infer_batch"], [17, 2, 1, "", "infer_sync"], [17, 3, 1, "", "inference_adapter"], [17, 3, 1, "", "inputs"], [17, 2, 1, "", "is_ready"], [17, 2, 1, "", "load"], [17, 2, 1, "", "log_layers_info"], [17, 3, 1, "", "logger"], [17, 3, 1, "", "model_loaded"], [17, 3, 1, "", "outputs"], [17, 2, 1, "", "parameters"], [17, 3, 1, "id0", "params"], [17, 2, 1, "", "postprocess"], [17, 2, 1, "", "preprocess"], [17, 2, 1, "", "raise_error"], [17, 2, 1, "", "reshape"], [17, 2, 1, "", "save"], [17, 2, 1, "", "set_callback"]], "model_api.models.sam_models": [[18, 1, 1, "", "SAMDecoder"], [18, 1, 1, "", "SAMImageEncoder"]], "model_api.models.sam_models.SAMDecoder": [[18, 2, 1, "", "apply_coords"], [18, 2, 1, "", "base_preprocess"], [18, 2, 1, "", "parameters"], [18, 2, 1, "", "postprocess"]], "model_api.models.sam_models.SAMImageEncoder": [[18, 2, 1, "", "parameters"], [18, 2, 1, "", "postprocess"], [18, 2, 1, "", "preprocess"]], "model_api.models.segmentation": [[19, 1, 1, "", "SegmentationModel"], [19, 4, 1, "", "create_hard_prediction_from_soft_prediction"]], "model_api.models.segmentation.SegmentationModel": [[19, 2, 1, "", "get_contours"], [19, 2, 1, "", "parameters"], [19, 2, 1, "", "postprocess"]], "model_api.models.ssd": [[20, 1, 1, "", "BoxesLabelsParser"], [20, 1, 1, "", "MultipleOutputParser"], [20, 1, 1, "", "SSD"], [20, 1, 1, "", "SingleOutputParser"], [20, 4, 1, "", "find_layer_by_name"]], "model_api.models.ssd.BoxesLabelsParser": [[20, 2, 1, "", "__call__"], [20, 2, 1, "", "find_layer_bboxes_output"]], "model_api.models.ssd.MultipleOutputParser": [[20, 2, 1, "", "__call__"]], "model_api.models.ssd.SSD": [[20, 2, 1, "", "postprocess"], [20, 2, 1, "", "preprocess"]], "model_api.models.ssd.SingleOutputParser": [[20, 2, 1, "", "__call__"]], "model_api.models.types": [[21, 1, 1, "", "BaseValue"], [21, 1, 1, "", "BooleanValue"], [21, 6, 1, "", "ConfigurableValueError"], [21, 1, 1, "", "DictValue"], [21, 1, 1, "", "ListValue"], [21, 1, 1, "", "NumericalValue"], [21, 1, 1, "", "StringValue"], [21, 4, 1, "", "get_python_type"]], "model_api.models.types.BaseValue": [[21, 2, 1, "", "build_error"], [21, 2, 1, "", "get_value"], [21, 2, 1, "", "update_default_value"], [21, 2, 1, "", "validate"]], "model_api.models.types.BooleanValue": [[21, 2, 1, "", "from_str"], [21, 2, 1, "", "validate"]], "model_api.models.types.DictValue": [[21, 2, 1, "", "from_str"], [21, 2, 1, "", "validate"]], "model_api.models.types.ListValue": [[21, 2, 1, "", "from_str"], [21, 2, 1, "", "validate"]], "model_api.models.types.NumericalValue": [[21, 2, 1, "", "from_str"], [21, 2, 1, "", "validate"]], "model_api.models.types.StringValue": [[21, 2, 1, "", "from_str"], [21, 2, 1, "", "validate"]], "model_api.models.utils": [[22, 1, 1, "", "OutputTransform"], [22, 1, 1, "", "ResizeMetadata"], [22, 4, 1, "", "add_rotated_rects"], [22, 4, 1, "", "clip_detections"], [22, 4, 1, "", "get_contours"], [22, 4, 1, "", "load_labels"], [22, 4, 1, "", "multiclass_nms"], [22, 4, 1, "", "nms"], [22, 4, 1, "", "softmax"]], "model_api.models.utils.OutputTransform": [[22, 2, 1, "", "compute_resolution"], [22, 2, 1, "", "resize"], [22, 2, 1, "", "scale"]], "model_api.models.utils.ResizeMetadata": [[22, 2, 1, "", "compute"], [22, 2, 1, "", "from_dict"], [22, 3, 1, "id0", "inverted_scale_x"], [22, 3, 1, "id1", "inverted_scale_y"], [22, 3, 1, "id2", "pad_left"], [22, 3, 1, "id3", "pad_top"], [22, 2, 1, "", "to_dict"]], "model_api.models.visual_prompting": [[23, 1, 1, "", "Prompt"], [23, 1, 1, "", "SAMLearnableVisualPrompter"], [23, 1, 1, "", "SAMVisualPrompter"], [23, 1, 1, "", "VisualPromptingFeatures"]], "model_api.models.visual_prompting.Prompt": [[23, 3, 1, "", "data"], [23, 3, 1, "", "label"]], "model_api.models.visual_prompting.SAMLearnableVisualPrompter": [[23, 2, 1, "", "__call__"], [23, 2, 1, "", "has_reference_features"], [23, 2, 1, "", "infer"], [23, 2, 1, "", "learn"], [23, 5, 1, "", "reference_features"], [23, 2, 1, "", "reset_reference_info"]], "model_api.models.visual_prompting.SAMVisualPrompter": [[23, 2, 1, "", "__call__"], [23, 2, 1, "", "infer"]], "model_api.models.visual_prompting.VisualPromptingFeatures": [[23, 3, 1, "", "feature_vectors"], [23, 3, 1, "", "used_indices"]], "model_api.models.yolo": [[24, 1, 1, "", "DetectionBox"], [24, 1, 1, "", "YOLO"], [24, 1, 1, "", "YOLOF"], [24, 1, 1, "", "YOLOX"], [24, 1, 1, "", "YOLOv5"], [24, 1, 1, "", "YOLOv8"], [24, 1, 1, "", "YoloV3ONNX"], [24, 1, 1, "", "YoloV4"], [24, 4, 1, "", "permute_to_N_HWA_K"], [24, 4, 1, "", "sigmoid"], [24, 4, 1, "", "xywh2xyxy"]], "model_api.models.yolo.DetectionBox": [[24, 3, 1, "", "h"], [24, 3, 1, "", "w"], [24, 3, 1, "", "x"], [24, 3, 1, "", "y"]], "model_api.models.yolo.YOLO": [[24, 1, 1, "", "Params"], [24, 2, 1, "", "parameters"], [24, 2, 1, "", "postprocess"]], "model_api.models.yolo.YOLOF": [[24, 1, 1, "", "Params"], [24, 2, 1, "", "parameters"]], "model_api.models.yolo.YOLOX": [[24, 2, 1, "", "parameters"], [24, 2, 1, "", "postprocess"], [24, 2, 1, "", "set_strides_grids"]], "model_api.models.yolo.YOLOv5": [[24, 2, 1, "", "parameters"], [24, 2, 1, "", "postprocess"]], "model_api.models.yolo.YoloV3ONNX": [[24, 2, 1, "", "parameters"], [24, 2, 1, "", "postprocess"], [24, 2, 1, "", "preprocess"]], "model_api.models.yolo.YoloV4": [[24, 1, 1, "", "Params"], [24, 2, 1, "", "parameters"]], "model_api.pipelines": [[25, 0, 0, "-", "async_pipeline"]], "model_api.pipelines.async_pipeline": [[25, 1, 1, "", "AsyncPipeline"]], "model_api.pipelines.async_pipeline.AsyncPipeline": [[25, 2, 1, "", "await_all"], [25, 2, 1, "", "await_any"], [25, 2, 1, "", "callback"], [25, 2, 1, "", "get_raw_result"], [25, 2, 1, "", "get_result"], [25, 2, 1, "", "is_ready"], [25, 2, 1, "", "submit_data"]], "model_api.tilers": [[27, 0, 0, "-", "detection"], [29, 0, 0, "-", "instance_segmentation"], [30, 0, 0, "-", "semantic_segmentation"], [31, 0, 0, "-", "tiler"]], "model_api.tilers.detection": [[27, 1, 1, "", "DetectionTiler"]], "model_api.tilers.detection.DetectionTiler": [[27, 2, 1, "", "parameters"]], "model_api.tilers.instance_segmentation": [[29, 1, 1, "", "InstanceSegmentationTiler"]], "model_api.tilers.instance_segmentation.InstanceSegmentationTiler": [[29, 2, 1, "", "__call__"]], "model_api.tilers.semantic_segmentation": [[30, 1, 1, "", "SemanticSegmentationTiler"]], "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler": [[30, 2, 1, "", "__call__"]], "model_api.tilers.tiler": [[31, 1, 1, "", "Tiler"]], "model_api.tilers.tiler.Tiler": [[31, 3, 1, "", "EXECUTION_MODES"], [31, 2, 1, "", "__call__"], [31, 3, 1, "", "async_pipeline"], [31, 3, 1, "", "execution_mode"], [31, 2, 1, "", "get_model"], [31, 3, 1, "", "model"], [31, 3, 1, "", "model_loaded"], [31, 2, 1, "", "parameters"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"], "5": ["py", "property", "Python property"], "6": ["py", "exception", "Python exception"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function", "5": "py:property", "6": "py:exception"}, "terms": {"": [1, 2, 3, 6, 7, 9, 11, 13], "0": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "000": 7, "001": 7, "020": 7, "02643": 18, "09": 22, "1": [1, 3, 4, 6, 7, 9, 10, 11, 12, 13, 16, 17, 19, 20, 23, 24], "10": 7, "100": [7, 16], "114640": 10, "128": [1, 3], "134": 10, "138": 10, "150": 10, "1e": 22, "2": [7, 23, 24], "200": 22, "2304": 18, "255": 16, "2d": 13, "2f": 7, "3": [1, 3, 11, 12, 15, 19, 24], "3d": [4, 13], "3f": 7, "45": 22, "497": 7, "4d": [9, 13], "5": [6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24], "50": 7, "556": 7, "570": 7, "572": 7, "6": 11, "60699755": 11, "642": 7, "65": 23, "6d": 9, "7": 11, "75": 7, "8536462108391619": 10, "85433626": 11, "90176445": 11, "A": [4, 9, 11, 12, 15, 16, 19, 23, 24], "For": [3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24], "If": [6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24], "In": [1, 2, 3, 11, 29], "It": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 24, 31], "No": 21, "Not": 2, "OR": 23, "One": [6, 9], "The": [1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 31], "To": 23, "_": 7, "__call__": [4, 17, 20, 23, 29, 30, 31], "__main__": 7, "__name__": 7, "_description_": 17, "_merge_result": 31, "_postprocess_til": 31, "_resize_detect": 12, "ab": 18, "abc": [1, 31], "about": [1, 2, 3, 16], "abstract": [1, 12, 13, 17, 31], "accept": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 27, 29, 30, 31], "access": [1, 6, 17], "accord": [9, 13, 18, 23], "accumul": 7, "accur": 19, "across": 7, "act": [2, 10, 16], "action": 14, "action_classif": 9, "actionclassificationmodel": 9, "activ": [11, 19], "actual": [1, 7], "ad": [11, 22], "adapt": [4, 8, 10, 11, 16, 17, 19], "adaptor_paramet": 17, "add": [1, 2, 6, 7, 11, 22], "add_edg": 11, "add_rotated_rect": 22, "addit": [6, 7, 9, 13, 23, 29], "addorfindsoftmaxandtopkoutput": 11, "affect": 6, "after": [1, 2, 3, 7, 22], "agnost": 6, "agnostic_nm": 6, "aim": [10, 12, 15, 16], "alia": [23, 24], "align": 4, "all": [1, 2, 3, 4, 6, 7, 9, 10, 11, 13, 16, 17, 22, 23, 31], "all_output": 20, "allow": [2, 7, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 29], "alongsid": 17, "alreadi": [6, 23], "also": [1, 2, 3, 9, 11, 12, 13, 17], "alwai": 7, "an": [1, 2, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 21, 22, 23, 29, 31], "analyze_model_perform": 7, "ancestor": 11, "anchor": [6, 24], "ani": [1, 2, 3, 4, 9, 10, 13, 16, 17, 18, 21, 31], "anomal": 6, "anomali": [6, 14], "anomalib": 10, "anomaly_map": 10, "anomalybas": 6, "anomalydetect": 10, "anomalymodel": 10, "anomalyresult": 10, "anoth": 9, "api": [7, 16, 17], "appli": [1, 4, 6, 16, 17, 22, 23, 29, 30, 31], "apply_coord": 18, "apply_masks_refin": 23, "approach": [11, 16], "appropri": [9, 10, 11, 13, 15, 16, 18, 19], "ar": [1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24, 27, 30, 31], "architectur": 3, "arg": 2, "argument": [6, 23], "arrai": [4, 9, 10, 11, 13, 19], "arriv": 23, "arxiv": 18, "aspect": 6, "aspect_ratio": 6, "assum": 19, "astyp": 16, "async": [1, 2, 3, 17, 26, 27, 29, 30, 31], "async_pipelin": [25, 31], "asynchron": [1, 2, 3, 17, 31], "asyncpipelin": [25, 31], "attent": 7, "attribut": [1, 2, 3, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 27, 30, 31], "auto": [13, 17], "automat": 7, "aux": 23, "avail": [1, 2, 3, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 24], "available_wrapp": 17, "awai": 23, "await_al": [1, 2, 3, 17, 25], "await_ani": [1, 2, 3, 17, 25], "axi": 22, "b": [1, 16], "b0": 7, "back": 22, "backbon": 6, "background": 7, "base": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "base_model": 16, "base_preprocess": [9, 13, 17, 18], "base_valu": 21, "basevalu": 21, "basic": [9, 11, 13, 16], "basicconfig": 7, "batch": [9, 16], "bbox": 20, "bboxes_lay": 20, "becom": [1, 2, 3], "befor": [2, 7, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24], "being": [1, 17, 31], "below": 9, "benchmark": 7, "between": [7, 19], "bgr": [4, 9, 13], "bgr2rgb": 1, "bicycl": 11, "bin": [3, 17], "binari": 23, "block": [1, 2, 3, 17], "blur": 6, "blur_strength": [6, 19], "bool": [1, 3, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 31], "boolean": [1, 2, 3], "booleanvalu": 21, "bound": [6, 12, 15, 20, 22, 23], "box": [6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "boxeslabelspars": 20, "breakdown": 7, "brg2rgb": [1, 2, 3, 4], "build_error": 21, "built": 7, "busi": [1, 2, 3], "byte": 2, "c": 9, "cach": 17, "cache_dir": [3, 17], "call": [4, 17, 23, 29, 30, 31], "callabl": [1, 2, 3, 4, 17], "callback": [1, 2, 3, 17, 25], "callback_arg": 25, "callback_data": [1, 2, 3, 17], "callback_fn": [1, 2, 3, 17], "can": [1, 2, 3, 4, 7, 9, 16, 17, 19, 23, 29], "capabl": 7, "car": 11, "case": [1, 2, 3, 11], "cat": 11, "center": 6, "chang": [4, 9, 10, 13], "change_layout": 4, "channel": [1, 6, 9, 13], "check": [1, 2, 3, 7, 17, 23], "child": 11, "children": 11, "choic": 21, "circl": 16, "class": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "class_id": 16, "classaif": 9, "classif": [6, 14, 16], "classifi": [6, 29], "classificationmodel": [2, 7, 11], "classificationresult": [9, 11], "classmethod": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 24, 27, 31], "clear_topological_cach": 11, "clip": [9, 12, 22], "clip_detect": 22, "clip_siz": 9, "collect": [7, 17], "color": 16, "come": 16, "comma": 6, "compar": 7, "compat": 4, "compil": 17, "complet": [1, 2, 3, 17], "comprehens": 7, "comput": 22, "compute_resolut": 22, "condit": 7, "conduct": 9, "confid": [6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24], "confidence_threshold": [6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "config": 17, "configur": [2, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 27, 29, 30, 31], "configurablevalueerror": 21, "consequ": 23, "consid": [6, 7], "consist": 7, "consol": 7, "construct": 6, "constructor": [1, 3, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 27, 29, 30, 31], "construtor": [12, 20, 24], "contain": [1, 2, 3, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 29, 30, 31], "contour": [19, 22], "control": [23, 27, 29, 30, 31], "convert": [4, 18, 22], "coord": 18, "coordin": [16, 22], "copy_raw_result": 3, "core": [3, 17], "correspond": [1, 2, 9, 13, 16, 21, 23], "count": 7, "cpu": [3, 17], "creat": [1, 2, 3, 4, 6, 7, 17, 19, 22, 23, 24, 27, 29, 30, 31], "create_cor": 3, "create_hard_prediction_from_soft_predict": 19, "create_model": [6, 7, 10, 11, 12, 15, 16, 17, 19], "crop": [4, 6, 9, 16], "crop_res": 4, "crop_resize_graph": 4, "crop_resize_ocv": 4, "cubic": 4, "current": [7, 10], "custom": [6, 17], "cv": 10, "cv2": [7, 10, 11, 12, 15, 16, 19], "d1": 16, "d2": 16, "data": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 29, 30, 31], "data_1": [1, 2, 3, 17], "data_2": [1, 2, 3, 17], "dataset": 6, "decod": [6, 16, 18, 23], "decoder_model": 23, "decor": 17, "def": 7, "default": [1, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23, 24], "default_label": 20, "default_valu": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 24], "defin": [1, 2, 3, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 27, 29, 30, 31], "definit": [10, 17], "degrad": 16, "delta": 6, "depend": [17, 22, 31], "deploy": 7, "descript": [8, 9, 10, 13, 17, 18, 19, 21, 24, 27, 31], "descriptor": 17, "destroyallwindow": 15, "det": 22, "detail": 17, "detect": [7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 22, 24, 28], "detect_model_typ": 17, "detectedkeypoint": 16, "detection_model": 12, "detection_result": 16, "detectionbox": 24, "detectionmodel": [7, 12, 20, 24], "detectionresult": [12, 20, 22, 24, 27], "detectiontil": [27, 29], "detector": 16, "deviat": 7, "devic": [1, 2, 3, 7, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 31], "device1": 3, "device2": 3, "device_str": 3, "dict": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 27, 29, 30, 31], "dict_data": [1, 2, 3, 17], "dict_input": [12, 13, 15, 16, 17, 18, 20, 24], "dictionari": [1, 3, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 24, 27, 31], "dictvalu": 21, "differ": [3, 7, 9, 22], "directori": 17, "discover": 17, "disk": 1, "divid": [6, 9, 13], "do": 22, "document": 17, "doesn": 2, "done": 2, "down": [11, 16], "download": 17, "download_dir": [3, 17], "dtype": [1, 2, 3, 4, 10, 11], "due": 7, "durat": 7, "dure": [6, 22, 23], "dynam": 3, "e": [4, 17, 22], "each": [1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 23, 24, 29], "edg": 11, "efficientnet": 7, "either": 17, "emb": [1, 3], "embed": [1, 6, 16], "embed_preprocess": [1, 2, 3], "embedded_process": 6, "enabl": [19, 23], "enable_pad": 6, "encod": [18, 23], "encoder_model": 23, "end": [1, 2, 3], "enough": [16, 22], "ensur": 7, "enumer": 7, "environ": 7, "ep": 22, "error": 17, "etc": [7, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 27, 29, 30, 31], "even": 17, "everi": 7, "exampl": [9, 10, 11, 13, 17, 18, 19, 24], "except": [17, 21, 23], "exclud": 7, "exclus": 11, "execut": [1, 2, 3, 17, 23, 31], "execution_mod": [27, 29, 30, 31], "executor": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 31], "exist": 19, "expect": [20, 27, 29], "export": [10, 11, 19], "extend": [10, 11, 12, 13, 15, 18, 19, 20, 24], "extens": [2, 11, 15, 19], "extern": 2, "extra": [1, 23], "extract": 21, "f": [7, 12, 15], "factor": 22, "factori": 1, "fail": [9, 10, 11, 13, 15, 18, 19], "fals": [1, 2, 3, 4, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "featur": [6, 11, 19, 23], "feature_vector": [11, 19, 23], "few": 7, "field": [6, 23, 24], "file": [2, 3, 6, 10, 17], "filenam": 2, "filesystem": [1, 2, 17], "filter": [6, 22, 29], "final": 19, "find": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24], "find_layer_bboxes_output": 20, "find_layer_by_nam": 20, "first": [6, 7, 9, 13, 23], "fit": [1, 3, 4, 9, 13, 17, 22], "fit_to_window": [4, 6, 22], "fit_to_window_letterbox": [4, 6, 22], "flag": [1, 2, 3, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 23, 24, 31], "flags_d": 3, "flags_nstream": 3, "flags_nthread": 3, "float": [6, 11, 19, 21, 22, 23], "float64": 11, "follow": [1, 2, 3, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "forc": [16, 17, 23], "format": [1, 2, 3, 4, 6, 7, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 29, 30, 31], "forward": [2, 12, 15], "found": 19, "fp": 7, "fp16": [1, 3, 17], "fp32": 1, "framework": [1, 2, 3], "free": [17, 31], "from": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 31], "from_dict": 22, "from_openvino": 4, "from_shap": 4, "from_str": 21, "from_user_layout": 4, "full": [16, 29, 30, 31], "function": [1, 2, 3, 4, 6, 9, 13, 21], "g": [4, 17, 22], "gener": [2, 10, 13, 23], "get": [1, 2, 3, 7, 9, 11, 17], "get_all_prob": 11, "get_ancestor": 11, "get_cached_paramet": 17, "get_children": 11, "get_contour": [19, 22], "get_fp": 7, "get_hierarchical_predict": 11, "get_inference_tim": 7, "get_input_lay": [1, 2, 3], "get_input_shap": 3, "get_label_nam": 13, "get_labels_in_topological_ord": 11, "get_layout_for_input": 3, "get_load_tim": 7, "get_model": [1, 2, 3, 17, 31], "get_model_class": 17, "get_multiclass_predict": 11, "get_multilabel_predict": 11, "get_output_lay": [1, 2, 3], "get_par": 11, "get_param": 17, "get_performance_metr": [7, 17], "get_postprocess_tim": 7, "get_preprocess_tim": 7, "get_python_typ": 21, "get_raw_result": [1, 2, 3, 25], "get_result": 25, "get_rt_info": [1, 2, 3], "get_rt_info_from_dict": 4, "get_saliency_map": 11, "get_shape_from_onnx": 2, "get_subclass": 17, "get_total_fram": 7, "get_total_tim": 7, "get_total_time_max": 7, "get_total_time_min": 7, "get_user_config": 3, "get_valu": 21, "getter": 31, "given": [3, 4, 6, 9, 16, 17, 23], "go": 6, "gpu": 17, "grab": [1, 2, 3, 17], "greater": 23, "greedi": 11, "greedylabelsresolv": 11, "group": 11, "h": [9, 11, 12, 15, 19, 23, 24], "ha": [1, 2, 3, 6, 9, 12, 13, 17, 20, 24, 29], "handl": [1, 2, 3, 22], "hard": [18, 19], "has_reference_featur": 23, "have": [6, 9, 12, 16], "height": [6, 9, 11, 12, 15, 19, 22], "help": 7, "helper": 21, "hierarch": [6, 11], "hierarchi": 6, "hierarchical_config": [6, 11], "higher": 19, "hole": 19, "hook": [12, 13, 15, 16, 17, 20, 24], "http": 18, "hwc": [4, 13, 23], "hxwxa": 24, "i": [1, 2, 3, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 29, 30, 31], "i16": 1, "i32": 1, "i8": 1, "id": 25, "ident": 24, "identifi": 7, "idx": 22, "ignor": 3, "imag": [1, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 24, 31], "image1": 7, "image2": 7, "image3": 7, "image_blob_nam": [9, 13], "image_info_blob_nam": 13, "image_model": 13, "image_path": 7, "image_shap": 6, "image_threshold": 6, "imagemodel": [10, 11, 12, 13, 15, 16, 18, 19, 20, 24, 29], "imageresultwithsoftpredict": 19, "implement": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 23, 24, 31], "impli": [1, 23], "import": [7, 10, 11, 12, 15, 16, 19], "imread": [7, 10, 11, 19], "imshow": 15, "includ": [7, 11, 17, 22], "include_boundari": 22, "include_nested_contour": 19, "incorrect": 17, "independ": 22, "index": [1, 4, 13, 19], "indic": 22, "inf": 6, "infer": [0, 2, 3, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24, 27, 29, 30, 31], "infer_async": [1, 2, 3, 17], "infer_async_raw": 17, "infer_batch": 17, "infer_result": [1, 2, 3], "infer_sync": [1, 2, 3, 17], "inference_adapt": [1, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "inference_tim": 7, "inferenceadapt": [1, 2, 3, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "inferencesess": 2, "info": [1, 2, 3, 4, 7, 9, 13, 16, 22], "inform": [1, 2, 3, 7, 16, 17, 23], "inherit": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24, 31], "initi": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24], "input": [1, 2, 3, 4, 6, 7, 9, 10, 13, 17, 18, 20, 22, 23, 24, 25, 29, 30, 31], "input0": [4, 6], "input1": [4, 6], "input_data": 17, "input_idx": [1, 2, 3, 4], "input_layer_nam": [9, 13], "input_layer_name_1": [1, 2, 3, 17], "input_layer_name_2": [1, 2, 3, 17], "input_nam": [4, 6], "input_s": [6, 20, 22], "input_tensor": 3, "input_transform": [9, 13], "inputtransform": [4, 9, 13], "inst_seg_result": 22, "insta": 1, "instanc": [1, 3, 6, 7, 9, 13, 14, 17, 21, 22, 23, 24, 28, 31], "instance_segment": [15, 29], "instancesegmentationresult": 15, "instancesegmentationtil": 29, "int": [1, 2, 3, 4, 6, 9, 13, 17, 19, 21, 22, 23], "int32": 16, "interest": 16, "interfac": [1, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "intermedi": 6, "intern": [1, 2, 3, 23], "interpol": [1, 4], "interpolation_mod": [1, 2, 3, 4], "intersect": 6, "introduc": 6, "inverted_scale_i": 22, "inverted_scale_x": 22, "iou": [6, 22], "iou_threshold": [6, 22], "ir": [3, 6], "ir_v10": 3, "is_pad": 4, "is_readi": [1, 2, 3, 17, 25], "isn": [6, 9], "item": 16, "iter": [12, 15, 16], "its": 21, "jpg": [7, 10, 11, 19], "just": [1, 3], "k": 24, "keep": [9, 13, 17], "keep_aspect_ratio": 4, "keep_top_k": 22, "keepdim": 22, "kei": [1, 3, 17, 22], "kept": [4, 22], "kernel": 6, "keypoint": [14, 22], "keypoint_detect": 16, "keypointdetectionmodel": 16, "kp_model": 16, "kwarg": 21, "label": [6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "label_fil": 22, "label_id": 13, "label_nam": [12, 15], "labels_lay": 20, "larg": 22, "last": 23, "later": 29, "launch": 23, "layer": [4, 6, 13, 20], "layout": [1, 2, 3, 4, 6, 9, 13, 17, 24], "layout_str": 4, "lead": [1, 2, 3], "learn": [11, 19, 23], "left": 22, "legaci": 22, "len": [6, 7], "less": 19, "letter": 9, "letterbox": [4, 22], "level": [6, 7], "like": [6, 9, 11, 13], "limit": 2, "linear": 4, "list": [1, 2, 3, 4, 9, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 29], "listvalu": 21, "load": [1, 2, 3, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 31], "load_label": 22, "load_model": [1, 2, 3, 17], "load_parameters_from_onnx": 4, "load_tim": 7, "locat": 16, "log_layers_info": 17, "log_metr": 7, "log_runtime_set": 3, "logger": [17, 31], "logit": [11, 19, 22], "lsit": 27, "mai": [7, 13], "map": [6, 11, 19, 22, 23], "mask": [6, 15, 19, 23, 24], "maskrcnnmodel": [2, 15], "mat": 19, "match": [6, 11, 22, 23], "max": [6, 7, 11, 21, 22], "max_answer_token_num": 6, "max_num": 22, "max_num_request": [3, 17], "maximum": [6, 7], "maxmium": 7, "mean": [1, 2, 3, 4, 6, 7, 9, 13, 23], "mean_valu": [4, 6, 9], "measur": 7, "median": 7, "member": 6, "merg": 31, "messag": [7, 17, 21], "meta": [1, 2, 3, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 25], "metadata": [1, 2, 3, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 24], "method": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24, 31], "metric": 17, "might": [9, 13, 17], "min": [6, 7, 21], "minim": 7, "minimum": [7, 19], "mode": [1, 22, 27, 29, 30, 31], "model": [1, 2, 3, 4, 7, 9, 10, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "model_adapt": 18, "model_api": [1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "model_height": 22, "model_info": [1, 2, 3, 6], "model_load": [17, 31], "model_paramet": 3, "model_path": 7, "model_typ": [6, 17], "model_width": 22, "modeladaptor": 17, "modelapi": 2, "modul": 1, "more": [7, 9, 12, 13, 19, 20, 24], "most": [6, 11], "multi": [11, 22], "multiclass": [6, 11], "multiclass_nm": 22, "multilabel": 6, "multipl": [6, 7], "multipleoutputpars": 20, "multipli": 22, "must": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 31], "n": [7, 9, 16, 24], "n_label": 23, "name": [1, 2, 3, 6, 9, 11, 12, 13, 15, 16, 17, 20], "namedtupl": 23, "nc": [4, 6], "nchw": [1, 4, 6, 13, 16], "nchw_layout": 13, "ndarrai": [4, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23], "nearest": 4, "need": [1, 17, 22], "nest": [1, 2], "network": [6, 19], "new": [1, 3, 6, 17, 23, 24], "new_shap": [1, 2, 3, 17], "newli": 23, "next": 17, "nhwc": [4, 13], "ninfer": 7, "nm": [6, 22], "node": 4, "non": [6, 11], "none": [1, 2, 3, 4, 10, 11, 17, 21, 22, 23, 29], "nor": 6, "noreturn": 17, "normal": [1, 4, 6, 9, 13], "normalization_scal": 6, "note": [6, 10, 20], "now": 7, "np": [10, 12, 15, 16, 18, 22, 23], "npu": 3, "nscthw": 9, "nsthwc": 9, "nstream": 17, "nthread": 17, "num": 24, "num_class": [6, 19], "number": [6, 7, 9, 16, 17, 22, 23, 24], "numericalvalu": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 24], "numpi": 19, "obj_keypoint": 16, "object": [1, 3, 4, 11, 12, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 29], "obtain": [11, 15, 17, 18, 19, 20, 23, 24], "occur": 17, "offset": 22, "onc": 23, "one": [1, 2, 3, 6, 9, 13, 16, 17, 23, 27, 29, 30, 31], "ones": [12, 17, 23], "onli": [2, 6, 9, 13, 22], "onnx": 0, "onnx_adapt": 2, "onnx_model": 4, "onnx_shap": 2, "onnxruntim": 2, "onnxruntimeadapt": 2, "openvino": [0, 1, 2, 4, 9, 10, 11, 17, 19], "openvino_adapt": 3, "openvinoadapt": [3, 17], "openvinotoolkit": 2, "oper": [9, 11, 23], "operation_typ": 3, "operations_by_typ": 3, "option": [1, 2, 3, 4, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "order": [6, 11, 22], "org": 18, "organ": 16, "orig_s": 18, "origin": [9, 10, 12, 13, 18, 22], "original_height": 22, "original_shap": [9, 13], "original_width": 22, "ort_opt": 2, "other": [1, 6, 22], "otx": [2, 6, 10], "out": [13, 23], "output": [1, 2, 3, 6, 7, 9, 10, 17, 18, 20, 24, 27, 29], "output_layer_name_1": [1, 2, 3, 11, 15, 17, 18, 19, 20, 24], "output_layer_name_2": [1, 2, 3, 11, 15, 17, 18, 19, 20, 24], "output_layout": 24, "output_nam": 6, "output_raw_scor": [6, 11], "output_resolut": 22, "outputtransform": 22, "ov": [3, 16], "ovani": [3, 4], "over": [6, 7, 12, 15, 16], "overal": 7, "overlap": 22, "overload": [6, 9, 13], "overrid": [6, 16], "overridden": 23, "pad": [1, 4, 6, 22], "pad_left": 22, "pad_top": 22, "pad_valu": [1, 2, 3, 4, 6], "padding_mod": 6, "padim": 10, "pai": 7, "param": [17, 24], "paramet": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31], "parameterdescriptor": 17, "parent": 11, "pars": [4, 20], "parse_devic": 3, "parse_layout": 4, "parse_value_per_devic": 3, "particular": 2, "pass": [12, 15, 17, 23], "path": [1, 2, 3, 4, 6, 7, 17], "path_to_imag": [10, 11, 19], "path_to_label": 6, "path_to_model": [10, 11, 19], "per": [6, 7, 16, 19, 22, 23], "perform": [1, 2, 3, 9, 13, 17, 22], "performancemetr": [7, 17], "period": 7, "permute_to_n_hwa_k": 24, "perspect": 16, "pipelin": [4, 7, 8, 16, 23, 27, 29, 30, 31], "pixel": [6, 19], "pixel_threshold": 6, "place": 1, "plugin_config": 3, "point": [16, 19, 23], "polygon": 23, "popul": 3, "pose": 6, "possibl": [1, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24], "post": [9, 10], "postprocess": [6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 29, 30, 31], "postprocess_semantic_mask": 6, "postprocess_tim": 7, "pre": [6, 16], "precis": [1, 2, 3, 17], "pred_box": 10, "pred_i": 16, "pred_label": 10, "pred_mask": 10, "pred_scor": 10, "pred_x": 16, "predecessor": 11, "predict": [6, 10, 11, 12, 15, 16, 18, 19, 23, 29], "predict_crop": 16, "prefix": 21, "preload": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "prepar": [17, 23], "prepostprocessor": 9, "preprocess": [1, 2, 3, 4, 6, 7, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "preprocess_tim": 7, "preprocessed_imag": [9, 13], "present": [16, 17, 23], "previou": 23, "previous": 23, "print": [7, 12, 15, 17], "prioriti": 6, "probabilisticlabelsresolv": 11, "probabl": [6, 11], "process": [6, 9, 10, 17, 18], "produc": 19, "product": 7, "progress": 7, "prompt": [14, 18], "prompter": 23, "properti": [9, 17, 23], "provid": [1, 2, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 23, 24, 31], "py": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24], "python": [1, 3, 4, 6, 16, 21], "pytorch": 7, "qualiti": 16, "r": 1, "radiu": 16, "rais": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24], "raise_error": 17, "rang": [7, 13], "ratio": 6, "raw": [1, 2, 3, 6, 10, 11, 15, 16, 17, 18, 19, 20, 24, 29, 30, 31], "raw_result_1": [1, 2, 3, 11, 15, 17, 18, 19, 20, 24], "raw_result_2": [1, 2, 3, 11, 15, 17, 18, 19, 20, 24], "raw_scor": 11, "read": 1, "readi": 17, "reason": 9, "reduc": 17, "refer": [2, 23], "reference_featur": 23, "refin": 23, "reflect": 23, "region": 6, "regress": 16, "reimplement": 24, "relat": 23, "remov": 11, "reorder": 11, "report": 7, "repres": [3, 11, 16, 19, 23], "represent": [1, 2, 3, 6, 16], "request": [1, 2, 3, 17, 25], "reset": 7, "reset_featur": 23, "reset_reference_info": 23, "reshap": [1, 2, 3, 6, 17, 24], "reshape_dynamic_input": 3, "reshape_model": [1, 2, 3], "resiz": [1, 4, 6, 9, 12, 13, 22], "resize_imag": 4, "resize_image_graph": 4, "resize_image_letterbox": [4, 6], "resize_image_letterbox_graph": 4, "resize_image_letterbox_ocv": 4, "resize_image_ocv": 4, "resize_image_with_aspect": 4, "resize_image_with_aspect_ocv": 4, "resize_info": 22, "resize_mod": [1, 2, 3, 4], "resize_typ": [6, 9, 13, 22], "resized_shap": [9, 13], "resizemetadata": 22, "resolut": 6, "resolv": 11, "resolve_label": 11, "respect": [11, 12, 15, 19], "result": [1, 2, 3, 7, 10, 11, 12, 17, 19, 22, 23, 31], "resultimag": 19, "retriev": 17, "return": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31], "return_soft_predict": 6, "revers": 6, "reverse_input_channel": [4, 6], "rgb": [4, 9, 13], "right": 23, "right_bottom": 6, "rotatedsegmentationresult": 22, "routin": 17, "rt": [3, 16], "rt_info": 6, "rt_info_dict": 4, "run": [2, 7, 17, 23], "salienc": [11, 19], "saliency_map": [11, 19], "sam": [14, 23], "sam_model": 18, "samdecod": [18, 23], "same": 23, "samimageencod": [18, 23], "samlearnablevisualprompt": 23, "samvisualprompt": 23, "save": [1, 2, 3, 17], "save_model": [1, 2, 3], "scale": [1, 2, 3, 4, 6, 9, 13, 22], "scale_valu": [4, 6], "scc": 16, "scope": 2, "score": [6, 11, 12, 15, 16, 20, 22, 29], "scoredlabel": 11, "scores_lay": 20, "scratch": 23, "search": 19, "second": 7, "secondari": 13, "section": 6, "see": [9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 24], "seg_result": 22, "segment": [6, 14, 23, 28], "segmentationmodel": [2, 18, 19], "segmentedobject": 29, "select": 11, "self": [4, 11], "semant": [28, 29], "semantic_segment": 30, "semanticsegmentationtil": 30, "separ": [1, 6, 15, 17], "sequenc": [1, 2, 6, 23], "serial": [1, 2, 3, 6, 17], "session": 2, "set": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 27, 30, 31], "set_callback": [1, 2, 3, 17], "set_strides_grid": 24, "setup_python_preprocessing_pipelin": 4, "shape": [1, 2, 3, 4, 6, 10, 11, 12, 15, 17, 19, 23], "should": [1, 2, 3, 6, 9, 12, 13, 17, 23], "shown": 17, "side": 24, "sigmoid": 24, "sigmoid_numpi": 11, "signific": 7, "simcc": 16, "similar": 31, "simpl": 16, "simplelabelsgraph": 11, "simplest": 7, "singl": [4, 9, 10, 11, 12, 13, 15, 16, 19], "singleoutputpars": 20, "size": [4, 6, 9, 13, 16, 18, 22], "size_divisor": 6, "skip": [17, 23], "slower": 7, "smoother": 19, "so": [9, 22], "soft": [18, 19], "soft_predict": 19, "soft_threshold": [6, 19], "softmax": 22, "some": 1, "sort": 7, "sourc": 23, "space": 22, "specif": [1, 2, 3, 7, 9, 10, 13, 17, 18, 20, 24, 27, 29, 30, 31], "specifi": [3, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24], "spent": 7, "squad": 6, "squad_ver": 6, "ssd": [2, 12, 14, 17], "stage": [7, 23], "standard": [4, 6, 7, 22], "start": [7, 23], "state": [7, 23], "static": [3, 4, 6, 20], "std": 7, "stddev": 7, "step": [1, 2, 11], "stfpm": 10, "storag": 22, "store": [1, 2, 6, 17, 23], "str": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 21, 22, 30, 31], "strategi": 22, "stream": 17, "strict": 19, "stricter": 23, "string": [2, 6], "stringvalu": 21, "structur": [1, 2, 3, 17, 31], "style": [2, 17], "subclass": [17, 21], "submiss": [1, 2, 3], "submit": [1, 2, 3, 17], "submit_data": 25, "subtract": [6, 9, 13], "summari": 7, "support": [2, 9, 10, 11, 13], "suppress": 6, "suquenc": 3, "swap": 1, "switch": [9, 13], "sync": [27, 29, 30, 31], "synchron": [1, 2, 3, 17], "system": 7, "t": [2, 6, 9], "tag": [1, 2, 3], "take": 6, "taken": [1, 2, 3, 6, 11], "target": [1, 4], "target_s": 6, "target_shap": [1, 2, 3, 4], "task": 6, "tensor": [9, 13, 16, 24], "term": 24, "test": 7, "test_imag": 7, "test_run": 7, "than": [12, 20, 24], "thei": [1, 6, 11, 17], "them": 7, "thi": [1, 2, 6, 7, 9, 10, 11, 16, 19, 27, 29], "thick": 16, "thread": 17, "thresh": 22, "threshold": [6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 22, 23, 24], "through": 7, "thrown": 23, "tight": 16, "tile": [27, 29, 30, 31], "tile_classifier_model": 29, "tile_prob": 29, "tile_s": [27, 29, 30, 31], "tiler": [8, 27, 29, 30], "tiles_overlap": [27, 29, 30, 31], "time": [9, 17, 23], "to_dict": 22, "todo": [0, 8, 14, 26, 28], "token": 6, "top": [2, 11, 16, 22], "top_down_detector": 16, "top_down_pipelin": 16, "top_label": 11, "topdownkeypointdetectionpipelin": 16, "topk": [6, 11], "topological_sort": 11, "torchvis": 23, "total": 7, "total_fram": 7, "total_max_tim": 7, "total_min_tim": 7, "total_tim": 7, "train": [2, 6, 11, 19], "training_extens": 2, "transform": 22, "transpos": 24, "tree": 11, "true": [6, 11, 17, 19, 23], "tupl": [1, 4, 11, 12, 13, 15, 16, 18, 20, 22, 23, 24], "two": [3, 6, 9, 11, 16], "type": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 27, 29, 30, 31], "u8": 1, "uint8": 10, "ultralyt": 24, "under": [1, 2], "underli": [16, 17, 27, 29, 30, 31], "union": 6, "until": [1, 2, 3], "unus": 4, "up": [3, 4], "updat": [1, 2, 18, 23], "update_default_valu": 21, "update_model_info": [1, 2, 3], "upgrad": 10, "upsampl": 6, "upsample_ratio": 6, "us": [1, 2, 6, 7, 9, 11, 12, 13, 16, 17, 18, 19, 23, 29], "usag": 23, "used_indic": 23, "user": 4, "user_data": 17, "user_layout": 4, "usual": 19, "util": [0, 14], "v": 23, "valid": 21, "valu": [1, 2, 3, 4, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 29, 30, 31], "value1": 3, "value2": 3, "value_typ": 21, "valueerror": 21, "values_str": 3, "variabl": 17, "vector": [11, 16, 19], "version": [1, 2, 3, 6, 17], "vertic": 11, "via": [2, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24], "video": 9, "view": 7, "visual": 14, "visual_prompt": 23, "visualpromptingfeatur": 23, "visualpromptingresult": 23, "vocab": 6, "vpt": 23, "w": [9, 11, 12, 15, 19, 23, 24], "wai": 7, "wait": [1, 2, 3, 17], "waitkei": 15, "warmup_cach": 11, "warmup_run": 7, "we": [1, 22], "weight": [1, 3, 17], "weights_path": [1, 2, 3, 17], "well": 11, "what": 9, "when": [7, 10, 23], "where": [11, 12, 15, 16, 17, 19, 23], "whether": [1, 2, 3, 4, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24, 31], "which": [1, 2, 3, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 23, 24, 27, 29, 30, 31], "while": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24], "width": [6, 9, 11, 12, 15, 19, 22], "window": 22, "within": 16, "without": 23, "work": [3, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24], "workflow": 23, "would": 1, "wrap": [3, 20], "wrapper": [2, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24, 27, 29, 30, 31], "wrapper_nam": 17, "wrappererror": [9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 24], "wrappernam": 17, "write": [1, 2, 17], "x": [9, 11, 16, 22, 23, 24], "x1": [12, 15, 22], "x2": [12, 15, 22], "x_max": 16, "x_min": 16, "xmax": 20, "xmin": 20, "xml": [3, 6, 7, 10, 11, 12, 15, 16, 19], "xy": 23, "xywh": 24, "xywh2xyxi": 24, "xyxi": 23, "y": [16, 22, 24], "y1": [12, 15, 22], "y2": [12, 15, 22], "y_max": 16, "y_min": 16, "ymax": 20, "ymin": 20, "yolo": 14, "yolof": 24, "yolov3onnx": 24, "yolov4": 24, "yolov5": 24, "yolov8": 24, "yolox": 24, "you": 7, "your": 7, "zip": [12, 15], "zoo": 17, "zsl": 23, "zslvisualpromptingresult": 23}, "titles": ["Adapters", "Inference Adapter", "Onnx Adapter", "Openvino Adapter", "Utils", "Guides", "Model configuration", "Performance Metrics", "Model API Documentation", "Action Classification", "Anomaly", "Classification", "Detection Model", "Image Model", "Models", "Instance Segmentation", "Keypoint Detection", "Model", "Sam Models", "Segmentation", "Ssd", "Types", "Utils", "Visual Prompting", "Yolo", "Async Pipeline", "Pipelines", "Detection", "Tilers", "Instance Segmentation", "Semantic Segmentation", "Tiler"], "titleterms": {"access": 7, "action": 9, "actionclassificationmodel": 6, "adapt": [0, 1, 2, 3], "advanc": 7, "analysi": 7, "analyz": 7, "anomali": 10, "anomalydetect": 6, "api": 8, "async": 25, "basic": 7, "batch": 7, "bert": 6, "bertquestionansw": 6, "best": 7, "bottleneck": 7, "classif": [9, 11], "classificationmodel": 6, "complet": 7, "configur": 6, "consider": 7, "ctpn": 6, "descript": [11, 12, 15, 16], "detail": 7, "detect": [12, 16, 27], "detectionmodel": 6, "document": 8, "dure": 7, "exampl": [7, 12, 15, 16], "facebox": 6, "frame": 7, "guid": 5, "hpeassociativeembed": 6, "imag": 13, "imagemodel": 6, "individu": 7, "infer": [1, 7], "input": [11, 12, 15, 16, 19], "instanc": [15, 29], "its": 6, "keypoint": 16, "list": 6, "log": 7, "maskrcnnmodel": 6, "metric": 7, "model": [6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19], "monitor": 7, "nanodet": 6, "onnx": 2, "openpos": 6, "openvino": [3, 12, 15, 16], "optim": 7, "output": [11, 12, 15, 16, 19], "overview": 7, "paramet": 16, "perform": 7, "pipelin": [25, 26], "practic": 7, "process": 7, "prompt": 23, "rate": 7, "refer": 8, "sam": 18, "segment": [15, 19, 29, 30], "segmentationmodel": 6, "semant": 30, "specif": [11, 12, 15, 16, 19], "ssd": 20, "statist": 7, "subclass": 6, "throughput": 7, "tiler": [28, 31], "time": 7, "tip": 7, "type": 21, "ultralightweightfacedetect": 6, "up": 7, "usag": 7, "util": [4, 22], "valu": 6, "visual": 23, "warm": 7, "yolo": [6, 24], "yolov4": 6, "yolov5": 6, "yolov8": 6, "yolox": 6}})