Search.setIndex({"alltitles": {"Action Classification": [[44, null]], "ActionClassificationModel": [[35, "actionclassificationmodel"]], "Adapters": [[0, null], [37, null]], "Anomaly": [[45, null]], "Anomaly Model": [[2, null]], "Anomaly Result": [[17, "anomaly-result"]], "AnomalyDetection": [[35, "anomalydetection"]], "Args Helper": [[24, null]], "Async Infer Queue": [[25, null]], "Async Pipeline": [[60, null]], "Bert and its subclasses": [[35, "bert-and-its-subclasses"]], "BertQuestionAnswering": [[35, "bertquestionanswering"]], "C++ API Reference": [[1, null], [36, "c-api-reference"]], "CTPN": [[35, "ctpn"]], "Classification": [[46, null]], "Classification Model": [[3, null]], "Classification Result": [[17, "classification-result"]], "ClassificationModel": [[35, "classificationmodel"]], "Common": [[26, null]], "Contour": [[17, "contour"]], "Description": [[46, "description"], [47, "description"], [50, "description"], [51, "description"]], "Detected Object": [[17, "detected-object"]], "DetectedKeypoints": [[17, "detectedkeypoints"]], "Detection": [[19, null], [62, null]], "Detection Model": [[4, null], [47, null]], "Detection Model Ext": [[5, null]], "Detection Model SSD": [[6, null]], "Detection Model Yolo": [[7, null]], "Detection Model YoloX": [[9, null]], "Detection Model Yolov3 ONNX": [[8, null]], "Detection Result": [[17, "detection-result"]], "DetectionModel and its subclasses": [[35, "detectionmodel-and-its-subclasses"]], "Example": [[47, "example"], [50, "example"], [51, "example"]], "FaceBoxes": [[35, "faceboxes"]], "Greedy Labels Resolver": [[3, "greedy-labels-resolver"]], "Guides": [[34, null]], "HpeAssociativeEmbedding": [[35, "hpeassociativeembedding"]], "HumanPose": [[17, "humanpose"]], "HumanPoseResult": [[17, "humanposeresult"]], "Image Model": [[10, null], [48, null]], "Image Result": [[17, "image-result"]], "Image Utils": [[27, null]], "ImageInput Data": [[12, "imageinput-data"]], "ImageModel and its subclasses": [[35, "imagemodel-and-its-subclasses"]], "ImageResult With Soft Prediction": [[17, "imageresult-with-soft-prediction"]], "Inference Adapter": [[38, null]], "Inference Result": [[17, "inference-result"]], "InferenceSDK Documentation": [[36, null]], "Input Data": [[12, null]], "Inputs": [[46, "inputs"], [47, "inputs"], [50, "inputs"], [51, "inputs"], [54, "inputs"]], "Instance Segmentation": [[13, null], [21, null], [50, null], [64, null]], "Instance Segmentation Result": [[17, "instance-segmentation-result"]], "Internal Model Data": [[14, null]], "InternalScaleData": [[14, "internalscaledata"]], "InternamImageModelData": [[14, "internamimagemodeldata"]], "Keypoint Detection": [[15, null], [51, null]], "KeypointDetectionResult": [[17, "keypointdetectionresult"]], "Kuhn Munkres": [[29, null]], "List of values": [[35, "list-of-values"]], "MaskRCNNModel": [[35, "maskrcnnmodel"]], "Model": [[52, null]], "Model Base": [[16, null]], "Model Specifications": [[46, "model-specifications"], [54, "model-specifications"]], "Model configuration": [[35, null]], "Models": [[11, null], [49, null], [51, "models"]], "NanoDet": [[35, "nanodet"]], "Nms": [[30, null]], "Ocv Common": [[31, null]], "Onnx Adapter": [[39, null]], "OpenPose": [[35, "openpose"]], "OpenVINO Model Specifications": [[47, "openvino-model-specifications"], [50, "openvino-model-specifications"], [51, "openvino-model-specifications"]], "Openvino Adapter": [[40, null]], "Outputs": [[46, "outputs"], [47, "outputs"], [50, "outputs"], [51, "outputs"], [54, "outputs"]], "Ovms Adapter": [[41, null]], "Parameters": [[51, "parameters"]], "Performance Metrics": [[32, null]], "Pipelines": [[61, null]], "Probabilistic Labels Resolver": [[3, "probabilistic-labels-resolver"]], "Python API Reference": [[36, "python-api-reference"], [43, null]], "Result Base": [[17, "result-base"]], "ResultBase": [[17, "resultbase"]], "Results": [[17, null]], "RetinaFace Detection Result": [[17, "retinaface-detection-result"]], "Sam Models": [[53, null]], "Segmentation": [[54, null]], "Segmentation Model": [[18, null]], "SegmentationModel and its subclasses": [[35, "segmentationmodel-and-its-subclasses"]], "Segmented Object": [[17, "segmented-object"]], "Segmented Object With Rects": [[17, "segmented-object-with-rects"]], "Semantic Segmentation": [[22, null], [65, null]], "Simple Labels Graph": [[3, "simple-labels-graph"]], "Slog": [[33, null]], "Ssd": [[55, null]], "Tiler": [[66, null]], "Tiler Base": [[23, null]], "Tilers": [[20, null], [63, null]], "Types": [[56, null]], "UltraLightweightFaceDetection": [[35, "ultralightweightfacedetection"]], "Utils": [[28, null], [42, null], [57, null]], "Visual Prompting": [[58, null]], "YOLO and its subclasses": [[35, "yolo-and-its-subclasses"]], "YOLOX": [[35, "yolox"]], "YOLOv5, YOLOv8": [[35, "yolov5-yolov8"]], "Yolo": [[59, null]], "YoloV4": [[35, "yolov4"]]}, "docnames": ["cpp/adapters/index", "cpp/index", "cpp/models/anomaly_model", "cpp/models/classification_model", "cpp/models/detection_model", "cpp/models/detection_model_ext", "cpp/models/detection_model_ssd", "cpp/models/detection_model_yolo", "cpp/models/detection_model_yolov3_onnx", "cpp/models/detection_model_yolox", "cpp/models/image_model", "cpp/models/index", "cpp/models/input_data", "cpp/models/instance_segmentation", "cpp/models/internal_model_data", "cpp/models/keypoint_detection", "cpp/models/model_base", "cpp/models/results", "cpp/models/segmentation_model", "cpp/tilers/detection", "cpp/tilers/index", "cpp/tilers/instance_segmentation", "cpp/tilers/semantic_segmentation", "cpp/tilers/tiler_base", "cpp/utils/args_helper", "cpp/utils/async_infer_queue", "cpp/utils/common", "cpp/utils/image_utils", "cpp/utils/index", "cpp/utils/kuhn_munkres", "cpp/utils/nms", "cpp/utils/ocv_common", "cpp/utils/performance_metrics", "cpp/utils/slog", "guides/index", "guides/model-configuration", "index", "python/adapters/index", "python/adapters/inference_adapter", "python/adapters/onnx_adapter", "python/adapters/openvino_adapter", "python/adapters/ovms_adapter", "python/adapters/utils", "python/index", "python/models/action_classification", "python/models/anomaly", "python/models/classification", "python/models/detection_model", "python/models/image_model", "python/models/index", "python/models/instance_segmentation", "python/models/keypoint_detection", "python/models/model", "python/models/sam_models", "python/models/segmentation", "python/models/ssd", "python/models/types", "python/models/utils", "python/models/visual_prompting", "python/models/yolo", "python/pipelines/async_pipeline", "python/pipelines/index", "python/tilers/detection", "python/tilers/index", "python/tilers/instance_segmentation", "python/tilers/semantic_segmentation", "python/tilers/tiler"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["cpp/adapters/index.md", "cpp/index.md", "cpp/models/anomaly_model.md", "cpp/models/classification_model.md", "cpp/models/detection_model.md", "cpp/models/detection_model_ext.md", "cpp/models/detection_model_ssd.md", "cpp/models/detection_model_yolo.md", "cpp/models/detection_model_yolov3_onnx.md", "cpp/models/detection_model_yolox.md", "cpp/models/image_model.md", "cpp/models/index.md", "cpp/models/input_data.md", "cpp/models/instance_segmentation.md", "cpp/models/internal_model_data.md", "cpp/models/keypoint_detection.md", "cpp/models/model_base.md", "cpp/models/results.md", "cpp/models/segmentation_model.md", "cpp/tilers/detection.md", "cpp/tilers/index.md", "cpp/tilers/instance_segmentation.md", "cpp/tilers/semantic_segmentation.md", "cpp/tilers/tiler_base.md", "cpp/utils/args_helper.md", "cpp/utils/async_infer_queue.md", "cpp/utils/common.md", "cpp/utils/image_utils.md", "cpp/utils/index.md", "cpp/utils/kuhn_munkres.md", "cpp/utils/nms.md", "cpp/utils/ocv_common.md", "cpp/utils/performance_metrics.md", "cpp/utils/slog.md", "guides/index.md", "guides/model-configuration.md", "index.md", "python/adapters/index.md", "python/adapters/inference_adapter.md", "python/adapters/onnx_adapter.md", "python/adapters/openvino_adapter.md", "python/adapters/ovms_adapter.md", "python/adapters/utils.md", "python/index.md", "python/models/action_classification.md", "python/models/anomaly.md", "python/models/classification.md", "python/models/detection_model.md", "python/models/image_model.md", "python/models/index.md", "python/models/instance_segmentation.md", "python/models/keypoint_detection.md", "python/models/model.md", "python/models/sam_models.md", "python/models/segmentation.md", "python/models/ssd.md", "python/models/types.md", "python/models/utils.md", "python/models/visual_prompting.md", "python/models/yolo.md", "python/pipelines/async_pipeline.md", "python/pipelines/index.md", "python/tilers/detection.md", "python/tilers/index.md", "python/tilers/instance_segmentation.md", "python/tilers/semantic_segmentation.md", "python/tilers/tiler.md"], "indexentries": {"__call__() (model_api.adapters.utils.inputtransform method)": [[42, "model_api.adapters.utils.InputTransform.__call__", false]], "__call__() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.__call__", false]], "__call__() (model_api.models.ssd.boxeslabelsparser method)": [[55, "model_api.models.ssd.BoxesLabelsParser.__call__", false]], "__call__() (model_api.models.ssd.multipleoutputparser method)": [[55, "model_api.models.ssd.MultipleOutputParser.__call__", false]], "__call__() (model_api.models.ssd.singleoutputparser method)": [[55, "model_api.models.ssd.SingleOutputParser.__call__", false]], "__call__() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[58, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.__call__", false]], "__call__() (model_api.models.visual_prompting.samvisualprompter method)": [[58, "model_api.models.visual_prompting.SAMVisualPrompter.__call__", false]], "__call__() (model_api.tilers.instance_segmentation.instancesegmentationtiler method)": [[64, "model_api.tilers.instance_segmentation.InstanceSegmentationTiler.__call__", false]], "__call__() (model_api.tilers.semantic_segmentation.semanticsegmentationtiler method)": [[65, "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler.__call__", false]], "__call__() (model_api.tilers.tiler.tiler method)": [[66, "model_api.tilers.tiler.Tiler.__call__", false]], "actionclassificationmodel (class in model_api.models.action_classification)": [[44, "model_api.models.action_classification.ActionClassificationModel", false]], "add_edge() (model_api.models.classification.simplelabelsgraph method)": [[46, "model_api.models.classification.SimpleLabelsGraph.add_edge", false]], "add_rotated_rects() (in module model_api.models.utils)": [[57, "model_api.models.utils.add_rotated_rects", false]], "addorfindsoftmaxandtopkoutputs() (in module model_api.models.classification)": [[46, "model_api.models.classification.addOrFindSoftmaxAndTopkOutputs", false]], "anomalydetection (class in model_api.models.anomaly)": [[45, "model_api.models.anomaly.AnomalyDetection", false]], "apply_coords() (model_api.models.sam_models.samdecoder method)": [[53, "model_api.models.sam_models.SAMDecoder.apply_coords", false]], "async_pipeline (model_api.tilers.tiler.tiler attribute)": [[66, "model_api.tilers.tiler.Tiler.async_pipeline", false]], "asyncpipeline (class in model_api.pipelines.async_pipeline)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline", false]], "available_wrappers() (model_api.models.model.model class method)": [[52, "model_api.models.model.Model.available_wrappers", false]], "await_all() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.await_all", false]], "await_all() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.await_all", false]], "await_all() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.await_all", false]], "await_all() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.await_all", false]], "await_all() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.await_all", false]], "await_all() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline.await_all", false]], "await_any() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.await_any", false]], "await_any() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.await_any", false]], "await_any() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.await_any", false]], "await_any() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.await_any", false]], "await_any() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.await_any", false]], "await_any() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline.await_any", false]], "basevalue (class in model_api.models.types)": [[56, "model_api.models.types.BaseValue", false]], "booleanvalue (class in model_api.models.types)": [[56, "model_api.models.types.BooleanValue", false]], "boxeslabelsparser (class in model_api.models.ssd)": [[55, "model_api.models.ssd.BoxesLabelsParser", false]], "build_error() (model_api.models.types.basevalue method)": [[56, "model_api.models.types.BaseValue.build_error", false]], "callback() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline.callback", false]], "change_layout() (in module model_api.adapters.onnx_adapter)": [[39, "model_api.adapters.onnx_adapter.change_layout", false]], "classificationmodel (class in model_api.models.classification)": [[46, "model_api.models.classification.ClassificationModel", false]], "clear_topological_cache() (model_api.models.classification.simplelabelsgraph method)": [[46, "model_api.models.classification.SimpleLabelsGraph.clear_topological_cache", false]], "clip_detections() (in module model_api.models.utils)": [[57, "model_api.models.utils.clip_detections", false]], "clip_size (model_api.models.action_classification.actionclassificationmodel property)": [[44, "model_api.models.action_classification.ActionClassificationModel.clip_size", false]], "compute_resolution() (model_api.models.utils.outputtransform method)": [[57, "model_api.models.utils.OutputTransform.compute_resolution", false]], "configurablevalueerror": [[56, "model_api.models.types.ConfigurableValueError", false]], "copy_raw_result() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.copy_raw_result", false]], "create_core() (in module model_api.adapters.openvino_adapter)": [[40, "model_api.adapters.openvino_adapter.create_core", false]], "create_hard_prediction_from_soft_prediction() (in module model_api.models.segmentation)": [[54, "model_api.models.segmentation.create_hard_prediction_from_soft_prediction", false]], "create_model() (model_api.models.model.model class method)": [[52, "model_api.models.model.Model.create_model", false]], "crop_resize() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.crop_resize", false]], "crop_resize_graph() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.crop_resize_graph", false]], "crop_resize_ocv() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.crop_resize_ocv", false]], "data (model_api.models.visual_prompting.prompt attribute)": [[58, "model_api.models.visual_prompting.Prompt.data", false]], "detectionbox (class in model_api.models.yolo)": [[59, "model_api.models.yolo.DetectionBox", false]], "detectionmodel (class in model_api.models.detection_model)": [[47, "model_api.models.detection_model.DetectionModel", false]], "detectiontiler (class in model_api.tilers.detection)": [[62, "model_api.tilers.detection.DetectionTiler", false]], "dictvalue (class in model_api.models.types)": [[56, "model_api.models.types.DictValue", false]], "embed_preprocessing() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.embed_preprocessing", false]], "embed_preprocessing() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.embed_preprocessing", false]], "execution_mode (model_api.tilers.tiler.tiler attribute)": [[66, "model_api.tilers.tiler.Tiler.execution_mode", false]], "execution_modes (model_api.tilers.tiler.tiler attribute)": [[66, "model_api.tilers.tiler.Tiler.EXECUTION_MODES", false]], "feature_vectors (model_api.models.visual_prompting.visualpromptingfeatures attribute)": [[58, "model_api.models.visual_prompting.VisualPromptingFeatures.feature_vectors", false]], "find_layer_bboxes_output() (model_api.models.ssd.boxeslabelsparser static method)": [[55, "model_api.models.ssd.BoxesLabelsParser.find_layer_bboxes_output", false]], "find_layer_by_name() (in module model_api.models.ssd)": [[55, "model_api.models.ssd.find_layer_by_name", false]], "from_openvino() (model_api.adapters.utils.layout static method)": [[42, "model_api.adapters.utils.Layout.from_openvino", false]], "from_shape() (model_api.adapters.utils.layout static method)": [[42, "model_api.adapters.utils.Layout.from_shape", false]], "from_str() (model_api.models.types.booleanvalue method)": [[56, "model_api.models.types.BooleanValue.from_str", false]], "from_str() (model_api.models.types.dictvalue method)": [[56, "model_api.models.types.DictValue.from_str", false]], "from_str() (model_api.models.types.listvalue method)": [[56, "model_api.models.types.ListValue.from_str", false]], "from_str() (model_api.models.types.numericalvalue method)": [[56, "model_api.models.types.NumericalValue.from_str", false]], "from_str() (model_api.models.types.stringvalue method)": [[56, "model_api.models.types.StringValue.from_str", false]], "from_user_layouts() (model_api.adapters.utils.layout static method)": [[42, "model_api.adapters.utils.Layout.from_user_layouts", false]], "get_all_probs() (model_api.models.classification.classificationmodel method)": [[46, "model_api.models.classification.ClassificationModel.get_all_probs", false]], "get_ancestors() (model_api.models.classification.simplelabelsgraph method)": [[46, "model_api.models.classification.SimpleLabelsGraph.get_ancestors", false]], "get_children() (model_api.models.classification.simplelabelsgraph method)": [[46, "model_api.models.classification.SimpleLabelsGraph.get_children", false]], "get_contours() (in module model_api.models.utils)": [[57, "model_api.models.utils.get_contours", false]], "get_contours() (model_api.models.segmentation.segmentationmodel method)": [[54, "model_api.models.segmentation.SegmentationModel.get_contours", false]], "get_hierarchical_predictions() (model_api.models.classification.classificationmodel method)": [[46, "model_api.models.classification.ClassificationModel.get_hierarchical_predictions", false]], "get_input_layers() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_input_layers", false]], "get_input_layers() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.get_input_layers", false]], "get_input_shape() (in module model_api.adapters.openvino_adapter)": [[40, "model_api.adapters.openvino_adapter.get_input_shape", false]], "get_label_name() (model_api.models.image_model.imagemodel method)": [[48, "model_api.models.image_model.ImageModel.get_label_name", false]], "get_labels_in_topological_order() (model_api.models.classification.simplelabelsgraph method)": [[46, "model_api.models.classification.SimpleLabelsGraph.get_labels_in_topological_order", false]], "get_layout_for_input() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_layout_for_input", false]], "get_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.get_model", false]], "get_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_model", false]], "get_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_model", false]], "get_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.get_model", false]], "get_model() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.get_model", false]], "get_model() (model_api.tilers.tiler.tiler method)": [[66, "model_api.tilers.tiler.Tiler.get_model", false]], "get_model_class() (model_api.models.model.model class method)": [[52, "model_api.models.model.Model.get_model_class", false]], "get_multiclass_predictions() (model_api.models.classification.classificationmodel method)": [[46, "model_api.models.classification.ClassificationModel.get_multiclass_predictions", false]], "get_multilabel_predictions() (model_api.models.classification.classificationmodel method)": [[46, "model_api.models.classification.ClassificationModel.get_multilabel_predictions", false]], "get_output_layers() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_output_layers", false]], "get_output_layers() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.get_output_layers", false]], "get_parent() (model_api.models.classification.simplelabelsgraph method)": [[46, "model_api.models.classification.SimpleLabelsGraph.get_parent", false]], "get_raw_result() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_raw_result", false]], "get_raw_result() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.get_raw_result", false]], "get_raw_result() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline.get_raw_result", false]], "get_result() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline.get_result", false]], "get_rt_info() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.get_rt_info", false]], "get_rt_info() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.get_rt_info", false]], "get_rt_info_from_dict() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.get_rt_info_from_dict", false]], "get_saliency_maps() (model_api.models.classification.classificationmodel method)": [[46, "model_api.models.classification.ClassificationModel.get_saliency_maps", false]], "get_shape_from_onnx() (in module model_api.adapters.onnx_adapter)": [[39, "model_api.adapters.onnx_adapter.get_shape_from_onnx", false]], "get_subclasses() (model_api.models.model.model class method)": [[52, "model_api.models.model.Model.get_subclasses", false]], "get_user_config() (in module model_api.adapters.openvino_adapter)": [[40, "model_api.adapters.openvino_adapter.get_user_config", false]], "get_value() (model_api.models.types.basevalue method)": [[56, "model_api.models.types.BaseValue.get_value", false]], "greedylabelsresolver (class in model_api.models.classification)": [[46, "model_api.models.classification.GreedyLabelsResolver", false]], "h (model_api.models.yolo.detectionbox attribute)": [[59, "model_api.models.yolo.DetectionBox.h", false]], "has_reference_features() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[58, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.has_reference_features", false]], "image_blob_name (model_api.models.action_classification.actionclassificationmodel attribute)": [[44, "model_api.models.action_classification.ActionClassificationModel.image_blob_name", false]], "image_blob_name (model_api.models.image_model.imagemodel attribute)": [[48, "model_api.models.image_model.ImageModel.image_blob_name", false]], "image_blob_names (model_api.models.action_classification.actionclassificationmodel attribute)": [[44, "model_api.models.action_classification.ActionClassificationModel.image_blob_names", false]], "image_blob_names (model_api.models.image_model.imagemodel attribute)": [[48, "model_api.models.image_model.ImageModel.image_blob_names", false]], "image_info_blob_names (model_api.models.image_model.imagemodel attribute)": [[48, "model_api.models.image_model.ImageModel.image_info_blob_names", false]], "imagemodel (class in model_api.models.image_model)": [[48, "model_api.models.image_model.ImageModel", false]], "infer() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[58, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.infer", false]], "infer() (model_api.models.visual_prompting.samvisualprompter method)": [[58, "model_api.models.visual_prompting.SAMVisualPrompter.infer", false]], "infer_async() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.infer_async", false]], "infer_async() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.infer_async", false]], "infer_async() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.infer_async", false]], "infer_async() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.infer_async", false]], "infer_async() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.infer_async", false]], "infer_async_raw() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.infer_async_raw", false]], "infer_batch() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.infer_batch", false]], "infer_sync() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.infer_sync", false]], "infer_sync() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.infer_sync", false]], "infer_sync() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.infer_sync", false]], "inference_adapter (model_api.models.model.model attribute)": [[52, "model_api.models.model.Model.inference_adapter", false]], "inferenceadapter (class in model_api.adapters.inference_adapter)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter", false]], "input_transform (model_api.models.action_classification.actionclassificationmodel attribute)": [[44, "model_api.models.action_classification.ActionClassificationModel.input_transform", false]], "input_transform (model_api.models.image_model.imagemodel attribute)": [[48, "model_api.models.image_model.ImageModel.input_transform", false]], "inputs (model_api.models.model.model attribute)": [[52, "model_api.models.model.Model.inputs", false]], "inputtransform (class in model_api.adapters.utils)": [[42, "model_api.adapters.utils.InputTransform", false]], "instancesegmentationtiler (class in model_api.tilers.instance_segmentation)": [[64, "model_api.tilers.instance_segmentation.InstanceSegmentationTiler", false]], "is_ready() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.is_ready", false]], "is_ready() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.is_ready", false]], "is_ready() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.is_ready", false]], "is_ready() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.is_ready", false]], "is_ready() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.is_ready", false]], "is_ready() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline.is_ready", false]], "keypointdetectionmodel (class in model_api.models.keypoint_detection)": [[51, "model_api.models.keypoint_detection.KeypointDetectionModel", false]], "label (model_api.models.visual_prompting.prompt attribute)": [[58, "model_api.models.visual_prompting.Prompt.label", false]], "layout (class in model_api.adapters.utils)": [[42, "model_api.adapters.utils.Layout", false]], "layout (model_api.adapters.inference_adapter.metadata attribute)": [[38, "model_api.adapters.inference_adapter.Metadata.layout", false]], "learn() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[58, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.learn", false]], "listvalue (class in model_api.models.types)": [[56, "model_api.models.types.ListValue", false]], "load() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.load", false]], "load_labels() (in module model_api.models.utils)": [[57, "model_api.models.utils.load_labels", false]], "load_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.load_model", false]], "load_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.load_model", false]], "load_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.load_model", false]], "load_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.load_model", false]], "load_parameters_from_onnx() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.load_parameters_from_onnx", false]], "log_layers_info() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.log_layers_info", false]], "log_runtime_settings() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.log_runtime_settings", false]], "logger (model_api.models.model.model attribute)": [[52, "model_api.models.model.Model.logger", false]], "maskrcnnmodel (class in model_api.models.instance_segmentation)": [[50, "model_api.models.instance_segmentation.MaskRCNNModel", false]], "meta (model_api.adapters.inference_adapter.metadata attribute)": [[38, "model_api.adapters.inference_adapter.Metadata.meta", false]], "metadata (class in model_api.adapters.inference_adapter)": [[38, "model_api.adapters.inference_adapter.Metadata", false]], "model (class in model_api.models.model)": [[52, "model_api.models.model.Model", false]], "model (model_api.tilers.tiler.tiler attribute)": [[66, "model_api.tilers.tiler.Tiler.model", false]], "model_api.adapters.inference_adapter": [[38, "module-model_api.adapters.inference_adapter", false]], "model_api.adapters.onnx_adapter": [[39, "module-model_api.adapters.onnx_adapter", false]], "model_api.adapters.openvino_adapter": [[40, "module-model_api.adapters.openvino_adapter", false]], "model_api.adapters.ovms_adapter": [[41, "module-model_api.adapters.ovms_adapter", false]], "model_api.adapters.utils": [[42, "module-model_api.adapters.utils", false]], "model_api.models.action_classification": [[44, "module-model_api.models.action_classification", false]], "model_api.models.anomaly": [[45, "module-model_api.models.anomaly", false]], "model_api.models.classification": [[46, "module-model_api.models.classification", false]], "model_api.models.detection_model": [[47, "module-model_api.models.detection_model", false]], "model_api.models.image_model": [[48, "module-model_api.models.image_model", false]], "model_api.models.instance_segmentation": [[50, "module-model_api.models.instance_segmentation", false]], "model_api.models.keypoint_detection": [[51, "module-model_api.models.keypoint_detection", false]], "model_api.models.model": [[52, "module-model_api.models.model", false]], "model_api.models.sam_models": [[53, "module-model_api.models.sam_models", false]], "model_api.models.segmentation": [[54, "module-model_api.models.segmentation", false]], "model_api.models.ssd": [[55, "module-model_api.models.ssd", false]], "model_api.models.types": [[56, "module-model_api.models.types", false]], "model_api.models.utils": [[57, "module-model_api.models.utils", false]], "model_api.models.visual_prompting": [[58, "module-model_api.models.visual_prompting", false]], "model_api.models.yolo": [[59, "module-model_api.models.yolo", false]], "model_api.pipelines.async_pipeline": [[60, "module-model_api.pipelines.async_pipeline", false]], "model_api.tilers.detection": [[62, "module-model_api.tilers.detection", false]], "model_api.tilers.instance_segmentation": [[64, "module-model_api.tilers.instance_segmentation", false]], "model_api.tilers.semantic_segmentation": [[65, "module-model_api.tilers.semantic_segmentation", false]], "model_api.tilers.tiler": [[66, "module-model_api.tilers.tiler", false]], "model_loaded (model_api.models.model.model attribute)": [[52, "model_api.models.model.Model.model_loaded", false]], "model_loaded (model_api.tilers.tiler.tiler attribute)": [[66, "model_api.tilers.tiler.Tiler.model_loaded", false]], "module": [[38, "module-model_api.adapters.inference_adapter", false], [39, "module-model_api.adapters.onnx_adapter", false], [40, "module-model_api.adapters.openvino_adapter", false], [41, "module-model_api.adapters.ovms_adapter", false], [42, "module-model_api.adapters.utils", false], [44, "module-model_api.models.action_classification", false], [45, "module-model_api.models.anomaly", false], [46, "module-model_api.models.classification", false], [47, "module-model_api.models.detection_model", false], [48, "module-model_api.models.image_model", false], [50, "module-model_api.models.instance_segmentation", false], [51, "module-model_api.models.keypoint_detection", false], [52, "module-model_api.models.model", false], [53, "module-model_api.models.sam_models", false], [54, "module-model_api.models.segmentation", false], [55, "module-model_api.models.ssd", false], [56, "module-model_api.models.types", false], [57, "module-model_api.models.utils", false], [58, "module-model_api.models.visual_prompting", false], [59, "module-model_api.models.yolo", false], [60, "module-model_api.pipelines.async_pipeline", false], [62, "module-model_api.tilers.detection", false], [64, "module-model_api.tilers.instance_segmentation", false], [65, "module-model_api.tilers.semantic_segmentation", false], [66, "module-model_api.tilers.tiler", false]], "multiclass_nms() (in module model_api.models.utils)": [[57, "model_api.models.utils.multiclass_nms", false]], "multipleoutputparser (class in model_api.models.ssd)": [[55, "model_api.models.ssd.MultipleOutputParser", false]], "names (model_api.adapters.inference_adapter.metadata attribute)": [[38, "model_api.adapters.inference_adapter.Metadata.names", false]], "nchw_layout (model_api.models.image_model.imagemodel attribute)": [[48, "model_api.models.image_model.ImageModel.nchw_layout", false]], "nms() (in module model_api.models.utils)": [[57, "model_api.models.utils.nms", false]], "numericalvalue (class in model_api.models.types)": [[56, "model_api.models.types.NumericalValue", false]], "onnxruntimeadapter (class in model_api.adapters.onnx_adapter)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter", false]], "openvinoadapter (class in model_api.adapters.openvino_adapter)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter", false]], "operations_by_type() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.operations_by_type", false]], "outputs (model_api.models.model.model attribute)": [[52, "model_api.models.model.Model.outputs", false]], "outputtransform (class in model_api.models.utils)": [[57, "model_api.models.utils.OutputTransform", false]], "ovmsadapter (class in model_api.adapters.ovms_adapter)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter", false]], "parameters() (model_api.models.action_classification.actionclassificationmodel class method)": [[44, "model_api.models.action_classification.ActionClassificationModel.parameters", false]], "parameters() (model_api.models.anomaly.anomalydetection class method)": [[45, "model_api.models.anomaly.AnomalyDetection.parameters", false]], "parameters() (model_api.models.classification.classificationmodel class method)": [[46, "model_api.models.classification.ClassificationModel.parameters", false]], "parameters() (model_api.models.detection_model.detectionmodel class method)": [[47, "model_api.models.detection_model.DetectionModel.parameters", false]], "parameters() (model_api.models.image_model.imagemodel class method)": [[48, "model_api.models.image_model.ImageModel.parameters", false]], "parameters() (model_api.models.instance_segmentation.maskrcnnmodel class method)": [[50, "model_api.models.instance_segmentation.MaskRCNNModel.parameters", false]], "parameters() (model_api.models.keypoint_detection.keypointdetectionmodel class method)": [[51, "model_api.models.keypoint_detection.KeypointDetectionModel.parameters", false]], "parameters() (model_api.models.model.model class method)": [[52, "model_api.models.model.Model.parameters", false]], "parameters() (model_api.models.sam_models.samdecoder class method)": [[53, "model_api.models.sam_models.SAMDecoder.parameters", false]], "parameters() (model_api.models.sam_models.samimageencoder class method)": [[53, "model_api.models.sam_models.SAMImageEncoder.parameters", false]], "parameters() (model_api.models.segmentation.segmentationmodel class method)": [[54, "model_api.models.segmentation.SegmentationModel.parameters", false]], "parameters() (model_api.models.yolo.yolo class method)": [[59, "model_api.models.yolo.YOLO.parameters", false]], "parameters() (model_api.models.yolo.yolof class method)": [[59, "model_api.models.yolo.YOLOF.parameters", false]], "parameters() (model_api.models.yolo.yolov3onnx class method)": [[59, "model_api.models.yolo.YoloV3ONNX.parameters", false]], "parameters() (model_api.models.yolo.yolov4 class method)": [[59, "model_api.models.yolo.YoloV4.parameters", false]], "parameters() (model_api.models.yolo.yolov5 class method)": [[59, "model_api.models.yolo.YOLOv5.parameters", false]], "parameters() (model_api.models.yolo.yolox class method)": [[59, "model_api.models.yolo.YOLOX.parameters", false]], "parameters() (model_api.tilers.detection.detectiontiler class method)": [[62, "model_api.tilers.detection.DetectionTiler.parameters", false]], "parameters() (model_api.tilers.tiler.tiler class method)": [[66, "model_api.tilers.tiler.Tiler.parameters", false]], "parse_devices() (in module model_api.adapters.openvino_adapter)": [[40, "model_api.adapters.openvino_adapter.parse_devices", false]], "parse_layouts() (model_api.adapters.utils.layout static method)": [[42, "model_api.adapters.utils.Layout.parse_layouts", false]], "parse_value_per_device() (in module model_api.adapters.openvino_adapter)": [[40, "model_api.adapters.openvino_adapter.parse_value_per_device", false]], "permute_to_n_hwa_k() (in module model_api.models.yolo)": [[59, "model_api.models.yolo.permute_to_N_HWA_K", false]], "postprocess() (model_api.models.action_classification.actionclassificationmodel method)": [[44, "model_api.models.action_classification.ActionClassificationModel.postprocess", false]], "postprocess() (model_api.models.anomaly.anomalydetection method)": [[45, "model_api.models.anomaly.AnomalyDetection.postprocess", false]], "postprocess() (model_api.models.classification.classificationmodel method)": [[46, "model_api.models.classification.ClassificationModel.postprocess", false]], "postprocess() (model_api.models.instance_segmentation.maskrcnnmodel method)": [[50, "model_api.models.instance_segmentation.MaskRCNNModel.postprocess", false]], "postprocess() (model_api.models.keypoint_detection.keypointdetectionmodel method)": [[51, "model_api.models.keypoint_detection.KeypointDetectionModel.postprocess", false]], "postprocess() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.postprocess", false]], "postprocess() (model_api.models.sam_models.samdecoder method)": [[53, "model_api.models.sam_models.SAMDecoder.postprocess", false]], "postprocess() (model_api.models.sam_models.samimageencoder method)": [[53, "model_api.models.sam_models.SAMImageEncoder.postprocess", false]], "postprocess() (model_api.models.segmentation.segmentationmodel method)": [[54, "model_api.models.segmentation.SegmentationModel.postprocess", false]], "postprocess() (model_api.models.ssd.ssd method)": [[55, "model_api.models.ssd.SSD.postprocess", false]], "postprocess() (model_api.models.yolo.yolo method)": [[59, "model_api.models.yolo.YOLO.postprocess", false]], "postprocess() (model_api.models.yolo.yolov3onnx method)": [[59, "model_api.models.yolo.YoloV3ONNX.postprocess", false]], "postprocess() (model_api.models.yolo.yolov5 method)": [[59, "model_api.models.yolo.YOLOv5.postprocess", false]], "postprocess() (model_api.models.yolo.yolox method)": [[59, "model_api.models.yolo.YOLOX.postprocess", false]], "precision (model_api.adapters.inference_adapter.metadata attribute)": [[38, "model_api.adapters.inference_adapter.Metadata.precision", false]], "precisions (model_api.adapters.inference_adapter.inferenceadapter attribute)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.precisions", false]], "predict() (model_api.models.keypoint_detection.topdownkeypointdetectionpipeline method)": [[51, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline.predict", false]], "predict_crops() (model_api.models.keypoint_detection.topdownkeypointdetectionpipeline method)": [[51, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline.predict_crops", false]], "preprocess() (model_api.models.action_classification.actionclassificationmodel method)": [[44, "model_api.models.action_classification.ActionClassificationModel.preprocess", false]], "preprocess() (model_api.models.image_model.imagemodel method)": [[48, "model_api.models.image_model.ImageModel.preprocess", false]], "preprocess() (model_api.models.instance_segmentation.maskrcnnmodel method)": [[50, "model_api.models.instance_segmentation.MaskRCNNModel.preprocess", false]], "preprocess() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.preprocess", false]], "preprocess() (model_api.models.sam_models.samdecoder method)": [[53, "model_api.models.sam_models.SAMDecoder.preprocess", false]], "preprocess() (model_api.models.sam_models.samimageencoder method)": [[53, "model_api.models.sam_models.SAMImageEncoder.preprocess", false]], "preprocess() (model_api.models.ssd.ssd method)": [[55, "model_api.models.ssd.SSD.preprocess", false]], "preprocess() (model_api.models.yolo.yolov3onnx method)": [[59, "model_api.models.yolo.YoloV3ONNX.preprocess", false]], "preprocess() (model_api.models.yolo.yolox method)": [[59, "model_api.models.yolo.YOLOX.preprocess", false]], "probabilisticlabelsresolver (class in model_api.models.classification)": [[46, "model_api.models.classification.ProbabilisticLabelsResolver", false]], "prompt (class in model_api.models.visual_prompting)": [[58, "model_api.models.visual_prompting.Prompt", false]], "raise_error() (model_api.models.model.model class method)": [[52, "model_api.models.model.Model.raise_error", false]], "reference_features (model_api.models.visual_prompting.samlearnablevisualprompter property)": [[58, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.reference_features", false]], "reset_reference_info() (model_api.models.visual_prompting.samlearnablevisualprompter method)": [[58, "model_api.models.visual_prompting.SAMLearnableVisualPrompter.reset_reference_info", false]], "reshape() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.reshape", false]], "reshape_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.reshape_model", false]], "reshape_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.reshape_model", false]], "resize (model_api.models.action_classification.actionclassificationmodel attribute)": [[44, "model_api.models.action_classification.ActionClassificationModel.resize", false]], "resize (model_api.models.image_model.imagemodel attribute)": [[48, "model_api.models.image_model.ImageModel.resize", false]], "resize() (model_api.models.utils.outputtransform method)": [[57, "model_api.models.utils.OutputTransform.resize", false]], "resize_image() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image", false]], "resize_image_graph() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image_graph", false]], "resize_image_letterbox() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image_letterbox", false]], "resize_image_letterbox_graph() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image_letterbox_graph", false]], "resize_image_letterbox_ocv() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image_letterbox_ocv", false]], "resize_image_ocv() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image_ocv", false]], "resize_image_with_aspect() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image_with_aspect", false]], "resize_image_with_aspect_ocv() (in module model_api.adapters.utils)": [[42, "model_api.adapters.utils.resize_image_with_aspect_ocv", false]], "resize_type (model_api.models.action_classification.actionclassificationmodel attribute)": [[44, "model_api.models.action_classification.ActionClassificationModel.resize_type", false]], "resize_type (model_api.models.image_model.imagemodel attribute)": [[48, "model_api.models.image_model.ImageModel.resize_type", false]], "resolve_labels() (model_api.models.classification.greedylabelsresolver method)": [[46, "model_api.models.classification.GreedyLabelsResolver.resolve_labels", false]], "resolve_labels() (model_api.models.classification.probabilisticlabelsresolver method)": [[46, "model_api.models.classification.ProbabilisticLabelsResolver.resolve_labels", false]], "samdecoder (class in model_api.models.sam_models)": [[53, "model_api.models.sam_models.SAMDecoder", false]], "samimageencoder (class in model_api.models.sam_models)": [[53, "model_api.models.sam_models.SAMImageEncoder", false]], "samlearnablevisualprompter (class in model_api.models.visual_prompting)": [[58, "model_api.models.visual_prompting.SAMLearnableVisualPrompter", false]], "samvisualprompter (class in model_api.models.visual_prompting)": [[58, "model_api.models.visual_prompting.SAMVisualPrompter", false]], "save() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.save", false]], "save_model() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.save_model", false]], "save_model() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.save_model", false]], "save_model() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.save_model", false]], "save_model() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.save_model", false]], "scale() (model_api.models.utils.outputtransform method)": [[57, "model_api.models.utils.OutputTransform.scale", false]], "segmentationmodel (class in model_api.models.segmentation)": [[54, "model_api.models.segmentation.SegmentationModel", false]], "semanticsegmentationtiler (class in model_api.tilers.semantic_segmentation)": [[65, "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler", false]], "set_callback() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.set_callback", false]], "set_callback() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.set_callback", false]], "set_callback() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.set_callback", false]], "set_callback() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.set_callback", false]], "set_callback() (model_api.models.model.model method)": [[52, "model_api.models.model.Model.set_callback", false]], "set_strides_grids() (model_api.models.yolo.yolox method)": [[59, "model_api.models.yolo.YOLOX.set_strides_grids", false]], "shape (model_api.adapters.inference_adapter.metadata attribute)": [[38, "model_api.adapters.inference_adapter.Metadata.shape", false]], "sigmoid() (in module model_api.models.yolo)": [[59, "model_api.models.yolo.sigmoid", false]], "sigmoid_numpy() (in module model_api.models.classification)": [[46, "model_api.models.classification.sigmoid_numpy", false]], "simplelabelsgraph (class in model_api.models.classification)": [[46, "model_api.models.classification.SimpleLabelsGraph", false]], "singleoutputparser (class in model_api.models.ssd)": [[55, "model_api.models.ssd.SingleOutputParser", false]], "softmax() (in module model_api.models.utils)": [[57, "model_api.models.utils.softmax", false]], "ssd (class in model_api.models.ssd)": [[55, "model_api.models.ssd.SSD", false]], "stringvalue (class in model_api.models.types)": [[56, "model_api.models.types.StringValue", false]], "submit_data() (model_api.pipelines.async_pipeline.asyncpipeline method)": [[60, "model_api.pipelines.async_pipeline.AsyncPipeline.submit_data", false]], "tiler (class in model_api.tilers.tiler)": [[66, "model_api.tilers.tiler.Tiler", false]], "topdownkeypointdetectionpipeline (class in model_api.models.keypoint_detection)": [[51, "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline", false]], "topological_sort() (model_api.models.classification.simplelabelsgraph method)": [[46, "model_api.models.classification.SimpleLabelsGraph.topological_sort", false]], "type (model_api.adapters.inference_adapter.metadata attribute)": [[38, "model_api.adapters.inference_adapter.Metadata.type", false]], "update_default_value() (model_api.models.types.basevalue method)": [[56, "model_api.models.types.BaseValue.update_default_value", false]], "update_model_info() (model_api.adapters.inference_adapter.inferenceadapter method)": [[38, "model_api.adapters.inference_adapter.InferenceAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.onnx_adapter.onnxruntimeadapter method)": [[39, "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.openvino_adapter.openvinoadapter method)": [[40, "model_api.adapters.openvino_adapter.OpenvinoAdapter.update_model_info", false]], "update_model_info() (model_api.adapters.ovms_adapter.ovmsadapter method)": [[41, "model_api.adapters.ovms_adapter.OVMSAdapter.update_model_info", false]], "used_indices (model_api.models.visual_prompting.visualpromptingfeatures attribute)": [[58, "model_api.models.visual_prompting.VisualPromptingFeatures.used_indices", false]], "validate() (model_api.models.types.basevalue method)": [[56, "model_api.models.types.BaseValue.validate", false]], "validate() (model_api.models.types.booleanvalue method)": [[56, "model_api.models.types.BooleanValue.validate", false]], "validate() (model_api.models.types.dictvalue method)": [[56, "model_api.models.types.DictValue.validate", false]], "validate() (model_api.models.types.listvalue method)": [[56, "model_api.models.types.ListValue.validate", false]], "validate() (model_api.models.types.numericalvalue method)": [[56, "model_api.models.types.NumericalValue.validate", false]], "validate() (model_api.models.types.stringvalue method)": [[56, "model_api.models.types.StringValue.validate", false]], "visualpromptingfeatures (class in model_api.models.visual_prompting)": [[58, "model_api.models.visual_prompting.VisualPromptingFeatures", false]], "w (model_api.models.yolo.detectionbox attribute)": [[59, "model_api.models.yolo.DetectionBox.w", false]], "wrappererror": [[52, "model_api.models.model.WrapperError", false]], "x (model_api.models.yolo.detectionbox attribute)": [[59, "model_api.models.yolo.DetectionBox.x", false]], "xywh2xyxy() (in module model_api.models.yolo)": [[59, "model_api.models.yolo.xywh2xyxy", false]], "y (model_api.models.yolo.detectionbox attribute)": [[59, "model_api.models.yolo.DetectionBox.y", false]], "yolo (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YOLO", false]], "yolo.params (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YOLO.Params", false]], "yolof (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YOLOF", false]], "yolof.params (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YOLOF.Params", false]], "yolov3onnx (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YoloV3ONNX", false]], "yolov4 (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YoloV4", false]], "yolov4.params (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YoloV4.Params", false]], "yolov5 (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YOLOv5", false]], "yolov8 (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YOLOv8", false]], "yolox (class in model_api.models.yolo)": [[59, "model_api.models.yolo.YOLOX", false]]}, "objects": {"model_api.adapters": [[38, 0, 0, "-", "inference_adapter"], [39, 0, 0, "-", "onnx_adapter"], [40, 0, 0, "-", "openvino_adapter"], [41, 0, 0, "-", "ovms_adapter"], [42, 0, 0, "-", "utils"]], "model_api.adapters.inference_adapter": [[38, 1, 1, "", "InferenceAdapter"], [38, 1, 1, "", "Metadata"]], "model_api.adapters.inference_adapter.InferenceAdapter": [[38, 2, 1, "", "await_all"], [38, 2, 1, "", "await_any"], [38, 2, 1, "", "embed_preprocessing"], [38, 2, 1, "", "get_input_layers"], [38, 2, 1, "", "get_model"], [38, 2, 1, "", "get_output_layers"], [38, 2, 1, "", "get_raw_result"], [38, 2, 1, "", "get_rt_info"], [38, 2, 1, "", "infer_async"], [38, 2, 1, "", "infer_sync"], [38, 2, 1, "", "is_ready"], [38, 2, 1, "", "load_model"], [38, 3, 1, "", "precisions"], [38, 2, 1, "", "reshape_model"], [38, 2, 1, "", "save_model"], [38, 2, 1, "", "set_callback"], [38, 2, 1, "", "update_model_info"]], "model_api.adapters.inference_adapter.Metadata": [[38, 3, 1, "", "layout"], [38, 3, 1, "", "meta"], [38, 3, 1, "", "names"], [38, 3, 1, "", "precision"], [38, 3, 1, "", "shape"], [38, 3, 1, "", "type"]], "model_api.adapters.onnx_adapter": [[39, 1, 1, "", "ONNXRuntimeAdapter"], [39, 4, 1, "", "change_layout"], [39, 4, 1, "", "get_shape_from_onnx"]], "model_api.adapters.onnx_adapter.ONNXRuntimeAdapter": [[39, 2, 1, "", "await_all"], [39, 2, 1, "", "await_any"], [39, 2, 1, "", "embed_preprocessing"], [39, 2, 1, "", "get_input_layers"], [39, 2, 1, "", "get_model"], [39, 2, 1, "", "get_output_layers"], [39, 2, 1, "", "get_raw_result"], [39, 2, 1, "", "get_rt_info"], [39, 2, 1, "", "infer_async"], [39, 2, 1, "", "infer_sync"], [39, 2, 1, "", "is_ready"], [39, 2, 1, "", "load_model"], [39, 2, 1, "", "reshape_model"], [39, 2, 1, "", "save_model"], [39, 2, 1, "", "set_callback"], [39, 2, 1, "", "update_model_info"]], "model_api.adapters.openvino_adapter": [[40, 1, 1, "", "OpenvinoAdapter"], [40, 4, 1, "", "create_core"], [40, 4, 1, "", "get_input_shape"], [40, 4, 1, "", "get_user_config"], [40, 4, 1, "", "parse_devices"], [40, 4, 1, "", "parse_value_per_device"]], "model_api.adapters.openvino_adapter.OpenvinoAdapter": [[40, 2, 1, "", "await_all"], [40, 2, 1, "", "await_any"], [40, 2, 1, "", "copy_raw_result"], [40, 2, 1, "", "embed_preprocessing"], [40, 2, 1, "", "get_input_layers"], [40, 2, 1, "", "get_layout_for_input"], [40, 2, 1, "", "get_model"], [40, 2, 1, "", "get_output_layers"], [40, 2, 1, "", "get_raw_result"], [40, 2, 1, "", "get_rt_info"], [40, 2, 1, "", "infer_async"], [40, 2, 1, "", "infer_sync"], [40, 2, 1, "", "is_ready"], [40, 2, 1, "", "load_model"], [40, 2, 1, "", "log_runtime_settings"], [40, 2, 1, "", "operations_by_type"], [40, 2, 1, "", "reshape_model"], [40, 2, 1, "", "save_model"], [40, 2, 1, "", "set_callback"], [40, 2, 1, "", "update_model_info"]], "model_api.adapters.ovms_adapter": [[41, 1, 1, "", "OVMSAdapter"]], "model_api.adapters.ovms_adapter.OVMSAdapter": [[41, 2, 1, "", "await_all"], [41, 2, 1, "", "await_any"], [41, 2, 1, "", "embed_preprocessing"], [41, 2, 1, "", "get_input_layers"], [41, 2, 1, "", "get_model"], [41, 2, 1, "", "get_output_layers"], [41, 2, 1, "", "get_raw_result"], [41, 2, 1, "", "get_rt_info"], [41, 2, 1, "", "infer_async"], [41, 2, 1, "", "infer_sync"], [41, 2, 1, "", "is_ready"], [41, 2, 1, "", "load_model"], [41, 2, 1, "", "reshape_model"], [41, 2, 1, "", "save_model"], [41, 2, 1, "", "set_callback"], [41, 2, 1, "", "update_model_info"]], "model_api.adapters.utils": [[42, 1, 1, "", "InputTransform"], [42, 1, 1, "", "Layout"], [42, 4, 1, "", "crop_resize"], [42, 4, 1, "", "crop_resize_graph"], [42, 4, 1, "", "crop_resize_ocv"], [42, 4, 1, "", "get_rt_info_from_dict"], [42, 4, 1, "", "load_parameters_from_onnx"], [42, 4, 1, "", "resize_image"], [42, 4, 1, "", "resize_image_graph"], [42, 4, 1, "", "resize_image_letterbox"], [42, 4, 1, "", "resize_image_letterbox_graph"], [42, 4, 1, "", "resize_image_letterbox_ocv"], [42, 4, 1, "", "resize_image_ocv"], [42, 4, 1, "", "resize_image_with_aspect"], [42, 4, 1, "", "resize_image_with_aspect_ocv"]], "model_api.adapters.utils.InputTransform": [[42, 2, 1, "", "__call__"]], "model_api.adapters.utils.Layout": [[42, 2, 1, "", "from_openvino"], [42, 2, 1, "", "from_shape"], [42, 2, 1, "", "from_user_layouts"], [42, 2, 1, "", "parse_layouts"]], "model_api.models": [[44, 0, 0, "-", "action_classification"], [45, 0, 0, "-", "anomaly"], [46, 0, 0, "-", "classification"], [47, 0, 0, "-", "detection_model"], [48, 0, 0, "-", "image_model"], [50, 0, 0, "-", "instance_segmentation"], [51, 0, 0, "-", "keypoint_detection"], [52, 0, 0, "-", "model"], [53, 0, 0, "-", "sam_models"], [54, 0, 0, "-", "segmentation"], [55, 0, 0, "-", "ssd"], [56, 0, 0, "-", "types"], [57, 0, 0, "-", "utils"], [58, 0, 0, "-", "visual_prompting"], [59, 0, 0, "-", "yolo"]], "model_api.models.action_classification": [[44, 1, 1, "", "ActionClassificationModel"]], "model_api.models.action_classification.ActionClassificationModel": [[44, 5, 1, "", "clip_size"], [44, 3, 1, "", "image_blob_name"], [44, 3, 1, "", "image_blob_names"], [44, 3, 1, "", "input_transform"], [44, 2, 1, "", "parameters"], [44, 2, 1, "", "postprocess"], [44, 2, 1, "", "preprocess"], [44, 3, 1, "", "resize"], [44, 3, 1, "", "resize_type"]], "model_api.models.anomaly": [[45, 1, 1, "", "AnomalyDetection"]], "model_api.models.anomaly.AnomalyDetection": [[45, 2, 1, "", "parameters"], [45, 2, 1, "", "postprocess"]], "model_api.models.classification": [[46, 1, 1, "", "ClassificationModel"], [46, 1, 1, "", "GreedyLabelsResolver"], [46, 1, 1, "", "ProbabilisticLabelsResolver"], [46, 1, 1, "", "SimpleLabelsGraph"], [46, 4, 1, "", "addOrFindSoftmaxAndTopkOutputs"], [46, 4, 1, "", "sigmoid_numpy"]], "model_api.models.classification.ClassificationModel": [[46, 2, 1, "", "get_all_probs"], [46, 2, 1, "", "get_hierarchical_predictions"], [46, 2, 1, "", "get_multiclass_predictions"], [46, 2, 1, "", "get_multilabel_predictions"], [46, 2, 1, "", "get_saliency_maps"], [46, 2, 1, "", "parameters"], [46, 2, 1, "", "postprocess"]], "model_api.models.classification.GreedyLabelsResolver": [[46, 2, 1, "", "resolve_labels"]], "model_api.models.classification.ProbabilisticLabelsResolver": [[46, 2, 1, "", "resolve_labels"]], "model_api.models.classification.SimpleLabelsGraph": [[46, 2, 1, "", "add_edge"], [46, 2, 1, "", "clear_topological_cache"], [46, 2, 1, "", "get_ancestors"], [46, 2, 1, "", "get_children"], [46, 2, 1, "", "get_labels_in_topological_order"], [46, 2, 1, "", "get_parent"], [46, 2, 1, "", "topological_sort"]], "model_api.models.detection_model": [[47, 1, 1, "", "DetectionModel"]], "model_api.models.detection_model.DetectionModel": [[47, 2, 1, "", "parameters"]], "model_api.models.image_model": [[48, 1, 1, "", "ImageModel"]], "model_api.models.image_model.ImageModel": [[48, 2, 1, "", "get_label_name"], [48, 3, 1, "", "image_blob_name"], [48, 3, 1, "", "image_blob_names"], [48, 3, 1, "", "image_info_blob_names"], [48, 3, 1, "", "input_transform"], [48, 3, 1, "", "nchw_layout"], [48, 2, 1, "", "parameters"], [48, 2, 1, "", "preprocess"], [48, 3, 1, "", "resize"], [48, 3, 1, "", "resize_type"]], "model_api.models.instance_segmentation": [[50, 1, 1, "", "MaskRCNNModel"]], "model_api.models.instance_segmentation.MaskRCNNModel": [[50, 2, 1, "", "parameters"], [50, 2, 1, "", "postprocess"], [50, 2, 1, "", "preprocess"]], "model_api.models.keypoint_detection": [[51, 1, 1, "", "KeypointDetectionModel"], [51, 1, 1, "", "TopDownKeypointDetectionPipeline"]], "model_api.models.keypoint_detection.KeypointDetectionModel": [[51, 2, 1, "", "parameters"], [51, 2, 1, "", "postprocess"]], "model_api.models.keypoint_detection.TopDownKeypointDetectionPipeline": [[51, 2, 1, "", "predict"], [51, 2, 1, "", "predict_crops"]], "model_api.models.model": [[52, 1, 1, "", "Model"], [52, 6, 1, "", "WrapperError"]], "model_api.models.model.Model": [[52, 2, 1, "", "__call__"], [52, 2, 1, "", "available_wrappers"], [52, 2, 1, "", "await_all"], [52, 2, 1, "", "await_any"], [52, 2, 1, "", "create_model"], [52, 2, 1, "", "get_model"], [52, 2, 1, "", "get_model_class"], [52, 2, 1, "", "get_subclasses"], [52, 2, 1, "", "infer_async"], [52, 2, 1, "", "infer_async_raw"], [52, 2, 1, "", "infer_batch"], [52, 2, 1, "", "infer_sync"], [52, 3, 1, "", "inference_adapter"], [52, 3, 1, "", "inputs"], [52, 2, 1, "", "is_ready"], [52, 2, 1, "", "load"], [52, 2, 1, "", "log_layers_info"], [52, 3, 1, "", "logger"], [52, 3, 1, "", "model_loaded"], [52, 3, 1, "", "outputs"], [52, 2, 1, "", "parameters"], [52, 2, 1, "", "postprocess"], [52, 2, 1, "", "preprocess"], [52, 2, 1, "", "raise_error"], [52, 2, 1, "", "reshape"], [52, 2, 1, "", "save"], [52, 2, 1, "", "set_callback"]], "model_api.models.sam_models": [[53, 1, 1, "", "SAMDecoder"], [53, 1, 1, "", "SAMImageEncoder"]], "model_api.models.sam_models.SAMDecoder": [[53, 2, 1, "", "apply_coords"], [53, 2, 1, "", "parameters"], [53, 2, 1, "", "postprocess"], [53, 2, 1, "", "preprocess"]], "model_api.models.sam_models.SAMImageEncoder": [[53, 2, 1, "", "parameters"], [53, 2, 1, "", "postprocess"], [53, 2, 1, "", "preprocess"]], "model_api.models.segmentation": [[54, 1, 1, "", "SegmentationModel"], [54, 4, 1, "", "create_hard_prediction_from_soft_prediction"]], "model_api.models.segmentation.SegmentationModel": [[54, 2, 1, "", "get_contours"], [54, 2, 1, "", "parameters"], [54, 2, 1, "", "postprocess"]], "model_api.models.ssd": [[55, 1, 1, "", "BoxesLabelsParser"], [55, 1, 1, "", "MultipleOutputParser"], [55, 1, 1, "", "SSD"], [55, 1, 1, "", "SingleOutputParser"], [55, 4, 1, "", "find_layer_by_name"]], "model_api.models.ssd.BoxesLabelsParser": [[55, 2, 1, "", "__call__"], [55, 2, 1, "", "find_layer_bboxes_output"]], "model_api.models.ssd.MultipleOutputParser": [[55, 2, 1, "", "__call__"]], "model_api.models.ssd.SSD": [[55, 2, 1, "", "postprocess"], [55, 2, 1, "", "preprocess"]], "model_api.models.ssd.SingleOutputParser": [[55, 2, 1, "", "__call__"]], "model_api.models.types": [[56, 1, 1, "", "BaseValue"], [56, 1, 1, "", "BooleanValue"], [56, 6, 1, "", "ConfigurableValueError"], [56, 1, 1, "", "DictValue"], [56, 1, 1, "", "ListValue"], [56, 1, 1, "", "NumericalValue"], [56, 1, 1, "", "StringValue"]], "model_api.models.types.BaseValue": [[56, 2, 1, "", "build_error"], [56, 2, 1, "", "get_value"], [56, 2, 1, "", "update_default_value"], [56, 2, 1, "", "validate"]], "model_api.models.types.BooleanValue": [[56, 2, 1, "", "from_str"], [56, 2, 1, "", "validate"]], "model_api.models.types.DictValue": [[56, 2, 1, "", "from_str"], [56, 2, 1, "", "validate"]], "model_api.models.types.ListValue": [[56, 2, 1, "", "from_str"], [56, 2, 1, "", "validate"]], "model_api.models.types.NumericalValue": [[56, 2, 1, "", "from_str"], [56, 2, 1, "", "validate"]], "model_api.models.types.StringValue": [[56, 2, 1, "", "from_str"], [56, 2, 1, "", "validate"]], "model_api.models.utils": [[57, 1, 1, "", "OutputTransform"], [57, 4, 1, "", "add_rotated_rects"], [57, 4, 1, "", "clip_detections"], [57, 4, 1, "", "get_contours"], [57, 4, 1, "", "load_labels"], [57, 4, 1, "", "multiclass_nms"], [57, 4, 1, "", "nms"], [57, 4, 1, "", "softmax"]], "model_api.models.utils.OutputTransform": [[57, 2, 1, "", "compute_resolution"], [57, 2, 1, "", "resize"], [57, 2, 1, "", "scale"]], "model_api.models.visual_prompting": [[58, 1, 1, "", "Prompt"], [58, 1, 1, "", "SAMLearnableVisualPrompter"], [58, 1, 1, "", "SAMVisualPrompter"], [58, 1, 1, "", "VisualPromptingFeatures"]], "model_api.models.visual_prompting.Prompt": [[58, 3, 1, "", "data"], [58, 3, 1, "", "label"]], "model_api.models.visual_prompting.SAMLearnableVisualPrompter": [[58, 2, 1, "", "__call__"], [58, 2, 1, "", "has_reference_features"], [58, 2, 1, "", "infer"], [58, 2, 1, "", "learn"], [58, 5, 1, "", "reference_features"], [58, 2, 1, "", "reset_reference_info"]], "model_api.models.visual_prompting.SAMVisualPrompter": [[58, 2, 1, "", "__call__"], [58, 2, 1, "", "infer"]], "model_api.models.visual_prompting.VisualPromptingFeatures": [[58, 3, 1, "", "feature_vectors"], [58, 3, 1, "", "used_indices"]], "model_api.models.yolo": [[59, 1, 1, "", "DetectionBox"], [59, 1, 1, "", "YOLO"], [59, 1, 1, "", "YOLOF"], [59, 1, 1, "", "YOLOX"], [59, 1, 1, "", "YOLOv5"], [59, 1, 1, "", "YOLOv8"], [59, 1, 1, "", "YoloV3ONNX"], [59, 1, 1, "", "YoloV4"], [59, 4, 1, "", "permute_to_N_HWA_K"], [59, 4, 1, "", "sigmoid"], [59, 4, 1, "", "xywh2xyxy"]], "model_api.models.yolo.DetectionBox": [[59, 3, 1, "", "h"], [59, 3, 1, "", "w"], [59, 3, 1, "", "x"], [59, 3, 1, "", "y"]], "model_api.models.yolo.YOLO": [[59, 1, 1, "", "Params"], [59, 2, 1, "", "parameters"], [59, 2, 1, "", "postprocess"]], "model_api.models.yolo.YOLOF": [[59, 1, 1, "", "Params"], [59, 2, 1, "", "parameters"]], "model_api.models.yolo.YOLOX": [[59, 2, 1, "", "parameters"], [59, 2, 1, "", "postprocess"], [59, 2, 1, "", "preprocess"], [59, 2, 1, "", "set_strides_grids"]], "model_api.models.yolo.YOLOv5": [[59, 2, 1, "", "parameters"], [59, 2, 1, "", "postprocess"]], "model_api.models.yolo.YoloV3ONNX": [[59, 2, 1, "", "parameters"], [59, 2, 1, "", "postprocess"], [59, 2, 1, "", "preprocess"]], "model_api.models.yolo.YoloV4": [[59, 1, 1, "", "Params"], [59, 2, 1, "", "parameters"]], "model_api.pipelines": [[60, 0, 0, "-", "async_pipeline"]], "model_api.pipelines.async_pipeline": [[60, 1, 1, "", "AsyncPipeline"]], "model_api.pipelines.async_pipeline.AsyncPipeline": [[60, 2, 1, "", "await_all"], [60, 2, 1, "", "await_any"], [60, 2, 1, "", "callback"], [60, 2, 1, "", "get_raw_result"], [60, 2, 1, "", "get_result"], [60, 2, 1, "", "is_ready"], [60, 2, 1, "", "submit_data"]], "model_api.tilers": [[62, 0, 0, "-", "detection"], [64, 0, 0, "-", "instance_segmentation"], [65, 0, 0, "-", "semantic_segmentation"], [66, 0, 0, "-", "tiler"]], "model_api.tilers.detection": [[62, 1, 1, "", "DetectionTiler"]], "model_api.tilers.detection.DetectionTiler": [[62, 2, 1, "", "parameters"]], "model_api.tilers.instance_segmentation": [[64, 1, 1, "", "InstanceSegmentationTiler"]], "model_api.tilers.instance_segmentation.InstanceSegmentationTiler": [[64, 2, 1, "", "__call__"]], "model_api.tilers.semantic_segmentation": [[65, 1, 1, "", "SemanticSegmentationTiler"]], "model_api.tilers.semantic_segmentation.SemanticSegmentationTiler": [[65, 2, 1, "", "__call__"]], "model_api.tilers.tiler": [[66, 1, 1, "", "Tiler"]], "model_api.tilers.tiler.Tiler": [[66, 3, 1, "", "EXECUTION_MODES"], [66, 2, 1, "", "__call__"], [66, 3, 1, "", "async_pipeline"], [66, 3, 1, "", "execution_mode"], [66, 2, 1, "", "get_model"], [66, 3, 1, "", "model"], [66, 3, 1, "", "model_loaded"], [66, 2, 1, "", "parameters"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"], "5": ["py", "property", "Python property"], "6": ["py", "exception", "Python exception"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function", "5": "py:property", "6": "py:exception"}, "terms": {"": [35, 38, 39, 40, 41, 44, 46, 48], "0": [35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59], "02643": 53, "09": 57, "1": [35, 38, 40, 42, 44, 45, 46, 47, 48, 51, 52, 54, 55, 58, 59], "100": 51, "114640": 45, "128": [38, 40], "134": 45, "138": 45, "150": 45, "1e": 57, "2": [58, 59], "200": 57, "2304": 53, "255": 51, "2d": 48, "3": [38, 40, 46, 47, 50, 54, 59], "3d": [39, 48, 50, 55, 59], "45": 57, "4d": [44, 48], "5": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59], "6": 46, "60699755": 46, "65": 58, "6d": 44, "7": 46, "8536462108391619": 45, "85433626": 46, "90176445": 46, "A": [41, 44, 46, 47, 50, 51, 54, 58, 59], "For": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59], "If": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59], "In": [38, 39, 40, 41, 46, 64], "It": [44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 66], "No": 56, "Not": 39, "OR": 58, "One": [35, 44], "The": [2, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 66], "To": 58, "__call__": [42, 52, 55, 58, 64, 65, 66], "_description_": 52, "_merge_result": 66, "_postprocess_til": 66, "_resize_detect": 47, "ab": 53, "abc": [38, 66], "about": [38, 39, 40, 41, 51], "abstract": [38, 47, 48, 52, 66], "accept": [44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 62, 64, 65, 66], "access": [35, 38], "accord": [44, 48, 50, 53, 55, 58, 59], "accur": 54, "act": [39, 45, 51], "action": 49, "action_classif": 44, "actionclassificationmodel": 44, "activ": [46, 54], "actual": [38, 41], "ad": 46, "adapt": [1, 36, 42, 43, 45, 46, 51, 52, 54], "adaptor_paramet": 52, "add": [35, 38, 39, 41, 46, 57], "add_edg": 46, "add_rotated_rect": 57, "addit": [35, 44, 48, 50, 55, 58, 59, 64], "addorfindsoftmaxandtopkoutput": 46, "address": 41, "affect": 35, "after": [38, 39, 40], "agnost": 35, "agnostic_nm": 35, "aim": [2, 45, 47, 50, 51], "alia": [58, 59], "align": 39, "all": [2, 35, 38, 39, 40, 41, 42, 44, 45, 46, 48, 51, 52, 57, 58, 66], "all_output": 55, "allow": [39, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 64], "alongsid": 52, "alreadi": [35, 58], "also": [38, 39, 40, 44, 46, 47, 48, 50, 52, 55, 59], "an": [35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 57, 58, 64, 66], "ancestor": 46, "anchor": [35, 59], "ani": [38, 39, 40, 41, 42, 44, 45, 48, 51, 52, 53, 56, 66], "anomal": 35, "anomali": [11, 35, 49], "anomalib": [2, 45], "anomaly_map": 45, "anomalybas": 35, "anomalydetect": 45, "anomalymodel": [2, 45], "anomalyresult": [17, 45], "anoth": 44, "api": [51, 52], "appli": [35, 38, 41, 42, 51, 52, 58, 64, 65, 66], "apply_coord": 53, "apply_masks_refin": 58, "approach": [46, 51], "appropri": [44, 45, 46, 48, 50, 51, 53, 54], "ar": [35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 57, 58, 59, 62, 65, 66], "architectur": 40, "arg": [28, 39], "args_help": 24, "argument": [35, 58], "arrai": [39, 44, 45, 46, 48, 50, 54, 55, 59], "arriv": 58, "arxiv": 53, "aspect": 35, "aspect_ratio": 35, "assum": 54, "astyp": 51, "async": [28, 38, 39, 40, 41, 52, 61, 62, 64, 65, 66], "async_pipelin": [60, 66], "asynchron": [38, 39, 40, 41, 52, 66], "asyncinferqueu": 25, "asyncpipelin": [60, 66], "attribut": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 62, 65, 66], "auto": [48, 52], "aux": 58, "avail": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 59], "available_wrapp": 52, "awai": 58, "await_al": [38, 39, 40, 41, 52, 60], "await_ani": [38, 39, 40, 41, 52, 60], "axi": 57, "b": [38, 41, 51], "backbon": 35, "base": [2, 11, 20, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66], "base_model": 51, "basevalu": 56, "basic": [44, 46, 48, 50, 51, 55, 59], "batch": [44, 51], "bbox": 55, "bboxes_lay": 55, "becom": [38, 39, 40, 41], "befor": [39, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59], "being": [38, 41, 52, 66], "below": 44, "between": 54, "bgr": [44, 48, 50, 55, 59], "bgr2rgb": [38, 41], "bicycl": 46, "bin": [40, 52], "binari": 58, "block": [38, 39, 40, 41, 52], "blur": 35, "blur_strength": [35, 54], "bool": [35, 38, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 66], "boolean": [38, 39, 40, 41], "booleanvalu": 56, "bound": [35, 47, 50, 55, 57, 58], "box": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59], "boxeslabelspars": 55, "brg2rgb": [38, 39, 40, 41], "build_cpp": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32], "build_error": 56, "busi": [38, 39, 40, 41], "byte": 39, "c": 44, "cache_dir": [40, 52], "call": [41, 42, 52, 58, 64, 65, 66], "callabl": [38, 39, 40, 41, 42, 52], "callback": [38, 39, 40, 41, 52, 60], "callback_arg": 60, "callback_data": [38, 39, 40, 41, 52], "callback_fn": [38, 39, 40, 41, 52], "can": [38, 39, 40, 41, 44, 51, 52, 54, 58, 64], "cannot": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33], "car": 46, "case": [38, 39, 40, 41, 46], "cat": 46, "center": 35, "chang": [39, 44, 45, 48, 50, 55, 59], "change_layout": 39, "channel": [35, 38, 41, 44, 48, 50, 55, 59], "check": [38, 39, 40, 41, 52, 58], "child": 46, "children": 46, "choic": 56, "circl": 51, "class": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66], "class_id": 51, "classaif": 44, "classif": [11, 35, 49, 51], "classifi": [35, 64], "classificationmodel": [3, 39, 46], "classificationresult": [17, 44, 46], "classmethod": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59, 62, 66], "clear_topological_cach": 46, "clip": [44, 47, 57], "clip_detect": 57, "clip_siz": 44, "collect": 52, "color": 51, "come": 51, "comma": 35, "common": 28, "compil": 52, "complet": [38, 39, 40, 41, 52], "compute_resolut": 57, "conduct": 44, "confid": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59], "confidence_threshold": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59], "config": 52, "configur": [39, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 62, 64, 65, 66], "configurablevalueerror": 56, "consequ": 58, "consid": 35, "construct": 35, "constructor": [38, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 62, 64, 65, 66], "construtor": [47, 55, 59], "contain": [38, 39, 40, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59, 62, 64, 65, 66], "contour": [54, 57], "control": [58, 62, 64, 65, 66], "convert": 53, "coord": 53, "coordin": 51, "copy_raw_result": 40, "core": [40, 52], "correspond": [38, 39, 44, 48, 51, 58], "cpu": [40, 52], "creat": [35, 38, 39, 40, 42, 52, 54, 58, 59, 62, 64, 65, 66], "create_cor": 40, "create_hard_prediction_from_soft_predict": 54, "create_model": [35, 45, 46, 47, 50, 51, 52, 54], "crop": [35, 44, 51], "crop_res": 42, "crop_resize_graph": 42, "crop_resize_ocv": 42, "current": [2, 45], "custom": [35, 52], "cv": 45, "cv2": [45, 46, 47, 50, 51, 54], "d1": 51, "d2": 51, "data": [11, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59, 62, 64, 65, 66], "data_1": [38, 39, 40, 52], "data_2": [38, 39, 40, 52], "dataset": 35, "decod": [35, 51, 53, 58], "decoder_model": 58, "decor": 52, "default": [35, 38, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59], "default_label": 55, "default_valu": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 59], "defin": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 62, 64, 65, 66], "definit": 45, "degrad": 51, "delta": 35, "depend": [52, 57, 66], "descript": [1, 36, 43, 44, 45, 48, 52, 53, 54, 56, 59, 62, 66], "destroyallwindow": 50, "det": 57, "detail": 52, "detect": [11, 20, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 59, 63], "detectedkeypoint": 51, "detectedobject": 17, "detection_model": 47, "detection_result": 51, "detectionbox": 59, "detectionmodel": [4, 47, 55, 59], "detectionmodelext": 5, "detectionresult": [17, 47, 55, 57, 59, 62], "detectiontil": [19, 62, 64], "detector": 51, "devic": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 66], "device1": 40, "device2": 40, "device_str": 40, "dict": [35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 62, 64, 65, 66], "dict_data": [38, 39, 40, 41, 52], "dictionari": [38, 40, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 62, 66], "dictvalu": 56, "differ": [40, 44, 57], "directori": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 52], "discover": 52, "disk": 38, "divid": [35, 44, 48, 50, 55, 59], "do": 57, "doc": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32], "document": 52, "doesn": 39, "done": 39, "down": [46, 51], "download": 52, "download_dir": [40, 52], "doxygen": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32], "doxygenclass": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 16, 18, 19, 21, 22, 23, 25, 29, 32], "doxygenfil": [24, 26, 27, 30, 31, 33], "doxygenstruct": [12, 14, 17], "dtype": [38, 39, 40, 41, 45, 46], "dure": [35, 58], "e": 52, "each": [35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 58, 59, 64], "edg": 46, "emb": [38, 40, 41], "embed": [35, 38, 41, 51], "embed_preprocess": [38, 39, 40, 41], "embedded_process": 35, "enabl": [54, 58], "enable_pad": 35, "encod": [53, 58], "encoder_model": 58, "end": [38, 39, 40], "enough": [51, 57], "ep": 57, "error": 52, "etc": [44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 62, 64, 65, 66], "even": 52, "exampl": [44, 45, 46, 48, 52, 53, 54, 59], "except": [41, 52, 56, 58], "exclus": 46, "execut": [38, 39, 40, 41, 52, 58, 66], "execution_mod": [62, 64, 65, 66], "executor": [44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 66], "exist": 54, "expect": [41, 55, 62, 64], "export": [2, 45, 46, 54], "ext": 11, "extend": [45, 46, 47, 48, 50, 53, 54, 55, 59], "extens": [39, 46, 50, 54], "extern": 39, "extra": [38, 41, 58], "f": [47, 50], "factori": 38, "fail": [44, 45, 46, 48, 50, 53, 54], "fals": [38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59], "featur": [35, 46, 54, 58], "feature_vector": [46, 54, 58], "field": [35, 58, 59], "file": [24, 26, 27, 30, 31, 33, 35, 39, 40, 45, 52], "filenam": 39, "filesystem": [38, 39, 52], "filter": [35, 57, 64], "final": 54, "find": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59], "find_layer_bboxes_output": 55, "find_layer_by_nam": 55, "first": [35, 44, 48, 58], "fit": [38, 39, 40, 44, 48, 50, 52, 55, 59], "fit_to_window": 35, "fit_to_window_letterbox": 35, "flag": [35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 66], "flags_d": 40, "flags_nstream": 40, "flags_nthread": 40, "float": [35, 46, 54, 56, 57, 58], "float64": 46, "follow": [2, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59], "forc": [51, 52, 58], "format": [35, 38, 39, 40, 41, 42, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 64, 65, 66], "forward": [39, 47, 50], "found": 54, "fp16": [38, 40, 52], "fp32": 38, "framework": [38, 39, 40, 41], "free": [52, 66], "from": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 57, 58, 59, 66], "from_openvino": 42, "from_shap": 42, "from_str": 56, "from_user_layout": 42, "full": [51, 64, 65, 66], "function": [35, 38, 39, 40, 41, 42, 44, 48], "g": 52, "gener": [2, 39, 45, 48, 58], "get": [38, 39, 40, 41, 44, 46], "get_all_prob": 46, "get_ancestor": 46, "get_children": 46, "get_contour": [54, 57], "get_hierarchical_predict": 46, "get_input_lay": [38, 39, 40, 41], "get_input_shap": 40, "get_label_nam": 48, "get_labels_in_topological_ord": 46, "get_layout_for_input": 40, "get_model": [38, 39, 40, 41, 52, 66], "get_model_class": 52, "get_multiclass_predict": 46, "get_multilabel_predict": 46, "get_output_lay": [38, 39, 40, 41], "get_par": 46, "get_raw_result": [38, 39, 40, 41, 60], "get_result": 60, "get_rt_info": [38, 39, 40, 41], "get_rt_info_from_dict": 42, "get_saliency_map": 46, "get_shape_from_onnx": 39, "get_subclass": 52, "get_user_config": 40, "get_valu": 56, "getter": 66, "given": [35, 40, 42, 44, 51, 52, 58], "go": 35, "gpu": 52, "grab": [38, 39, 40, 41, 52], "greater": 58, "greedi": 46, "greedylabelsresolv": [3, 46], "group": 46, "grpcclient": 41, "h": [27, 44, 46, 47, 50, 54, 58, 59], "ha": [35, 38, 39, 40, 44, 47, 48, 50, 52, 55, 59, 64], "handl": [38, 39, 40], "hard": [53, 54], "has_reference_featur": 58, "have": [35, 44, 47, 51], "height": [35, 44, 46, 47, 50, 54, 57], "helper": 28, "hierarch": [35, 46], "hierarchi": 35, "hierarchical_config": [35, 46], "higher": 54, "hole": 54, "home": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32], "hpp": [24, 26, 30, 31, 33], "http": 53, "hwc": [39, 48, 50, 55, 58, 59], "hxwxa": 59, "i": [2, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 64, 65, 66], "i16": 38, "i32": 38, "i8": 38, "id": 60, "ident": 59, "idx": 57, "ignor": 40, "imag": [11, 28, 35, 38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 57, 58, 59, 66], "image_blob_nam": [44, 48], "image_info_blob_nam": 48, "image_model": 48, "image_shap": 35, "image_threshold": 35, "image_util": 27, "imageinputdata": 12, "imagemodel": [10, 45, 46, 47, 48, 50, 51, 53, 54, 55, 59, 64], "imageresultwithsoftpredict": [17, 54], "imit": 41, "implement": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 58, 59, 66], "impli": [38, 41, 58], "import": [45, 46, 47, 50, 51, 54], "imread": [45, 46, 54], "imshow": 50, "includ": [46, 52, 57], "include_boundari": 57, "include_nested_contour": 54, "incorrect": 52, "independ": 57, "index": [38, 41, 48, 54], "indic": 57, "inf": 35, "infer": [28, 37, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59, 62, 64, 65, 66], "infer_async": [38, 39, 40, 41, 52], "infer_async_raw": 52, "infer_batch": 52, "infer_result": [38, 39, 40, 41], "infer_sync": [38, 39, 40, 41, 52], "inference_adapt": [38, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59], "inferenceadapt": [0, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59], "inferenceresult": 17, "inferencesdk": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32], "inferencesess": 39, "info": [38, 39, 40, 41, 42, 44, 48, 51], "inform": [38, 39, 40, 41, 51, 58], "inherit": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59, 66], "initi": [41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59], "input": [11, 35, 38, 39, 40, 41, 42, 44, 45, 48, 52, 53, 55, 57, 58, 59, 60, 64, 65, 66], "input0": [35, 42], "input1": [35, 42], "input_data": 52, "input_idx": [38, 39, 40, 41], "input_layer_nam": [44, 48, 50, 55, 59], "input_layer_name_1": [38, 39, 40, 52], "input_layer_name_2": [38, 39, 40, 52], "input_nam": [35, 42], "input_s": [35, 55, 57], "input_tensor": 40, "input_transform": [44, 48], "inputdata": 12, "inputtransform": [42, 44, 48], "inst_seg_result": 57, "insta": [38, 41], "instanc": [11, 20, 35, 38, 40, 41, 44, 48, 49, 52, 58, 59, 63, 66], "instance_segment": [50, 64], "instancesegmentationresult": [17, 50], "instancesegmentationtil": [21, 64], "int": [35, 38, 39, 40, 41, 44, 48, 52, 54, 57, 58], "int32": 51, "interest": 51, "interfac": [2, 38, 45, 46, 50, 52, 53, 54, 55, 59], "intermedi": 35, "intern": [11, 38, 39, 40, 41, 58], "internalimagemodeldata": 14, "internalmodeldata": 14, "interpol": [38, 41, 42], "interpolation_mod": [38, 39, 40, 41], "intersect": 35, "introduc": 35, "iou": [35, 57], "iou_threshold": [35, 57], "ir": [35, 40], "ir_v10": 40, "is_pad": 42, "is_readi": [38, 39, 40, 41, 52, 60], "isn": [35, 44], "item": 51, "iter": [47, 50, 51], "jpg": [45, 46, 54], "just": [38, 40, 41], "k": 59, "keep": [44, 48, 50, 52, 55, 59], "keep_aspect_ratio": 42, "keep_top_k": 57, "keepdim": 57, "kei": [38, 40, 52], "kept": 57, "kernel": 35, "keypoint": [11, 49], "keypoint_detect": 51, "keypointdetectionmodel": [15, 51], "kp_model": 51, "kuhn": 28, "kuhnmunkr": 29, "kwarg": 56, "label": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59], "label_fil": 57, "label_id": 48, "label_nam": [47, 50], "labels_lay": 55, "larg": 57, "last": 58, "later": 64, "launch": 58, "layer": [35, 39, 41, 48, 55], "layout": [35, 38, 39, 40, 41, 42, 44, 48, 50, 52, 55, 59], "layout_str": 42, "lead": [38, 39, 40], "learn": [46, 54, 58], "len": 35, "less": 54, "letter": 44, "level": 35, "like": [35, 44, 46, 48], "limit": 39, "list": [38, 39, 40, 41, 44, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 64], "listvalu": 56, "load": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 66], "load_label": 57, "load_model": [38, 39, 40, 41, 52], "load_parameters_from_onnx": 42, "locat": 51, "log_layers_info": 52, "log_runtime_set": 40, "logger": [52, 66], "logit": [46, 54, 57], "lsit": 62, "mai": 48, "map": [35, 46, 54, 58], "mask": [35, 50, 54, 58, 59], "maskrcnnmodel": [13, 39, 50], "mat": 54, "match": [35, 46, 58], "max": [35, 46, 56, 57], "max_answer_token_num": 35, "max_num": 57, "max_num_request": [40, 52], "maximum": 35, "mean": [35, 38, 39, 40, 41, 44, 48, 50, 55, 58, 59], "mean_valu": [35, 42, 44], "member": 35, "merg": 66, "messag": [52, 56], "meta": [38, 39, 40, 44, 45, 46, 50, 51, 52, 53, 54, 55, 59, 60], "metadata": [38, 39, 40, 41, 44, 46, 48, 50, 52, 53, 54, 55, 59], "method": [35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59, 66], "metric": 28, "might": [44, 48, 50, 52, 55, 59], "min": [35, 56], "minimum": 54, "mode": [38, 41, 62, 64, 65, 66], "model": [1, 36, 38, 39, 40, 41, 43, 44, 45, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66], "model_adapt": 53, "model_api": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66], "model_info": [35, 38, 39, 40, 41], "model_load": [52, 66], "model_nam": 41, "model_paramet": 40, "model_typ": [35, 52], "model_vers": 41, "modeladaptor": 52, "modelapi": 39, "modelbas": 16, "modelssd": 6, "modelyolo": 7, "modelyolov3onnx": 8, "modelyolox": 9, "modifi": 41, "modul": [38, 40, 41], "more": [44, 47, 48, 50, 54, 55, 59], "most": [35, 46], "multi": [46, 57], "multiclass": [35, 46], "multiclass_nm": 57, "multilabel": 35, "multipl": 35, "multipleoutputpars": 55, "munkr": 28, "must": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 66], "n": [44, 51, 59], "n_label": 58, "name": [35, 38, 39, 40, 44, 46, 47, 48, 50, 51, 52, 55], "namedtupl": 58, "nc": [35, 42], "nchw": [35, 38, 41, 42, 48, 51], "nchw_layout": 48, "ndarrai": [39, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59], "need": [38, 41], "nest": [38, 39], "network": [35, 54], "new": [35, 38, 40, 52, 58, 59], "new_shap": [38, 39, 40, 41, 52], "newli": 58, "next": 52, "nhwc": 48, "nm": [28, 35, 57], "node": 42, "non": [35, 46], "none": [38, 39, 40, 41, 42, 45, 46, 52, 56, 57, 58, 64], "nor": 35, "noreturn": 52, "normal": [35, 38, 41, 44, 48, 50, 55, 59], "normalization_scal": 35, "note": [35, 45, 55], "np": [45, 47, 50, 51, 53, 57, 58], "nscthw": 44, "nsthwc": 44, "nstream": 52, "nthread": 52, "num": 59, "num_class": [35, 54], "number": [35, 44, 51, 52, 57, 58, 59], "numericalvalu": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 59], "numpi": 54, "obj_keypoint": 51, "object": [38, 40, 42, 46, 47, 50, 51, 52, 55, 56, 57, 58, 59, 60, 62, 64], "obtain": [46, 50, 52, 53, 54, 55, 58, 59], "occur": 52, "ocv": 28, "ocv_common": 31, "offset": 57, "onc": 58, "one": [35, 38, 39, 40, 41, 44, 48, 50, 51, 52, 55, 58, 59, 62, 64, 65, 66], "ones": [47, 52, 58], "onli": [35, 39, 44, 48, 50, 55, 57, 59], "onnx": [11, 37], "onnx_adapt": 39, "onnx_model": 42, "onnx_shap": 39, "onnxruntim": 39, "onnxruntimeadapt": 39, "openvino": [2, 37, 38, 39, 41, 42, 44, 45, 46, 52, 54], "openvino_adapt": 40, "openvinoadapt": [40, 52], "openvinoinferenceadapt": 0, "openvinotoolkit": 39, "oper": [44, 46, 58], "operation_typ": 40, "operations_by_typ": 40, "option": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59], "order": [35, 46, 57], "org": 53, "organ": 51, "orig_s": 53, "origin": [44, 45, 47, 48, 50, 53, 55, 59], "original_shap": [44, 48, 50, 55, 59], "ort_opt": 39, "other": [35, 38], "otx": [35, 39, 45], "out": [48, 58], "output": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 35, 38, 39, 40, 41, 44, 45, 52, 53, 55, 59, 62, 64], "output_layer_name_1": [38, 39, 40, 41, 46, 50, 52, 53, 54, 55, 59], "output_layer_name_2": [38, 39, 40, 41, 46, 50, 52, 53, 54, 55, 59], "output_layout": 59, "output_nam": 35, "output_raw_scor": [35, 46], "output_resolut": 57, "outputtransform": 57, "ov": [40, 51], "ovani": [40, 42], "over": [35, 47, 50, 51], "overlap": 57, "overload": [35, 44, 48, 50, 55, 59], "overrid": [35, 51], "overridden": 58, "ovm": [37, 52], "ovms_adapt": 41, "ovmsadapt": 41, "pad": [35, 38, 41], "pad_valu": [35, 38, 39, 40, 41, 42], "padding_mod": 35, "padim": [2, 45], "param": 59, "paramet": [35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 57, 58, 59, 62, 64, 65, 66], "parent": 46, "pars": [42, 55], "parse_devic": 40, "parse_layout": 42, "parse_value_per_devic": 40, "particular": 39, "pass": [47, 50, 52, 58], "path": [35, 38, 39, 40, 41, 42, 52], "path_to_imag": [45, 46, 54], "path_to_label": 35, "path_to_model": [45, 46, 54], "per": [35, 51, 54, 57, 58], "perform": [28, 38, 39, 40, 41, 44, 48, 50, 52, 55, 57, 59], "performancemetr": 32, "permute_to_n_hwa_k": 59, "perspect": 51, "pipelin": [36, 43, 51, 58, 62, 64, 65, 66], "pixel": [35, 54], "pixel_threshold": 35, "place": 38, "plugin_config": 40, "point": [51, 54, 58], "polygon": 58, "popul": 40, "port": 41, "pose": 35, "possibl": [38, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59], "post": [44, 45], "postprocess": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 64, 65, 66], "postprocess_semantic_mask": 35, "pre": [35, 51], "precis": [38, 39, 40, 52], "pred_box": 45, "pred_i": 51, "pred_label": 45, "pred_mask": 45, "pred_scor": 45, "pred_x": 51, "predecessor": 46, "predict": [35, 45, 46, 47, 50, 51, 53, 54, 58, 64], "predict_crop": 51, "prefix": 56, "preload": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59], "prepar": [52, 58], "prepostprocessor": [40, 44], "preprocess": [35, 38, 39, 41, 44, 46, 47, 48, 50, 52, 53, 54, 55, 59], "preprocessed_imag": [44, 48, 50, 55, 59], "present": [51, 52, 58], "previou": 58, "previous": 58, "print": [47, 50, 52], "prioriti": 35, "probabilisticlabelsresolv": [3, 46], "probabl": [35, 46], "process": [35, 44, 45, 52, 53], "produc": 54, "project": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32], "prompt": [49, 53], "prompter": 58, "properti": [44, 52, 58], "provid": [2, 35, 38, 39, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 58, 59, 66], "py": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59], "python": [35, 38, 41, 51], "qualiti": 51, "queue": 28, "r": [38, 41], "radiu": 51, "rais": [41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59], "raise_error": 52, "rang": 48, "ratio": 35, "raw": [35, 38, 39, 40, 41, 45, 46, 50, 51, 52, 53, 54, 55, 59, 64, 65, 66], "raw_result_1": [38, 39, 40, 41, 46, 50, 52, 53, 54, 55, 59], "raw_result_2": [38, 39, 40, 41, 46, 50, 52, 53, 54, 55, 59], "raw_scor": 46, "read": 38, "readi": 52, "reason": 44, "reduc": 52, "refer": [39, 41, 58], "reference_featur": 58, "refin": 58, "reflect": 58, "region": 35, "regress": 51, "reimplement": 59, "relat": 58, "remot": 41, "remov": 46, "reorder": 46, "repres": [40, 46, 51, 54, 58], "represent": [35, 38, 39, 40, 41, 51], "request": [38, 39, 40, 41, 52, 60], "reset_featur": 58, "reset_reference_info": 58, "reshap": [35, 38, 39, 40, 52, 59], "reshape_model": [38, 39, 40, 41], "resiz": [35, 38, 41, 44, 47, 48, 50, 55, 57, 59], "resize_imag": 42, "resize_image_graph": 42, "resize_image_letterbox": [35, 42], "resize_image_letterbox_graph": 42, "resize_image_letterbox_ocv": 42, "resize_image_ocv": 42, "resize_image_with_aspect": 42, "resize_image_with_aspect_ocv": 42, "resize_mod": [38, 39, 40, 41], "resize_typ": [35, 44, 48], "resized_shap": [44, 48, 50, 55, 59], "resolut": 35, "resolv": 46, "resolve_label": 46, "respect": [46, 47, 50, 54], "result": [11, 38, 39, 40, 41, 45, 46, 47, 52, 54, 57, 58, 66], "resultimag": 54, "retinafacedetectionresult": 17, "retriev": [41, 52], "return": [35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66], "return_soft_predict": 35, "revers": 35, "reverse_input_channel": [35, 42], "rgb": [44, 48, 50, 55, 59], "right": 58, "right_bottom": 35, "rotatedsegmentationresult": 57, "routin": 52, "rt": [40, 51], "rt_info": 35, "rt_info_dict": 42, "run": [39, 52, 58], "runner": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32], "salienc": [46, 54], "saliency_map": [46, 54], "sam": [49, 58], "sam_model": 53, "samdecod": [53, 58], "same": 58, "samimageencod": [53, 58], "samlearnablevisualprompt": 58, "samvisualprompt": 58, "save": [38, 39, 40, 52], "save_model": [38, 39, 40, 41], "scale": [35, 38, 39, 40, 41, 44, 48, 50, 55, 57, 59], "scale_valu": [35, 42], "scc": 51, "scope": 39, "score": [35, 46, 47, 50, 51, 55, 57, 64], "scoredlabel": 46, "scores_lay": 55, "scratch": 58, "search": 54, "secondari": 48, "section": 35, "see": [44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 59], "seg_result": 57, "segment": [11, 20, 35, 49, 58, 63], "segmentationmodel": [18, 39, 53, 54], "segmentedobject": [17, 64], "segmentedobjectwithrect": 17, "select": 46, "self": [42, 46], "semant": [20, 63, 64], "semantic_segment": 65, "semanticsegmentationtil": [22, 65], "separ": [35, 38, 50, 52], "sequenc": [35, 38, 39, 58], "serial": [35, 38, 39, 40, 52], "serv": 41, "server": 41, "session": 39, "set": [35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59, 62, 65, 66], "set_callback": [38, 39, 40, 41, 52], "set_strides_grid": 59, "shape": [35, 38, 39, 40, 41, 42, 45, 46, 47, 50, 52, 54, 58], "should": [35, 38, 39, 40, 44, 47, 48, 50, 52, 55, 58, 59], "shown": 52, "side": 59, "sigmoid": 59, "sigmoid_numpi": 46, "simcc": 51, "similar": 66, "simpl": 51, "simplelabelsgraph": [3, 46], "singl": [2, 39, 44, 45, 46, 47, 48, 50, 51, 54, 55, 59], "singleoutputpars": 55, "size": [35, 42, 44, 48, 50, 51, 53, 55, 57, 59], "size_divisor": 35, "skip": [52, 58], "slog": 28, "smoother": 54, "so": [44, 57], "soft": [53, 54], "soft_predict": 54, "soft_threshold": [35, 54], "softmax": 57, "some": [38, 41], "sourc": [41, 58], "specif": [38, 39, 40, 41, 44, 45, 48, 52, 53, 55, 59, 62, 64, 65, 66], "specifi": [35, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59], "squad": 35, "squad_ver": 35, "ssd": [11, 39, 47, 49, 52], "stage": 58, "standard": 35, "start": 58, "state": 58, "static": [35, 42, 55], "step": [38, 39, 41, 46], "stfpm": [2, 45], "store": [35, 38, 39, 41, 52, 58], "str": [35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 65, 66], "strategi": 57, "stream": 52, "strict": 54, "stricter": 58, "string": [35, 39], "stringvalu": 56, "structur": [38, 39, 40, 52, 66], "stub": 41, "style": 39, "subclass": 52, "submiss": [38, 39, 40, 41], "submit": [38, 39, 40, 41, 52], "submit_data": 60, "subtract": [35, 44, 48, 50, 55, 59], "support": [2, 39, 44, 45, 46, 48, 50, 55, 59], "suppress": 35, "suquenc": 40, "swap": [38, 41], "switch": [44, 48, 50, 55, 59], "sync": [62, 64, 65, 66], "synchron": [38, 39, 40, 41, 52], "t": [35, 39, 44], "tag": [38, 39, 40], "take": 35, "taken": [35, 38, 39, 40, 46], "target": [38, 41], "target_model": 41, "target_s": 35, "target_shap": [38, 39, 40, 41], "task": 35, "tensor": [44, 48, 51, 59], "term": 59, "than": [47, 55, 59], "thei": [35, 38, 46, 52], "thi": [35, 38, 39, 41, 44, 45, 46, 51, 54, 62, 64], "thick": 51, "thread": 52, "thresh": 57, "threshold": [35, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59], "thrown": 58, "tight": 51, "tile": [62, 64, 65, 66], "tile_classifier_model": 64, "tile_prob": 64, "tile_s": [62, 64, 65, 66], "tiler": [1, 36, 43, 62, 64, 65], "tilerbas": 23, "tiles_overlap": [62, 64, 65, 66], "time": [44, 52, 58], "todo": [1, 11, 20, 28, 36, 37, 43, 49, 61, 63], "token": 35, "top": [39, 46, 51], "top_down_detector": 51, "top_down_pipelin": 51, "top_label": 46, "topdownkeypointdetectionpipelin": 51, "topk": [35, 46], "topological_sort": 46, "torchvis": 58, "train": [35, 39, 46, 54], "training_extens": 39, "transpos": 59, "tree": 46, "true": [35, 46, 52, 54, 58], "tupl": [38, 41, 46, 57, 58, 59], "two": [35, 40, 44, 46, 51], "type": [35, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 62, 64, 65, 66], "u8": 38, "uint8": 45, "ultralyt": 59, "under": [38, 39], "underli": [51, 52, 62, 64, 65, 66], "union": 35, "until": [38, 39, 40, 41], "updat": [38, 39, 41, 53, 58], "update_default_valu": 56, "update_model_info": [38, 39, 40, 41], "upgrad": 45, "upsampl": 35, "upsample_ratio": 35, "url": [41, 52], "us": [35, 38, 39, 41, 44, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59, 64], "usag": 58, "used_indic": 58, "user": 42, "user_data": 52, "user_layout": 42, "usual": 54, "util": [1, 36, 37, 49], "v": 58, "v2": 41, "valid": 56, "valu": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 62, 64, 65, 66], "value1": 40, "value2": 40, "value_typ": 56, "valueerror": 56, "values_str": 40, "variabl": 52, "vector": [46, 51, 54], "version": [35, 38, 39, 40, 41, 52], "vertic": 46, "via": [35, 39, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 59], "video": 44, "visual": 49, "visual_prompt": 58, "visualpromptingfeatur": 58, "visualpromptingresult": 58, "vocab": 35, "vpt": 58, "w": [44, 46, 47, 50, 54, 58, 59], "wait": [38, 39, 40, 41, 52], "waitkei": 50, "warmup_cach": 46, "we": [38, 41, 57], "weight": [38, 40, 52], "weights_path": [38, 39, 40, 41, 52], "well": 46, "what": 44, "when": [45, 58], "where": [46, 47, 50, 51, 52, 54, 58], "whether": [38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59, 66], "which": [35, 38, 39, 40, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 62, 64, 65, 66], "while": [44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59], "width": [35, 44, 46, 47, 50, 54, 57], "within": 51, "without": 58, "work": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 40, 41, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59], "workflow": 58, "would": [38, 41], "wrap": [40, 55], "wrapper": [35, 39, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 58, 59, 62, 64, 65, 66], "wrapper_nam": 52, "wrappererror": [44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 59], "wrappernam": 52, "write": [38, 39, 52], "x": [44, 46, 51, 58, 59], "x1": [47, 50, 57], "x2": [47, 50, 57], "x_max": 51, "x_min": 51, "xmax": 55, "xmin": 55, "xml": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 35, 40, 45, 46, 47, 50, 51, 54], "xy": 58, "xywh": 59, "xywh2xyxi": 59, "xyxi": 58, "y": [51, 59], "y1": [47, 50, 57], "y2": [47, 50, 57], "y_max": 51, "y_min": 51, "ymax": 55, "ymin": 55, "yolo": [11, 49], "yolof": 59, "yolov3": 11, "yolov3onnx": 59, "yolov4": 59, "yolov5": 59, "yolov8": 59, "yolox": [11, 59], "zip": [47, 50], "zoo": 52, "zsl": 58, "zslvisualpromptingresult": 58}, "titles": ["Adapters", "C++ API Reference", "Anomaly Model", "Classification Model", "Detection Model", "Detection Model Ext", "Detection Model SSD", "Detection Model Yolo", "Detection Model Yolov3 ONNX", "Detection Model YoloX", "Image Model", "Models", "Input Data", "Instance Segmentation", "Internal Model Data", "Keypoint Detection", "Model Base", "Results", "Segmentation Model", "Detection", "Tilers", "Instance Segmentation", "Semantic Segmentation", "Tiler Base", "Args Helper", "Async Infer Queue", "Common", "Image Utils", "Utils", "Kuhn Munkres", "Nms", "Ocv Common", "Performance Metrics", "Slog", "Guides", "Model configuration", "InferenceSDK Documentation", "Adapters", "Inference Adapter", "Onnx Adapter", "Openvino Adapter", "Ovms Adapter", "Utils", "Python API Reference", "Action Classification", "Anomaly", "Classification", "Detection Model", "Image Model", "Models", "Instance Segmentation", "Keypoint Detection", "Model", "Sam Models", "Segmentation", "Ssd", "Types", "Utils", "Visual Prompting", "Yolo", "Async Pipeline", "Pipelines", "Detection", "Tilers", "Instance Segmentation", "Semantic Segmentation", "Tiler"], "titleterms": {"With": 17, "action": 44, "actionclassificationmodel": 35, "adapt": [0, 37, 38, 39, 40, 41], "anomali": [2, 17, 45], "anomalydetect": 35, "api": [1, 36, 43], "arg": 24, "async": [25, 60], "base": [16, 17, 23], "bert": 35, "bertquestionansw": 35, "c": [1, 36], "classif": [3, 17, 44, 46], "classificationmodel": 35, "common": [26, 31], "configur": 35, "contour": 17, "ctpn": 35, "data": [12, 14], "descript": [46, 47, 50, 51], "detect": [4, 5, 6, 7, 8, 9, 15, 17, 19, 47, 51, 62], "detectedkeypoint": 17, "detectionmodel": 35, "document": 36, "exampl": [47, 50, 51], "ext": 5, "facebox": 35, "graph": 3, "greedi": 3, "guid": 34, "helper": 24, "hpeassociativeembed": 35, "humanpos": 17, "humanposeresult": 17, "imag": [10, 17, 27, 48], "imageinput": 12, "imagemodel": 35, "imageresult": 17, "infer": [17, 25, 38], "inferencesdk": 36, "input": [12, 46, 47, 50, 51, 54], "instanc": [13, 17, 21, 50, 64], "intern": 14, "internalscaledata": 14, "internamimagemodeldata": 14, "its": 35, "keypoint": [15, 51], "keypointdetectionresult": 17, "kuhn": 29, "label": 3, "list": 35, "maskrcnnmodel": 35, "metric": 32, "model": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 18, 35, 46, 47, 48, 49, 50, 51, 52, 53, 54], "munkr": 29, "nanodet": 35, "nm": 30, "object": 17, "ocv": 31, "onnx": [8, 39], "openpos": 35, "openvino": [40, 47, 50, 51], "output": [46, 47, 50, 51, 54], "ovm": 41, "paramet": 51, "perform": 32, "pipelin": [60, 61], "predict": 17, "probabilist": 3, "prompt": 58, "python": [36, 43], "queue": 25, "rect": 17, "refer": [1, 36, 43], "resolv": 3, "result": 17, "resultbas": 17, "retinafac": 17, "sam": 53, "segment": [13, 17, 18, 21, 22, 50, 54, 64, 65], "segmentationmodel": 35, "semant": [22, 65], "simpl": 3, "slog": 33, "soft": 17, "specif": [46, 47, 50, 51, 54], "ssd": [6, 55], "subclass": 35, "tiler": [20, 23, 63, 66], "type": 56, "ultralightweightfacedetect": 35, "util": [27, 28, 42, 57], "valu": 35, "visual": 58, "yolo": [7, 35, 59], "yolov3": 8, "yolov4": 35, "yolov5": 35, "yolov8": 35, "yolox": [9, 35]}})