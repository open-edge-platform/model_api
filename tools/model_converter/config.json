{
  "models": [
    {
      "model_short_name": "efficientnet_b0",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b0",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B0",
      "description": "EfficientNet-B0 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b0.html#torchvision.models.efficientnet_b0",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b1",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b1",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B1",
      "description": "EfficientNet-B1 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b1.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth",
      "input_shape": [1, 3, 240, 240],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b2",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b2",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B2",
      "description": "EfficientNet-B2 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b2.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth",
      "input_shape": [1, 3, 260, 260],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b3",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b3",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B3",
      "description": "EfficientNet-B3 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b3.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth",
      "input_shape": [1, 3, 300, 300],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b4",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b4",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B4",
      "description": "EfficientNet-B4 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b4.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth",
      "input_shape": [1, 3, 380, 380],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b5",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b5",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B5",
      "description": "EfficientNet-B5 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b5.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b5_lukemelas-1a07897c.pth",
      "input_shape": [1, 3, 456, 456],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b6",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b6",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B6",
      "description": "EfficientNet-B6 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b6.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b6_lukemelas-24a108a5.pth",
      "input_shape": [1, 3, 528, 528],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b7",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b7",
      "model_library": "torchvision",
      "model_full_name": "EfficientNet-B7",
      "description": "EfficientNet-B7 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b7.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b7_lukemelas-c5b4e57e.pth",
      "input_shape": [1, 3, 600, 600],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_v2_s",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_v2_s",
      "model_library": "torchvision",
      "model_full_name": "EfficientNetV2-S",
      "description": "EfficientNetV2-Small - Improved EfficientNet with faster training and better parameter efficiency",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_v2_s.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth",
      "input_shape": [1, 3, 384, 384],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_v2_m",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_v2_m",
      "model_library": "torchvision",
      "model_full_name": "EfficientNetV2-M",
      "description": "EfficientNetV2-Medium - Improved EfficientNet with faster training and better parameter efficiency",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_v2_m.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_v2_m-dc08266a.pth",
      "input_shape": [1, 3, 480, 480],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_v2_l",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_v2_l",
      "model_library": "torchvision",
      "model_full_name": "EfficientNetV2-L",
      "description": "EfficientNetV2-Large - Improved EfficientNet with faster training and better parameter efficiency",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_v2_l.html",
      "weights_url": "https://download.pytorch.org/models/efficientnet_v2_l-59c71312.pth",
      "input_shape": [1, 3, 480, 480],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "mobilenet_v2",
      "model_class_name": "torchvision.models.mobilenetv2.mobilenet_v2",
      "model_library": "torchvision",
      "model_full_name": "MobileNetV2",
      "description": "MobileNetV2 - Efficient convolutional neural network for mobile and embedded vision applications",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v2.html",
      "weights_url": "https://download.pytorch.org/models/mobilenet_v2-b0353104.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "mobilenet_v3_small",
      "model_class_name": "torchvision.models.mobilenetv3.mobilenet_v3_small",
      "model_library": "torchvision",
      "model_full_name": "MobileNetV3-Small",
      "description": "MobileNetV3 Small - Efficient convolutional neural network for mobile and embedded vision applications",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v3_small.html#torchvision.models.mobilenet_v3_small",
      "weights_url": "https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output1"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "mobilenet_v3_large",
      "model_class_name": "torchvision.models.mobilenetv3.mobilenet_v3_large",
      "model_library": "torchvision",
      "model_full_name": "MobileNetV3-Large",
      "description": "MobileNetV3 Large - Efficient convolutional neural network for mobile and embedded vision applications",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v3_large.html",
      "weights_url": "https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "resnet18",
      "model_class_name": "torchvision.models.resnet.resnet18",
      "model_library": "torchvision",
      "model_full_name": "ResNet-18",
      "description": "ResNet-18 - 18-layer residual learning network for image classification",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html",
      "weights_url": "https://download.pytorch.org/models/resnet18-f37072fd.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "resnet34",
      "model_class_name": "torchvision.models.resnet.resnet34",
      "model_library": "torchvision",
      "model_full_name": "ResNet-34",
      "description": "ResNet-34 - 34-layer residual learning network for image classification",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet34.html",
      "weights_url": "https://download.pytorch.org/models/resnet34-b627a593.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "resnet50",
      "model_class_name": "torchvision.models.resnet.resnet50",
      "model_library": "torchvision",
      "model_full_name": "ResNet-50",
      "description": "ResNet-50 - 50-layer residual learning network for image classification",
      "weights_url": "https://download.pytorch.org/models/resnet50-0676ba61.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },    
    {
      "model_short_name": "resnet101",
      "model_class_name": "torchvision.models.resnet.resnet101",
      "model_library": "torchvision",
      "model_full_name": "ResNet-101",
      "description": "ResNet-101 - 101-layer residual learning network for image classification",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet101.html",
      "weights_url": "https://download.pytorch.org/models/resnet101-63fe2227.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "resnet152",
      "model_class_name": "torchvision.models.resnet.resnet152",
      "model_library": "torchvision",
      "model_full_name": "ResNet-152",
      "description": "ResNet-152 - 152-layer residual learning network for image classification",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet152.html",
      "weights_url": "https://download.pytorch.org/models/resnet152-394f9c45.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },

    {
      "model_short_name": "mobilenetv2_050_lamb_in1k",
      "huggingface_repo": "timm/mobilenetv2_050.lamb_in1k",
      "model_library": "timm",
      "model_full_name": "MobileNetV2-0.5 LAMB ImageNet-1k",
      "description": "MobileNetV2 with 0.5x width multiplier trained with LAMB optimizer on ImageNet-1k",
      "docs": "https://huggingface.co/timm/mobilenetv2_050.lamb_in1k",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "mobilenetv2_100_ra_in1k",
      "huggingface_repo": "timm/mobilenetv2_100.ra_in1k",
      "model_library": "timm",
      "model_full_name": "MobileNetV2-1.0 RandAugment ImageNet-1k",
      "description": "MobileNetV2 with 1.0x width multiplier trained with RandAugment on ImageNet-1k",
      "docs": "https://huggingface.co/timm/mobilenetv2_100.ra_in1k",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "mobilenetv2_110d_ra_in1k",
      "huggingface_repo": "timm/mobilenetv2_110d.ra_in1k",
      "model_library": "timm",
      "model_full_name": "MobileNetV2-1.1 RandAugment ImageNet-1k",
      "description": "MobileNetV2 with 1.1x width multiplier trained with RandAugment on ImageNet-1k",
      "docs": "https://huggingface.co/timm/mobilenetv2_110d.ra_in1k",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "mobilenetv2_120d_ra_in1k",
      "huggingface_repo": "timm/mobilenetv2_120d.ra_in1k",
      "model_library": "timm",
      "model_full_name": "MobileNetV2-1.2 RandAugment ImageNet-1k",
      "description": "MobileNetV2 with 1.2x width multiplier trained with RandAugment on ImageNet-1k",
      "docs": "https://huggingface.co/timm/mobilenetv2_120d.ra_in1k",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "mobilenetv2_140_ra_in1k",
      "huggingface_repo": "timm/mobilenetv2_140.ra_in1k",
      "model_library": "timm",
      "model_full_name": "MobileNetV2-1.4 RandAugment ImageNet-1k",
      "description": "MobileNetV2 with 1.4x width multiplier trained with RandAugment on ImageNet-1k",
      "docs": "https://huggingface.co/timm/mobilenetv2_140.ra_in1k",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b0_ra_in1k",
      "huggingface_repo": "timm/efficientnet_b0.ra_in1k",
      "model_library": "timm",
      "model_full_name": "EfficientNet-B0 RandAugment ImageNet-1k",
      "description": "EfficientNet-B0 trained with RandAugment recipe on ImageNet-1k",
      "docs": "https://huggingface.co/timm/efficientnet_b0.ra_in1k",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b0_ra4_e3600_r224_in1k",
      "huggingface_repo": "timm/efficientnet_b0.ra4_e3600_r224_in1k",
      "model_library": "timm",
      "model_full_name": "EfficientNet-B0 RA4 3600 Epochs ImageNet-1k",
      "description": "EfficientNet-B0 trained with RA4 recipe for 3600 epochs on ImageNet-1k",
      "docs": "https://huggingface.co/timm/efficientnet_b0.ra4_e3600_r224_in1k",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b1_ft_in1k",
      "huggingface_repo": "timm/efficientnet_b1.ft_in1k",
      "model_library": "timm",
      "model_full_name": "EfficientNet-B1 Fine-tuned ImageNet-1k",
      "description": "EfficientNet-B1 fine-tuned on ImageNet-1k",
      "docs": "https://huggingface.co/timm/efficientnet_b1.ft_in1k",
      "input_shape": [1, 3, 240, 240],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b1_pruned_in1k",
      "huggingface_repo": "timm/efficientnet_b1_pruned.in1k",
      "model_library": "timm",
      "model_full_name": "EfficientNet-B1 Pruned ImageNet-1k",
      "description": "EfficientNet-B1 with pruned weights on ImageNet-1k",
      "docs": "https://huggingface.co/timm/efficientnet_b1_pruned.in1k",
      "input_shape": [1, 3, 240, 240],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b1_ra4_e3600_r240_in1k",
      "huggingface_repo": "timm/efficientnet_b1.ra4_e3600_r240_in1k",
      "model_library": "timm",
      "model_full_name": "EfficientNet-B1 RA4 3600 Epochs ImageNet-1k",
      "description": "EfficientNet-B1 trained with RA4 recipe for 3600 epochs at 240x240 resolution on ImageNet-1k",
      "docs": "https://huggingface.co/timm/efficientnet_b1.ra4_e3600_r240_in1k",
      "input_shape": [1, 3, 240, 240],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    }
  ]
}
