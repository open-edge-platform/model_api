{
  "models": [
    {
      "model_short_name": "mobilenet_v3_small",
      "model_class_name": "torchvision.models.mobilenetv3.mobilenet_v3_small",
      "model_full_name": "MobileNetV3-Small",
      "description": "MobileNetV3 Small - Efficient convolutional neural network for mobile and embedded vision applications",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v3_small.html#torchvision.models.mobilenet_v3_small",
      "weights_url": "https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output1"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": false,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "efficientnet_b0",
      "model_class_name": "torchvision.models.efficientnet.efficientnet_b0",
      "model_full_name": "EfficientNet-B0",
      "description": "EfficientNet-B0 - Efficient convolutional neural network with compound scaling",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_b0.html#torchvision.models.efficientnet_b0",
      "weights_url": "https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["logits"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "resnet18",
      "model_class_name": "torchvision.models.resnet.resnet18",
      "model_full_name": "ResNet-18",
      "description": "ResNet-18 - 18-layer residual learning network for image classification",
      "weights_url": "https://download.pytorch.org/models/resnet18-f37072fd.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "resnet50",
      "model_class_name": "torchvision.models.resnet.resnet50",
      "model_full_name": "ResNet-50",
      "description": "ResNet-50 - 50-layer residual learning network for image classification",
      "weights_url": "https://download.pytorch.org/models/resnet50-0676ba61.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "squeezenet1_0",
      "model_class_name": "torchvision.models.squeezenet.squeezenet1_0",
      "model_full_name": "SqueezeNet 1.0",
      "description": "SqueezeNet 1.0 - Small CNN with AlexNet-level accuracy and 50x fewer parameters",
      "weights_url": "https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "vgg16",
      "model_class_name": "torchvision.models.vgg.vgg16",
      "model_full_name": "VGG-16",
      "description": "VGG-16 - 16-layer deep convolutional network",
      "weights_url": "https://download.pytorch.org/models/vgg16-397923af.pth",
      "input_shape": [1, 3, 224, 224],
      "input_names": ["image"],
      "output_names": ["output"],
      "model_params": null,
      "model_type": "Classification",
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "IMAGENET1K_V1"
    },
    {
      "model_short_name": "ssd300_vgg16",
      "model_class_name": "torchvision.models.detection.ssd.ssd300_vgg16",
      "model_full_name": "SSD300 VGG16",
      "description": "SSD300 with VGG16 backbone - Single Shot MultiBox Detector for object detection",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.detection.ssd300_vgg16.html",
      "weights_url": "https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth",
      "input_shape": [1, 3, 300, 300],
      "input_names": ["image"],
      "output_names": ["boxes", "scores", "labels"],
      "model_params": null,
      "model_type": "SSD",
      "export_method": "onnx",
      "onnx_opset_version": 17,
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "COCO"
    },
    {
      "model_short_name": "ssdlite320_mobilenet_v3_large",
      "model_class_name": "torchvision.models.detection.ssdlite.ssdlite320_mobilenet_v3_large",
      "model_full_name": "SSDLite320 MobileNetV3 Large",
      "description": "SSDLite with MobileNetV3 Large backbone - Lightweight object detection model",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.detection.ssdlite320_mobilenet_v3_large.html",
      "weights_url": "https://download.pytorch.org/models/ssdlite320_mobilenet_v3_large_coco-a79551df.pth",
      "input_shape": [1, 3, 320, 320],
      "input_names": ["image"],
      "output_names": ["boxes", "scores", "labels"],
      "model_params": null,
      "model_type": "SSD",
      "export_method": "onnx",
      "onnx_opset_version": 17,
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "COCO"
    },
    {
      "model_short_name": "fasterrcnn_resnet50_fpn",
      "model_class_name": "torchvision.models.detection.faster_rcnn.fasterrcnn_resnet50_fpn",
      "model_full_name": "Faster R-CNN ResNet50 FPN",
      "description": "Faster R-CNN with ResNet50 FPN backbone - Two-stage object detection model",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html",
      "weights_url": "https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth",
      "input_shape": [1, 3, 800, 800],
      "input_names": ["image"],
      "output_names": ["boxes", "scores", "labels"],
      "model_params": null,
      "model_type": "FasterRCNNModel",
      "export_method": "onnx",
      "onnx_opset_version": 17,
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "COCO"
    },
    {
      "model_short_name": "fasterrcnn_mobilenet_v3_large_fpn",
      "model_class_name": "torchvision.models.detection.faster_rcnn.fasterrcnn_mobilenet_v3_large_fpn",
      "model_full_name": "Faster R-CNN MobileNetV3 Large FPN",
      "description": "Faster R-CNN with MobileNetV3 Large FPN backbone - Lightweight two-stage object detection",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn.html",
      "weights_url": "https://download.pytorch.org/models/fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth",
      "input_shape": [1, 3, 800, 800],
      "input_names": ["image"],
      "output_names": ["boxes", "scores", "labels"],
      "model_params": null,
      "model_type": "FasterRCNNModel",
      "export_method": "onnx",
      "onnx_opset_version": 17,
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "COCO"
    },
    {
      "model_short_name": "retinanet_resnet50_fpn",
      "model_class_name": "torchvision.models.detection.retinanet.retinanet_resnet50_fpn",
      "model_full_name": "RetinaNet ResNet50 FPN",
      "description": "RetinaNet with ResNet50 FPN backbone - Single-stage object detection with focal loss",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.detection.retinanet_resnet50_fpn.html",
      "weights_url": "https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth",
      "input_shape": [1, 3, 800, 800],
      "input_names": ["image"],
      "output_names": ["boxes", "scores", "labels"],
      "model_params": null,
      "model_type": "RetinaNet",
      "export_method": "onnx",
      "onnx_opset_version": 17,
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "COCO"
    },
    {
      "model_short_name": "maskrcnn_resnet50_fpn",
      "model_class_name": "torchvision.models.detection.mask_rcnn.maskrcnn_resnet50_fpn",
      "model_full_name": "Mask R-CNN ResNet50 FPN",
      "description": "Mask R-CNN with ResNet50 FPN backbone - Instance segmentation model for object detection and segmentation",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.detection.maskrcnn_resnet50_fpn.html",
      "weights_url": "https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth",
      "input_shape": [1, 3, 800, 800],
      "input_names": ["image"],
      "output_names": ["boxes", "labels", "masks"],
      "model_params": null,
      "model_type": "MaskRCNN",
      "export_method": "onnx",
      "onnx_opset_version": 17,
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "COCO"
    },
    {
      "model_short_name": "maskrcnn_resnet50_fpn_v2",
      "model_class_name": "torchvision.models.detection.mask_rcnn.maskrcnn_resnet50_fpn_v2",
      "model_full_name": "Mask R-CNN ResNet50 FPN V2",
      "description": "Mask R-CNN V2 with ResNet50 FPN backbone - Improved instance segmentation model",
      "docs": "https://docs.pytorch.org/vision/main/models/generated/torchvision.models.detection.maskrcnn_resnet50_fpn_v2.html",
      "weights_url": "https://download.pytorch.org/models/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth",
      "input_shape": [1, 3, 800, 800],
      "input_names": ["image"],
      "output_names": ["boxes", "labels", "masks"],
      "model_params": null,
      "model_type": "MaskRCNN",
      "export_method": "onnx",
      "onnx_opset_version": 17,
      "reverse_input_channels": true,
      "mean_values": "123.675 116.28 103.53",
      "scale_values": "58.395 57.12 57.375",
      "labels": "COCO"
    }
  ]
}
